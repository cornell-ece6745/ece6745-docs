{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"ece6745-sec01-asic-front-end/","title":"ECE 6745 Section 1: ASIC Front-End Flow","text":"<p>In this section, we will be discussing the front-end of the ASIC toolflow. More detailed tutorials will be posted on the public course website, but this section will at least give you a chance to edit some RTL, synthesize that to a gate-level netlist, and then simulate that gate-level netlist. The following diagram illustrates the tool flow we will be using in ECE 6745. Notice that the Synopsys and Cadence ASIC tools all require various views from the standard-cell library which part of the ASIC design kit (ADK).</p> <p></p> <p>The \"front-end\" of the flow is highlighted in red and refers to the PyMTL simulator, Synopsys DC, and Synopsys VCS:</p> <ul> <li>We write our RTL models in Verilog, and we use the PyMTL framework to    test, verify, and evaluate the execution time (in cycles) of our    design. This part of the flow is very similar to the flow used in ECE</li> <li> <p>Once we are sure our design is working correctly, we can then    start to push the design through the flow.</p> </li> <li> <p>We use Synopsys VCS for RTL and gate-level simulation. PyMTL uses    the Verilator two-state RTL simulator meaning every wire will be    either a 0 (logic low) or 1 (logic high). Synopsys VCS uses four-state    RTL simulation meaning every wire will be either a 0 (logic low), 1    (logic high), X (unknown), or Z (floating). Four-state RTL simulation    can identify different kinds of bugs than two-state simulation such as    bugs due to uninitialized state. Gate-level simulation involves    simulating every standard-cell gate and helps verify that the Verilog    gate-level netlist is functionally correct.</p> </li> <li> <p>We use Synopsys Design Compiler (DC) to synthesize our design,    which means to transform the Verilog RTL model into a Verilog    gate-level netlist where all of the gates are selected from the    standard-cell library. We need to provide Synopsys DC with abstract    logical and timing views of the standard-cell library in <code>.db</code> format.    In addition to the Verilog gate-level netlist, Synopsys DC can also    generate a <code>.ddc</code> file which contains information about the gate-level    netlist and timing, and this <code>.ddc</code> file can be inspected using    Synopsys Design Vision (DV).</p> </li> </ul> <p>Extensive documentation is provided by Synopsys and Cadence. We have organized this documentation and made it available to you on the Canvas course page:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use Microsoft Remote Desktop to log into a specific <code>ecelinux</code> server. Then use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone https://github.com/cornell-ece6745/ece6745-sec01-asic-front-end sec01\n% cd sec01\n% TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#1-nangate-45nm-standard-cell-libraries","title":"1. NanGate 45nm Standard-Cell Libraries","text":"<p>A standard-cell library is a collection of combinational and sequential logic gates that adhere to a standardized set of logical, electrical, and physical policies. For example, all standard cells are usually the same height, include pins that align to a predetermined vertical and horizontal grid, include power/ground rails and nwells in predetermined locations, and support a predetermined number of drive strengths. In this course, we will be using the a NanGate 45nm standard-cell library. It is based on a \"fake\" 45nm technology. This means you cannot actually tapeout a design using this standard cell library, but the technology is representative enough to provide reasonable area, energy, and timing estimates for teaching purposes. All of the files associated with this standard cell library are located in the <code>${ECE6745_STDCELLS}</code> directory.</p> <p>Let's first look at the data book which is on the Canvas course page:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/resources/nangate-freepdk45nm-stdcell-databook.pdf</li> </ul> <p>Scroll through the PDF and find the entry for the NAND3_X1 cell (it is on page 104). The data book provides information on the standard cell's logic function, delay, area, and power consumption. Let's take a look at the layout for the same cell. Note that since Klayout is a Linux GUI application you will need to use Microsoft Remote Desktop.</p> <pre><code>% klayout -l ${ECE6745_STDCELLS}/klayout.lyp ${ECE6745_STDCELLS}/stdcells.gds\n</code></pre> <p>Find the NAND3_X1 cell in the left-hand cell list, and then choose Display &gt; Show as New Top from the menu. We will learn more about layout and how this layout corresponds to a static CMOS circuit later in the course. The key point is that the layout for the standard cells are the basic building blocks that we will be using to create our ASIC chips.</p> <p>The Synopsys and Cadence tools do not actually use this layout directly; it is actually too detailed. Instead these tools use abstract views of the standard cells, which capture logical functionality, timing, geometry, and power usage at a much higher level. Let's look at the Verilog behavioral specification for the 3-input NAND cell.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.v\n</code></pre> <p>Note that the Verilog implementation of the 3-input NAND cell looks nothing like the Verilog we used in ECE 4750. This cell is implemented using three Verilog primitive gates (i.e., two <code>and</code> gates and one <code>not</code> gate), and it includes a <code>specify</code> block which is used for advanced gate-level simulation with back-annotated delays.</p> <p>Finally, let's look at an abstract view of the timing and power of the 3-input NAND cell suitable for use by the ASIC flow. This abstract view is in the <code>.lib</code> file for the standard cell library.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.lib\n</code></pre> <p>Now that we have looked at some of the views of the standard cell library, we can now try using these views and the ASIC flow front-end to synthesize RTL into a gate-level netlist.</p>"},{"location":"ece6745-sec01-asic-front-end/#2-pymtl-based-testing-simulation-translation","title":"2. PyMTL-Based Testing, Simulation, Translation","text":"<p>Our goal in this section is to generate a gate-level netlist for the following four-stage registered incrementer:</p> <p></p> <p>We will take an incremental design approach. We will start by implementing and testing a single registered incrementer, and then we will write a generic multi-stage registered incrementer. For this section (and indeed the entire course) you will use Verilog for RTL design and Python for test harnesses, simulation drivers, function-level models, and cycle-level models.</p>"},{"location":"ece6745-sec01-asic-front-end/#21-implement-and-test-a-registered-incrementer","title":"2.1. Implement and Test a Registered Incrementer","text":"<p>Now let's run all of the tests for the registered incrementer:</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr\n</code></pre> <p>The tests will fail because we need to finish the implementation. Let's start by focusing on the basic registered incrementer module.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr/test/RegIncr_test.py\n</code></pre> <p>Use VS Code to open the implementation and uncomment the actual combinational logic for the increment operation. The Verilog RTL implementation should look as follows:</p> <pre><code>`ifndef TUT3_VERILOG_REGINCR_REG_INCR_V\n`define TUT3_VERILOG_REGINCR_REG_INCR_V\n\nmodule tut3_verilog_regincr_RegIncr\n(\n  input  logic       clk,\n  input  logic       reset,\n  input  logic [7:0] in_,\n  output logic [7:0] out\n);\n\n  // Sequential logic\n\n  logic [7:0] reg_out;\n\n  always @( posedge clk ) begin\n    if ( reset )\n      reg_out &lt;= 0;\n    else\n      reg_out &lt;= in_;\n  end\n\n  // Combinational logic\n\n  logic [7:0] temp_wire;\n\n  always @(*) begin\n    temp_wire = reg_out + 1;\n  end\n\n  // Combinational logic\n\n  assign out = temp_wire;\n\n  // Line tracing\n\n  `ifndef SYNTHESIS\n\n  logic [`VC_TRACE_NBITS-1:0] str;\n  `VC_TRACE_BEGIN\n  begin\n    $sformat( str, \"%x (%x) %x\", in_, reg_out, out );\n    vc_trace.append_str( trace_str, str );\n  end\n  `VC_TRACE_END\n\n  `endif /* SYNTHESIS */\n\nendmodule\n\n`endif /* TUT3_VERILOG_REGINCR_REG_INCR_V */\n</code></pre> <p>If you have an error you can use a trace-back to get a more detailed error message:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr/test/RegIncr_test.py --tb=long\n</code></pre> <p>Once you have finished the implementation let's rerun the tests:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr/test/RegIncr_test.py -sv\n</code></pre> <p>The <code>-v</code> command line option tells <code>pytest</code> to be more verbose in its output and the <code>-s</code> command line option tells <code>pytest</code> to print out the line tracing. Make sure you understand the line tracing output. You can also dump VCD files using <code>--dump-vcd</code> for waveform debugging with Surfer.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr/test/RegIncr_test.py -sv --dump-vcd\n% code regincr.test.RegIncr_test__test_small_top.verilator1.vcd\n</code></pre> <p>You can also use GTKWave if you prefer to view waveforms, but since GTKWave is a Linux GUI application you will need to use Microsoft Remote Desktop. PyMTL takes care of including all Verilog dependencies into a single Verilog file (also called \"pickling\") suitable for use with the ASIC flow. Take a look at the generated pickled Verilog file.</p> <pre><code>% cd $TOPDIR/sim/build\n% less RegIncr_noparam__pickled.v\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#22-test-the-multi-stage-registered-incrementer","title":"2.2. Test the Multi-Stage Registered Incrementer","text":"<p>Now let's work on composing a single registered incrementer into a multi-stage registered incrementer. We will be using static elaboration to make the multi-stage registered incrementer generic. In other words, our design will be parameterized by the number of stages so we can easily generate a pipeline with one stage, two stages, four stages, etc.</p> <p>Use VS Code to open the implementation and look at the static elaboration logic to instantiate a pipeline of registered incrementers. The Verilog RTL implementation looks as follows:</p> <pre><code>`ifndef TUT3_VERILOG_REGINCR_REG_INCR_NSTAGE_V\n`define TUT3_VERILOG_REGINCR_REG_INCR_NSTAGE_V\n\n`include \"tut3_verilog/regincr/RegIncr.v\"\n\nmodule tut3_verilog_regincr_RegIncrNstage\n#(\n  parameter nstages = 2\n)(\n  input  logic       clk,\n  input  logic       reset,\n  input  logic [7:0] in_,\n  output logic [7:0] out\n);\n\n  // This defines an _array_ of signals. There are p_nstages+1 signals\n  // and each signal is 8 bits wide. We will use this array of\n  // signals to hold the output of each registered incrementer stage.\n\n  logic [7:0] reg_incr_out [nstages+1];\n\n  // Connect the input port of the module to the first signal in the\n  // reg_incr_out signal array.\n\n  assign reg_incr_out[0] = in_;\n\n  // Instantiate the registered incrementers and make the connections\n  // between them using a generate block.\n\n  genvar i;\n  generate\n  for ( i = 0; i &lt; nstages; i = i + 1 ) begin: gen\n\n    tut3_verilog_regincr_RegIncr reg_incr\n    (\n      .clk   (clk),\n      .reset (reset),\n      .in_   (reg_incr_out[i]),\n      .out   (reg_incr_out[i+1])\n    );\n\n  end\n  endgenerate\n\n  // Connect the last signal in the reg_incr_out signal array to the\n  // output port of the module.\n\n  assign out = reg_incr_out[nstages];\n\nendmodule\n\n`endif /* TUT3_VERILOG_REGINCR_REG_INCR_NSTAGE_V */\n</code></pre> <p>Before running the tests, let's take a look at how we are doing the testing in the corresponding test script. Use VS Code to open up <code>RegIncrNstage_test.py</code>. Notice how PyMTL enables sophisticated testing for highly parameterized components. The test script includes directed tests for two and three stage pipelines with various small, large, and random values, and also includes random testing with 1, 2, 3, 4, 5, 6 stages. Writing a similar test harness in Verilog would likely require 10x more code and be significantly more tedious!</p> <p>Let's run all of the tests for the multi-stage registered incrementer.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr/test/RegIncrNstage_test.py -sv\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#23-interactive-simulator-for-multi-stage-registered-incrementer","title":"2.3. Interactive Simulator for Multi-Stage Registered Incrementer","text":"<p>Test scripts are great for verification, but when we want to push a design through the flow we usually want to use an interactive simulator to drive that process. An interactive simulator is meant for evaluting the area, energy, and performance of a design as opposed to verification. We have included a simple interactive simulator called <code>regincr-sim</code> which takes a list of values on the command line and sends these values through the pipeline. Let's see the simulator in action:</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/regincr/regincr-sim -s 0xff 0x20 0x30 0x40 0x00\n</code></pre> <p>The simulator will generate the pickled Verilog file we want to push through the ASIC front-end flow.</p> <pre><code>% cd $TOPDIR/sim/build\n% less RegIncr4stage__pickled.v\n</code></pre> <p>Notice how PyMTL3 has generated a wrapper which picks a specific parameter value for this instance of the multi-stage registered incrementer. The interactive simulator will also generate pure-Verilog test bench with associated test cases which we can use to run four-state RTL and gate-level simulation.</p> <pre><code>% cd $TOPDIR/sim/build\n% less RegIncr4stage_basic_tb.v\n% less RegIncr4stage_basic_tb.v.cases\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#3-synopsys-vcs-for-4-state-rtl-simulation","title":"3. Synopsys VCS for 4-State RTL Simulation","text":"<p>Recall that PyMTL3 simulation of Verilog RTL uses Verilator which is a two-state simulator. To help catch bugs due to uninitialized state (and also just to help verify the design using another Verilog simulator), we can use Synopsys VCS for four-state RTL simulation. This simulator will make use of the Verilog test-bench generated by the <code>--test-verilog</code> and <code>--dump-vtb</code> options from earlier (although we could also write our own Verilog test-bench from scratch). Here is how to run VCS for RTL simulation:</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/01-synopsys-vcs-rtlsim\n% cd $TOPDIR/asic/build-regincr/01-synopsys-vcs-rtlsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${TOPDIR}/sim/build/RegIncr4stage__pickled.v \\\n    ${TOPDIR}/sim/build/RegIncr4stage_basic_tb.v\n</code></pre> <p>You should see a <code>simv</code> binary which is the compiled RTL simulator which you can run like this:</p> <pre><code>% cd $TOPDIR/asic/build-regincr/01-synopsys-vcs-rtlsim\n% ./simv\n</code></pre> <p>It should pass the test. Now let's look at the resulting waveforms with Surfer.</p> <pre><code>% code waves.vcd\n</code></pre> <p>You can also use GTKWave if you prefer to view waveforms, but since GTKWave is a Linux GUI application you will need to use Microsoft Remote Desktop. Browse the signal hierarchy and view the waveforms for one of the four registered incrementers. Note how the signals are initialized to X and only become 0 or 1 after a few cycles once we come out of reset. If we improperly used an initialized value then we would see X-propagation which would hopefully cause a failing test case.</p>"},{"location":"ece6745-sec01-asic-front-end/#4-synopsys-design-compiler-for-synthesis","title":"4. Synopsys Design Compiler for Synthesis","text":"<p>We use Synopsys Design Compiler (DC) to synthesize Verilog RTL models into a gate-level netlist where all of the gates are from the standard cell library. So Synopsys DC will synthesize the Verilog + operator into a specific arithmetic block at the gate-level. Based on various constraints it may synthesize a ripple-carry adder, a carry-look-ahead adder, or even more advanced parallel-prefix adders.</p> <p>We start by creating a subdirectory for our work, and then launching Synopsys DC.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/02-synopsys-dc-synth\n% cd $TOPDIR/asic/build-regincr/02-synopsys-dc-synth\n% dc_shell-xg-t\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#41-initial-setup","title":"4.1. Initial Setup","text":"<p>We need to set two variables before starting to work in Synopsys DC. These variables tell Synopsys DC the location of the standard cell library <code>.db</code> file which is just a binary version of the <code>.lib</code> file we saw earlier.</p> <pre><code>dc_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\ndc_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#42-analyze-and-elaborate-the-design","title":"4.2. Analyze and Elaborate the Design","text":"<p>We are now ready to read in the Verilog file which contains the top-level design and all referenced modules. We do this with two commands. The analyze command reads the Verilog RTL into an intermediate internal representation. The elaborate command recursively resolves all of the module references starting from the top-level module, and also infers various registers and/or advanced data-path components.</p> <pre><code>dc_shell&gt; analyze -format sverilog ../../../sim/build/RegIncr4stage__pickled.v\ndc_shell&gt; elaborate RegIncr4stage\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#43-create-timing-constraints","title":"4.3. Create Timing Constraints","text":"<p>We now need to create a clock constraint to tell Synopsys DC what our target cycle time is:</p> <pre><code>dc_shell&gt; create_clock clk -name ideal_clock1 -period 1\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#44-synthesize-the-design","title":"4.4. Synthesize the Design","text":"<p>Finaly, the <code>compile</code> comamnd will do the actual logic synthesis:</p> <pre><code>dc_shell&gt; compile\n</code></pre>"},{"location":"ece6745-sec01-asic-front-end/#45-write-final-outputs-and-reports","title":"4.5. Write Final Outputs and Reports","text":"<p>We write the output to a <code>.ddc</code> file which we can use with Synopsys DV and a Verilog gate-level netlist.</p> <pre><code>dc_shell&gt; write -format ddc     -hierarchy -output post-synth.ddc\ndc_shell&gt; write -format verilog -hierarchy -output post-synth.v\n</code></pre> <p>We can also generate usful reports about area and timing. Prof. Batten will spend some time explaining these reports:</p> <pre><code>dc_shell&gt; report_area   -hierarchy\ndc_shell&gt; report_timing -nets\n</code></pre> <p>Make some notes about what you find. Note the total cell area used in this design. Finally, we go ahead and exit Synopsys DC.</p> <pre><code>dc_shell&gt; exit\n</code></pre> <p>Take a few minutes to examine the resulting Verilog gate-level netlist. Notice that the module hierarchy is preserved.</p> <pre><code>% less post-synth.v\n</code></pre> <p>Take a close look at the implementation of the incrementer. What kind of standard cells has the synthesis tool chosen? What kind of adder microarchitecture?</p>"},{"location":"ece6745-sec01-asic-front-end/#46-synopsys-design-vision","title":"4.6. Synopsys Design Vision","text":"<p>We can use the Synopsys Design Vision (DV) tool for browsing the resulting gate-level netlist, plotting critical path histograms, and generally analyzing our design. Start Synopsys DV and setup the <code>target_library</code> and <code>link_library</code> variables as before. Note that since Synsopsy DV is a Linux GUI application you will need to use Microsoft Remote Desktop.</p> <pre><code>% design_vision-xg\ndesign_vision&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\ndesign_vision&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>You can use the following steps to open the <code>.ddc</code> file generated during synthesis.</p> <ul> <li>Choose File &gt; Read from the menu</li> <li>Open the <code>post-synth.dcc</code> file</li> </ul> <p>You can use the following steps to view the gate-level schematic for the design.:</p> <ul> <li>Select the <code>RegIncr4stage</code> module in the Logical Hierarchy panel</li> <li>Choose Select &gt; Cells &gt; Leaf Cells of Selected Cells from the menu</li> <li>Choose Schematic &gt; New Schematic View from the menu</li> <li>Choose Select &gt; Clear from the menu</li> </ul> <p>You can use the Logical Hierarchy browser to highlight modules in the schematic view. If you click on the drop down you can choose Cells (All) instead of Cells (Hierarchical) to browse the standard cells as well. You can determine the type of module or gate by selecting the module or gate and choosing Edit &gt; Properties from the menu. Then look for <code>ref_name</code>. You should be able to see the schematic for eaech stage of the pipline including the flip-flops and and the add module. See if you can figure out why the synthesis tool has inserted AND gates in front of each flip-flop. If you look inside the <code>add</code> module you should be able to see the adder microarchitecture.</p> <p>You can use the following steps to view a histogram of path slack, and also to open a gave-level schematic of just the critical path.</p> <ul> <li>Choose Timing &gt; Path Slack from the menu</li> <li>Click OK in the pop-up window</li> <li>Select the left-most bar in the histogram to see list of most critical paths</li> <li>Select one of the paths in the path list to highlight the path in the schematic view</li> </ul>"},{"location":"ece6745-sec01-asic-front-end/#5-synopsys-vcs-for-fast-functional-gate-level-simulation","title":"5. Synopsys VCS for Fast-Functional Gate-Level Simulation","text":"<p>Good ASIC designers are always paranoid and never trust their tools. How do we know that the synthesized gate-level netlist is correct? One way we can check is to rerun our test suite on the gate-level model. We can do this using Synopsys VCS for fast-functional gatel-level simulation. Fast-functional refers to the fact that this simulation will not take account any of the gate delays. All gates will take zero time and all signals will still change on the rising clock edge just like in RTL simulation. Here is how to run VCS for RTL simulation.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/03-synopsys-vcs-ffglsim\n% cd $TOPDIR/asic/build-regincr/03-synopsys-vcs-ffglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top\\\n    +delay_mode_zero \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../02-synopsys-dc-synth/post-synth.v \\\n    ${TOPDIR}/sim/build/RegIncr4stage_basic_tb.v\n</code></pre> <p>The key difference from four-state RTL simulation is that this simulation takes as input the Verilog for the standard-cell library and the Verilog for the post-synthesis gate-level netlist. You should see a <code>simv</code> binary which is the compiled RTL simulator which you can run as follows.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/03-synopsys-vcs-ffglsim\n% ./simv\n</code></pre> <p>It should pass the test. Now let's look at the resulting waveforms using Surfer.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/03-synopsys-vcs-ffglsim\n% code waves.vcd\n</code></pre> <p>You can also use GTKWave if you prefer to view waveforms, but since GTKWave is a Linux GUI application you will need to use Microsoft Remote Desktop. Browse the signal hierarchy and display all the waveforms for a subset of the gate-level netlist using these steps:</p> <ul> <li>Expand out the Scopes panel until you find an add module</li> <li>Click on the _add_module</li> <li>Click the + button in the Variables panel</li> </ul> <p>Notice how we can see all of the single-bit signals corresponding to each gate in the gate-level netlist, and how these signals all change without any delays.</p>"},{"location":"ece6745-sec02-asic-back-end/","title":"ECE 6745 Section 2: ASIC Back-End Flow","text":"<p>In this section, we will be discussing the back-end of the ASIC toolflow. More detailed tutorials will be posted on the public course website, but this section will at least give you a chance to take a gate-level netlist through place-and-route, simulate the final gate-level netlist, and energy analysis. The following diagram illustrates the tool flow we will be using in ECE 6745. Notice that the Synopsys and Cadence ASIC tools all require various views from the standard-cell library which part of the ASIC design kit (ADK).</p> <p></p> <p>The \"back-end\" of the flow is highlighted in red and refers to the PyMTL simulator, Synopsys DC, and Synopsys VCS:</p> <ul> <li> <p>We use Cadence Innovus to place-and-route our design, which means    to place all of the gates in the gate-level netlist into rows on the    chip and then to generate the metal wires that connect all of the    gates together. We need to provide Cadence Innovus with similar    abstract logical and timing views used in Synopsys DC. Cadence Innovus    takes as input the <code>.lib</code> file which is the ASCII text version of a    <code>.db</code> file. In addition, we need to provide Cadence Innovus with    technology information in <code>.lef</code> and <code>.captable</code> format and abstract    physical views of the standard-cell library in <code>.lef</code> format. Cadence    Innovus will generate an updated Verilog gate-level netlist, a <code>.spef</code>    file which contains parasitic resistance/capacitance information about    all nets in the design, and a <code>.gds</code> file which contains the final    layout. The <code>.gds</code> file can be inspected using the open-source Klayout    GDS viewer. Cadence Innovus also generates reports which can be used    to accurately characterize area and timing.</p> </li> <li> <p>We use Synopsys VCS for back-annotated gate-level simulation.    Gate-level simulation involves simulating every standard-cell gate and    helps verify that the Verilog gate-level netlist is functionally    correct. Fast-functional gate-level simulation does not include any    timing information, while back-annotated gate-levle simulation does    include the estimated delay of every gate and every wire.</p> </li> <li> <p>We use Synopsys PrimeTime (PT) to perform power-analysis of our    design. This requires switching activity information for every net in    the design (which comes from the back-annotated gate-level simulation)    and parasitic capacitance information for every net in the design    (which comes from Cadence Innovus). Synopsys PT puts the switching    activity, capacitance, clock frequency, and voltage together to    estimate the power consumption of every net and thus every module in    the design.</p> </li> </ul> <p>Extensive documentation is provided by Synopsys and Cadence. We have organized this documentation and made it available to you on the Canvas course page:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use Microsoft Remote Desktop to log into a specific <code>ecelinux</code> server. Then use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone https://github.com/cornell-ece6745/ece6745-sec02-asic-back-end sec02\n% cd sec02\n% TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-sec02-asic-back-end/#1-nangate-45nm-standard-cell-libraries","title":"1. NanGate 45nm Standard-Cell Libraries","text":"<p>Recall that a standard-cell library is a collection of combinational and sequential logic gates that adhere to a standardized set of logical, electrical, and physical policies. For example, all standard cells are usually the same height, include pins that align to a predetermined vertical and horizontal grid, include power/ground rails and nwells in predetermined locations, and support a predetermined number of drive strengths. In this course, we will be using the a NanGate 45nm standard-cell library. It is based on a \"fake\" 45nm technology. This means you cannot actually tapeout a design using this standard cell library, but the technology is representative enough to provide reasonable area, energy, and timing estimates for teaching purposes. All of the files associated with this standard cell library are located in the <code>$ECE6745_STDCELLS</code> directory.</p> <p>Let's look at some layout for the standard cell library just like we did in the last section.</p> <pre><code>% klayout -l ${ECE6745_STDCELLS}/klayout.lyp ${ECE6745_STDCELLS}/stdcells.gds\n</code></pre> <p>Let's look at a 3-input NAND cell, find the NAND3_X1 cell in the left-hand cell list, and then choose Display &gt; Show as New Top from the menu. We will learn more about layout and how this layout corresponds to a static CMOS circuit later in the course. The key point is that the layout for the standard cells are the basic building blocks that we will be using to create our ASIC chips.</p> <p>The Synopsys and Cadence tools do not actually use this layout directly; it is actually too detailed. Instead these tools use abstract views of the standard cells, which capture logical functionality, timing, geometry, and power usage at a much higher level. In the last section, we looked at Verilog and <code>.lib</code> views. The back-end flow takes as input the <code>.lib</code> view for logical timing information, but it also takes as input a <code>.lef</code> view which contains physical information about the standard cell. Let's look at the LEF for the 3-input NAND cell.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.lef\n</code></pre> <p>The <code>.lef</code> view includes information about the size of the standard cell, but also includes information about where every pin is physically located. You can use Klayout to view <code>.lef</code> files as well. Start Klayout like this:</p> <pre><code>% klayout ${ECE6745_STDCELLS}/stdcells.lef\n</code></pre> <p>Let's look at a 3-input NAND cell, find the NAND3_X1 cell in the left-hand cell list, and then choose Display &gt; Show as New Top from the menu. The <code>.lef</code> file does not contain any transistor-level information. It only contains information relevant to placement and routing.</p> <p>In addition to physical information about each standard cell, the back-end flow also needs to take as input general information about the technology. This information is contained in two files:</p> <pre><code>% less ${ECE6745_STDCELLS}/rtk-tech.lef\n% less ${ECE6745_STDCELLS}/rtk-typical.captable\n</code></pre> <p>The first provides information about the geometry and orientation of wires for each metal layer. The second provides information about the resistance and capacitance of each metal layer.</p> <p>Now that we have looked at the physical views of the standard cell library, we can now try using these views and the ASIC flow back-end to place and route a gate-level netlist.</p>"},{"location":"ece6745-sec02-asic-back-end/#2-revisiting-the-asic-flow-front-end","title":"2. Revisiting the ASIC Flow Front-End","text":"<p>As in the last section, we will be using the following four-stage registered incrementer as our example design:</p> <p></p> <p>Before we can place and route a gate-level netlist, we need to synthesize that netlist. This is what we learned about in the last section. Here are the steps to test and then synthesize the design using Synopsys DC.</p>"},{"location":"ece6745-sec02-asic-back-end/#21-test-simulate-translate","title":"2.1. Test, Simulate, Translate","text":"<p>Always run the tests before pushing anything through the ASIC flow. There is no sense in running the flow if the design is incorrect!</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr\n</code></pre> <p>You can run the simulator for our four-stage registered incrementer like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/regincr/regincr-sim -s 0xff 0x20 0x30 0x04 0x00\n% less RegIncr4stage__pickled.v\n</code></pre> <p>You should now have the Verilog that we want to push through the ASIC flow.</p>"},{"location":"ece6745-sec02-asic-back-end/#22-simulate-synthesize-simulate","title":"2.2. Simulate, Synthesize, Simulate","text":"<p>We have provided you run scripts that will reproduce the three key steps we learned about in the previous discussion section:</p> <ul> <li>Use Synopsys VCS for four-state RTL simulation</li> <li>Use Synopsys DC to synthesize RTL to gate-level netlist</li> <li>Use Synopsys VCS for fast-functional gate-level simulation</li> </ul> <p>Let's take a look at each script to confirm it matches the manual commands we used in the previous discussion section. Here is the run script for four-start RTL simulation.</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% cat ./01-synopsys-vcs-rtlsim/run\n</code></pre> <p>Here is the run script for synthesis.</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% cat ./02-synopsys-dc-synth/run\n</code></pre> <p>Notice that this script simply executes <code>dc_shell-xg-t</code> with a TCL script which contains the commands to: configure the standard cell library, analyze and elaborate the design; setup timing constraints; synthesize the design; write outputs; and write final outputs (i.e., Verilog and DDC) and reports (i.e., timing report and area report).</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% cat ./02-synopsys-dc-synth/run.tcl\n</code></pre> <p>Finally, here is the run script for fast-functional gate-level simulation. The key difference from four-state RTL simulation is that this simulation takes as input the Verilog for the standard-cell library and the Verilog for the post-synthesis gate-level netlist.</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% cat ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>You can run these steps as follows:</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>Verify that your design passes four-state RTL simulation and fast-functional gate-level simulation. Then take a look at the synthesis reports.</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% less ./02-synopsys-dc-synth/area.rpt\n% less ./02-synopsys-dc-synth/timing.rpt\n</code></pre> <p>Finally, take a few minutes to examine the resulting Verilog gate-level netlist. Notice that the module hierarchy is preserved.</p> <pre><code>% cd $TOPDIR/asic/build-regincr\n% less ./02-synopsys-dc-synth/post-synth.v\n</code></pre> <p>This is the gate-level netlist that we now want to push through the ASIC back-end flow.</p>"},{"location":"ece6745-sec02-asic-back-end/#3-cadence-innovus-for-place-and-route","title":"3. Cadence Innovus for Place-and-Route","text":"<p>We will be running Cadence Innovus in a separate directory to keep the input and output files separate.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n% cd $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n</code></pre>"},{"location":"ece6745-sec02-asic-back-end/#31-constraint-and-timing-input-files","title":"3.1. Constraint and Timing Input Files","text":"<p>Before starting Cadence Innovus, we need to create two files which will be loaded into the tool. The first file is a <code>.sdc</code> file which contains timing constraint information about our design. This file is where we specify our target clock period, but it is also where we could specify input or output delay constraints (e.g., the output signals must be stable 200ps before the rising edge). Use VS Code to create a file named <code>constraints.sdc</code>.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n% code constraints.sdc\n</code></pre> <p>The file should have the following constraint:</p> <pre><code>create_clock clk -name ideal_clock -period 1\n</code></pre> <p>The <code>create_clock</code> command is similar to the command we used in synthesis, and usually, we use the same target clock period that we used for synthesis. In this case, we are targeting a 1GHz clock frequency (i.e., a 1ns clock period).</p> <p>The second file is a \"multi-mode multi-corner\" (MMMC) analysis file. This file specifies what \"corner\" to use for our timing analysis. A corner is a characterization of the standard cell library and technology with specific assumptions about the process temperature, and voltage (PVT). So we might have a \"fast\" corner which assumes best-case process variability, low temperature, and high voltage, or we might have a \"slow\" corner which assumes worst-case variability, high temperature, and low voltage. To ensure our design worked across a range of operating conditions, we need to evaluate our design across a range of corners. In this course, we will keep things simple by only considering a \"typical\" corner (i.e., average PVT). Use VS Code to create a file named <code>setup-timing.tcl</code>.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n% code setup-timing.tcl\n</code></pre> <p>The file should have the following content:</p> <pre><code>create_rc_corner -name typical \\\n   -cap_table \"$env(ECE6745_STDCELLS)/rtk-typical.captable\" \\\n   -T 25\n\ncreate_library_set -name libs_typical \\\n   -timing [list \"$env(ECE6745_STDCELLS)/stdcells.lib\"]\n\ncreate_delay_corner -name delay_default \\\n   -library_set libs_typical \\\n   -rc_corner typical\n\ncreate_constraint_mode -name constraints_default \\\n   -sdc_files [list constraints.sdc]\n\ncreate_analysis_view -name analysis_default \\\n   -constraint_mode constraints_default \\\n   -delay_corner delay_default\n\nset_analysis_view -setup analysis_default -hold  analysis_default\n</code></pre> <p>The <code>create_rc_corner</code> command loads in the <code>.captable</code> file that we examined earlier. This file includes information about the resistance and capacitance of every metal layer. Notice that we are loading in the \"typical\" captable and we are specifying an \"average\" operating temperature of 25 degC. The <code>create_library_set</code> command loads in the <code>.lib</code> file that we examined in the last section. This file includes information about the input/output capacitance of each pin in each standard cell along with the delay from every input to every output in the standard cell. The <code>create_delay_corner</code> specifies a specific corner that we would like to use for our timing analysis by putting together a <code>.captable</code> and a <code>.lib</code> file. In this specific example, we are creating a typical corner by putting together the typical <code>.captable</code> and typical <code>.lib</code> we just loaded. The <code>create_constraint_mode</code> command loads in the <code>.sdc</code> file we mentioned earlier in this section. The <code>create_analysis_view</code> command puts together constraints with a specific corner, and the <code>set_analysis_view</code> command tells Cadence Innovus that we would like to use this specific analysis view for both setup and hold time analysis.</p>"},{"location":"ece6745-sec02-asic-back-end/#32-initial-setup-and-floorplanning","title":"3.2. Initial Setup and Floorplanning","text":"<p>Now that we have created our <code>constraints.sdc</code> and <code>setup-timing.tcl</code> files we can start Cadence Innovus. Note that we are using the Cadence Innovus GUI so you will need to use Microsoft Remote Desktop.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n% innovus\n</code></pre> <p>We can enter commands in the terminal and watch the effect of these commands on our design in the GUI. We need to set various variables before starting to work in Cadence Innovus. These variables tell Cadence Innovus the location of the MMMC file, the location of the Verilog gate-level netlist, the name of the top-level module in our design, the location of the <code>.lef</code> files, and finally the names of the power and ground nets.</p> <pre><code>innovus&gt; set init_mmmc_file \"setup-timing.tcl\"\ninnovus&gt; set init_verilog   \"../02-synopsys-dc-synth/post-synth.v\"\ninnovus&gt; set init_top_cell  \"RegIncr4stage\"\ninnovus&gt; set init_lef_file  \"$env(ECE6745_STDCELLS)/rtk-tech.lef $env(ECE6745_STDCELLS)/stdcells.lef\"\ninnovus&gt; set init_gnd_net   \"VSS\"\ninnovus&gt; set init_pwr_net   \"VDD\"\n</code></pre> <p>We can now use the <code>init_design</code> command to read in the verilog, set the design name, setup the timing analysis views, read the technology <code>.lef</code> for layer information, and read the standard cell <code>.lef</code> for physical information about each cell used in the design.</p> <pre><code>innovus&gt; init_design\n</code></pre> <p>We start by working on power planning which is the process of routing the power and ground signals across the chip. First, we use the <code>floorPlan</code> command to set the dimensions for our chip.</p> <pre><code>innovus&gt; floorPlan -su 1.0 0.70 4.0 4.0 4.0 4.0\n</code></pre> <p>In this example, we have chosen the aspect ration to be 1.0, the target cell utilization to be 0.7, and we have added 4.0um of margin around the top, bottom, left, and right of the chip. This margin gives us room for the power ring which will go around the entire chip.</p>"},{"location":"ece6745-sec02-asic-back-end/#33-placement","title":"3.3. Placement","text":"<p>The first step is to place all of the standard cells and perform a very preliminary routing using the <code>place_design</code> command:</p> <pre><code>innovus&gt; place_design\n</code></pre> <p>You should be able to see the standard cells placed in the rows along with preliminary routing to connect all of the standard cells together. You can toggle the visibility of metal layers by pressing the number keys on the keyboard. So try toggling the visibility of M1, M2, M3, etc. You can visualize how the modules in the original Verilog mapped to the place-and-routed design by using the Design Browser. Choose the Windows &gt; Workspaces &gt; Design Browser + Physical menu option. Then use the Design Browser to click on specific modules or nets to highlight them in the physical view.</p>"},{"location":"ece6745-sec02-asic-back-end/#34-power-routing","title":"3.4. Power Routing","text":"<p>Now we need to tell Cadence Innovus that <code>VDD</code> and <code>VSS</code> in the gate-level netlist correspond to the physical pins labeled <code>VDD</code> and <code>VSS</code> in the <code>.lef</code> files.</p> <pre><code>innovus&gt; globalNetConnect VDD -type pgpin -pin VDD -inst * -verbose\ninnovus&gt; globalNetConnect VSS -type pgpin -pin VSS -inst * -verbose\n</code></pre> <p>For this discussion section we will just draw M1 wires for the power and ground rails that go along each row of standard cells.</p> <pre><code>innovus&gt; sroute -nets {VDD VSS}\n</code></pre> <p>In a more realistic flow we would also create a power ring and connect the rows of standard cells to this power ring.</p>"},{"location":"ece6745-sec02-asic-back-end/#35-signal-routing","title":"3.5. Signal Routing","text":"<p>The <code>place_design</code> command will perform a very preliminary route to help ensure a good placement, but we will now use the <code>routeDesign</code> command to do a more detailed routing pass.</p> <pre><code>innovus&gt; routeDesign\n</code></pre> <p>Watch the physical view to see the result before and after running this command. You should be able to appreciate that the final result requires fewer and shorter wires.</p> <p>Now that our design is fully placed and routed, we can extract the parasitic resistance and capacitances to enable more accurate timing and power analysis.</p> <pre><code>innovus&gt; extractRC\n</code></pre>"},{"location":"ece6745-sec02-asic-back-end/#36-final-output-and-reports","title":"3.6. Final Output and Reports","text":"<p>The final step is to insert \"filler\" cells. Filler cells are essentially empty standard cells whose sole purpose is to connect the wells across each standard cell row.</p> <pre><code>innovus&gt; setFillerMode -core {FILLCELL_X4 FILLCELL_X2 FILLCELL_X1}\ninnovus&gt; addFiller\n</code></pre> <p>Now we are basically done! Obviously there are many more steps required before you can really tape out a chip. We would need to add a real power grid and an I/O ring to connect the chip to the package. We would need to do further verification and additional optimization.</p> <p>We can generate various artifacts. We might want to save the final gate-level netlist for the chip since Cadence Innovus will often insert new cells or change cells during its optimization passes.</p> <pre><code>innovus&gt; saveNetlist post-pnr.v\n</code></pre> <p>We can write parasitic information to a special <code>.spef</code> file and all of the delay information (including interconnect delays) to a <code>.sdf</code> file. These files can be used for later back-annotated gate-level simulation and/or power analysis.</p> <pre><code>innovus&gt; rcOut -rc_corner typical -spef post-pnr.spef\ninnovus&gt; write_sdf post-pnr.sdf\n</code></pre> <p>And of course the step is to generate the real layout as a <code>.gds</code> file. This is what we will send to the foundry when we are ready to tapeout the chip.</p> <pre><code>innovus&gt; streamOut post-pnr.gds \\\n  -merge \"$env(ECE6745_STDCELLS)/stdcells.gds\" \\\n  -mapFile \"$env(ECE6745_STDCELLS)/rtk-stream-out.map\"\n</code></pre> <p>We can also use Cadence Innovus to do timing and area analysis similar to what we did with Synopsys DC. These post-place-and-route results will be much more accurate than the preliminary post-synthesis results.</p> <pre><code>innovus&gt; report_timing -late  -path_type full_clock -net\ninnovus&gt; report_timing -early -path_type full_clock -net\ninnovus&gt; report_area\n</code></pre> <p>Finally, we go ahead and exit Cadence Innovus.</p> <pre><code>innovus&gt; exit\n</code></pre> <p>Open the final layout using Klayout.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/04-cadence-innovus-pnr\n% klayout -l ${ECE6745_STDCELLS}/klayout.lyp post-pnr.gds\n</code></pre> <p>Choose Display &gt; Full Hierarchy from the menu to display the entire design. Zoom in and out to see the individual transistors as well as the entire block.</p>"},{"location":"ece6745-sec02-asic-back-end/#4-synopsys-vcs-for-back-annotated-gate-level-simulation","title":"4. Synopsys VCS for Back-Annotated Gate-Level Simulation","text":"<p>As we learned in the last discussion section, good ASIC designers are always paranoid and never trust their tools. How do we know that the final post-place-and-route gate-level netlist is correct? Once again, we can rerun our test suite on the gate-level model. We can do this using Synopsys VCS for back-annotated gatel-level simulation. Back-annotated refers to the fact that this simulation will take into account all of the gate and interconnect delays. So this also helps build our confidence not just that the final gate-level netlist is functionally correct, but also that it meets all setup and hold time constraints. Here is how to run VCS for RTL simulation:</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% cd $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +neg_tchk +sdfverbose \\\n    -sdf max:Top.DUT:../04-cadence-innovus-pnr/post-pnr.sdf \\\n    +define+CYCLE_TIME=1.000 \\\n    +define+VTB_INPUT_DELAY=0.025 \\\n    +define+VTB_OUTPUT_DELAY=0.025 \\\n    +define+VTB_DUMP_SAIF=waves.saif \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+$TOPDIR/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../04-cadence-innovus-pnr/post-pnr.v \\\n    ${TOPDIR}/sim/build/RegIncr4stage_basic_tb.v\n</code></pre> <p>You should see a <code>simv</code> binary which is the compiled RTL simulator which you can run like this:</p> <pre><code>% cd $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% ./simv\n</code></pre> <p>It should pass the test and also dump out an SAIF file which has the activity factors for every net in the design. We will use the SAIF file in power analysis. Now let's look at the resulting waveforms using Surfer.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% code waves.vcd\n</code></pre> <p>Browse the signal hierarchy and display all the waveforms for the DUT using these steps:</p> <ul> <li>Expand out the Scopes until you find the DUT module</li> <li>Select the clk, in, out signals</li> <li>Expand out the Scopes until you find the <code>gen[0].reg_incr.add</code> module</li> <li>Select all of the signals in this adder</li> </ul> <p>Zoom in and notice how the signals now change throughout the cycle. This is because the delay of every gate and wire is now modeled. Let's rerun the simulation, but this time let's use a very fast clock frequency (much faster than the 1ns clock constraint we used during synthesis and place-and-route).</p> <pre><code>% cd $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +neg_tchk +sdfverbose \\\n    -sdf max:Top.DUT:../04-cadence-innovus-pnr/post-pnr.sdf \\\n    +define+CYCLE_TIME=0.300 \\\n    +define+VTB_INPUT_DELAY=0.025 \\\n    +define+VTB_OUTPUT_DELAY=0.025 \\\n    +vcs+dumpvars+waves-300ps.vcd \\\n    +incdir+$TOPDIR/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../04-cadence-innovus-pnr/post-pnr.v \\\n    ${TOPDIR}/sim/build/RegIncr4stage_basic_tb.v\n% ./simv\n</code></pre> <p>You should see timing violations and the test will fail. If you look at the resulting waveforms you can see that the adder does not have time to finish its calculation and cannot meet the setup time contraint.</p> <pre><code>% cd $TOPDIR/asic/build-regincr/05-synopsys-vcs-baglsim\n% code waves-300ps.vcd\n</code></pre>"},{"location":"ece6745-sec02-asic-back-end/#5-synopsys-primetime-for-power-analysis","title":"5. Synopsys PrimeTime for Power Analysis","text":"<p>Synopsys PrimeTime (PT) is primarily used for very accurate \"sign-off\" static timing analysis (more accurate than the analysis performed by Synopsys DC and Cadence Innovus), but in this course, we will only use Synopsys PT for power analysis. There are many ways to perform power analysis. Synthesis and place-and-route power reports use statistical power analysis where we simply assume some toggle probability on each net. For more accurate power analysis, we need to find out the actual activity for every net for a given experiment; this is exactly what we figured out during back-annotated gate-level simulation.</p> <p>We start by creating a subdirectory for our work and then launching Synopsys PT.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-regincr/06-synopsys-pt-pwr\n% cd $TOPDIR/asic/build-regincr/06-synopsys-pt-pwr\n% pt_shell\n</code></pre> <p>We begin by setting the <code>target_library</code> and <code>link_library</code> variables as before.</p> <pre><code>pt_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\npt_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>Since Synopsys PT is primarily used for static timing analysis, we need to explicitly tell Synopsys PT that we want to use it for power analysis.</p> <pre><code>pt_shell&gt; set_app_var power_enable_analysis true\n</code></pre> <p>We now read in the gate-level netlist, tell Synopsys PT we want to do power analysis for the top-level module, and link the design (i.e., recursively resolve all of the module references starting from the top-level module).</p> <pre><code>pt_shell&gt; read_verilog   \"../04-cadence-innovus-pnr/post-pnr.v\"\npt_shell&gt; current_design RegIncr4stage\npt_shell&gt; link_design\n</code></pre> <p>In order to do power analysis, Synopsys PT needs to know the clock period. Here we will set the clock frequency to be the same as the initial clock constraint.</p> <pre><code>pt_shell&gt; create_clock clk -name ideal_clock1 -period 1\n</code></pre> <p>We now read in the SAIF file with the activity factors and the SPEF file with the parasitic cpacitances for every net in our design.</p> <pre><code>pt_shell&gt; read_saif \"../05-synopsys-vcs-baglsim/waves.saif\" -strip_path \"Top/DUT\"\npt_shell&gt; read_parasitics -format spef \"../04-cadence-innovus-pnr/post-pnr.spef\"\n</code></pre> <p>We now have everything we need to perform the power analysis: (1) the activity factor of a subset set of the nets, (2) the capacitance of every net/port, (3) the supply voltage, and (4) the clock frequency. We use the <code>update_power</code> command to propagate activity factors to unannotated nest and to estimate the power of our design.</p> <pre><code>pt_shell&gt; update_power\n</code></pre> <p>We can use the <code>report_power</code> command to show a high-level overview of how much power the sort unit consumes as well as how much each module in our design consumes.</p> <pre><code>pt_shell&gt; report_power\npt_shell&gt; report_power -hierarchy\n</code></pre> <p>Finally, we go ahead and exit Synopsys PT.</p> <pre><code>pt_shell&gt; exit\n</code></pre>"},{"location":"ece6745-sec03-asic-auto/","title":"ECE 6745 Section 3: ASIC Automated Flow","text":"<p>In the previous sections, we manually commands entering commands for each tool to take a design from RTL to layout. Flow scripts can help automate the process but copying and modifying these flow scripts for every design is tedious and error prone. An agile hardware design flow demands automation to simplify rapidly exploring the area, energy, timing design space of one or more designs. In this section, we will introduce a simple tool called pyhflow which takes as input a step templates and a design YAML and generates appropriate flow scripts.</p> <p>The following diagram illustrates the five primary tools we have already seen in the previous discussion sections. Notice that the ASIC tools all require various views from the standard-cell library.</p> <p></p> <p>Extensive documentation is provided by Synopsys and Cadence for these ASIC tools. We have organized this documentation and made it available to you on the public course webpage:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use Microsoft Remote Desktop to log into a specific <code>ecelinux</code> server. Then use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-sec03-asic-auto sec03\n% cd sec03\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-sec03-asic-auto/#1-testing-simulation-and-translation","title":"1. Testing, Simulation, and Translation","text":"<p>As in the last section, we will be using the following four-stage registered incrementer as our example design:</p> <p></p> <p>Before we can use the ASIC flow, we need to verify the design and generate the corresponding Verilog files for each test which can be used for RTL simulation, fast-functional gate-level simulation, and back-annotated gate-level simulation. Always run the tests before pushing anything through the ASIC flow. There is no sense in running the flow if the design is incorrect!</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/regincr  --test-verilog --dump-vtb\n</code></pre> <p>You can run the interactive simulator for our four-stage registered incrementer like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/regincr/regincr-sim 0xff 0x20 0x30 0x04 0x00\n% less RegIncrNstage__p_nstages_4__pickled.v\n</code></pre> <p>You should now have the Verilog that we want to push through the ASIC flow.</p>"},{"location":"ece6745-sec03-asic-auto/#2-pyhflow-for-generating-flows","title":"2. pyhflow For Generating Flows","text":"<p>pyflow is based on the idea of step templates which are located in the <code>asic/steps</code> directory.</p> <pre><code>% cd $TOPDIR/asic/steps\n% tree\n.\n\u251c\u2500\u2500 01-synopsys-vcs-rtlsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 02-synopsys-dc-synth\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u2514\u2500\u2500 run.tcl\n\u251c\u2500\u2500 03-synopsys-vcs-ffglsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 04-cadence-innovus-pnr\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u251c\u2500\u2500 run.tcl\n\u2502   \u2514\u2500\u2500 setup-timing.tcl\n\u251c\u2500\u2500 05-synopsys-vcs-baglsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 06-synopsys-pt-pwr\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u2514\u2500\u2500 run.tcl\n\u2514\u2500\u2500 07-summarize-results\n    \u251c\u2500\u2500 run\n    \u2514\u2500\u2500 summarize-results\n</code></pre> <p>Each step is a directory with a run script and possibly other scripts. The key difference from the scripts we used in the previous tutorials, is that these scripts are templated using the Jinja2 templating system:</p> <ul> <li>https://jinja.palletsprojects.com</li> </ul> <p>Open the <code>run.tcl</code> script in the <code>02-synopsys-dc-synth</code> step template which uses Synopsys DC for synthesis.</p> <pre><code>% cd $TOPDIR/asic/steps/02-synopsys-dc-synth\n% code run.tcl\n</code></pre> <p>Notice how the <code>run.tcl</code> script is templated based on the design name and the target clock period.</p> <pre><code>analyze -format sverilog $env(TOPDIR)/sim/build/{{design_name}}__pickled.v\nelaborate {{design_name}}\n\ncreate_clock clk -name ideal_clock1 -period {{clock_period}}\n</code></pre> <p>The <code>{{ }}</code> directive is the standard syntax for template variable substitution using Jinja2.</p> <p>The pyhflow program takes as input a design YAML file which specifies:</p> <ul> <li>what steps make up the flow</li> <li>key/value pairs for variables to substitute into scripts</li> <li>list of tests</li> <li>list of evals</li> </ul> <p>Take a look at the provided design YAML file for the registered incrementer.</p> <pre><code>% cd $TOPDIR/asic/designs\n% cat sec03-regincr.yml\n\nsteps:\n - 01-synopsys-vcs-rtlsim\n - 02-synopsys-dc-synth\n - 03-synopsys-vcs-ffglsim\n - 04-cadence-innovus-pnr\n - 05-synopsys-vcs-baglsim\n - 06-synopsys-pt-pwr\n - 07-summarize-results\n\nsrc_dir      : ../../../sim/build\ndesign_name  : RegIncrNstage__p_nstages_4\nclock_period : 1.0\ndump_vcd     : true\n\ntests:\n - RegIncrNstage__p_nstages_4_test_4stage_large\n - RegIncrNstage__p_nstages_4_test_4stage_overflow\n - RegIncrNstage__p_nstages_4_test_4stage_random\n - RegIncrNstage__p_nstages_4_test_4stage_small\n\nevals:\n - RegIncrNstage__p_nstages_4_regincr-sim-basic\n</code></pre> <p>This design YAML file specifies the generated flow should use all seven steps. We run RTL sim, FFGL sim, and BAGL sim on all tests and evals, but we only do energy analysis on the evals. The evals usually come from running an interactive simulator like <code>regincr-sim</code>. All pyhflow does is use the YAML file to figure out what to substitute into the templated steps and then copy the run scripts into the current working directory. You can also override parameters on pyhflow command line.</p>"},{"location":"ece6745-sec03-asic-auto/#11-running-asic-flow-with-one-test","title":"1.1. Running ASIC Flow with One Test","text":"<p>Let's go ahead and use pyhflow to generate the flow scripts for the registered incrementer.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sec03-regincr\n% cd $TOPDIR/asic/build-sec03-regincr\n% pyhflow --one-test ../designs/sec03-regincr.yml\n</code></pre> <p>The <code>--one-test</code> command line option tells pyhflow to only include the first test and no evals in the flow scripts. This is a useful way to get started with a single test and reduces the overall runtime of the flow. Once we know that everything works with one test we can circle back and regenerate the flow scripts with all of the tests and evals.</p> <p>Let's see how the step template has been filled in for the Synopsys DC synthesis step.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% cat 02-synopsys-dc-synth/run.tcl\n...\nanalyze -format sverilog $env(TOPDIR)/sim/build/RegIncrNstage__p_nstages_4__pickled.v\nelaborate RegIncrNstage__p_nstages_4\ncreate_clock clk -name ideal_clock1 -period 1.0\n</code></pre> <p>Notice how the name of the source Verilog RTL File, the top-level modulename, and the clock period have all been filled in.</p> <p>After generating a flow, we always recommend explicitly running at least the first two steps to ensure there are no errors. You can run the four-state RTL simulation as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% ./01-synopsys-vcs-rtlsim/run\n</code></pre> <p>Make sure the step can find the source files and passes the test. Then run synthesis as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% ./02-synopsys-dc-synth/run\n</code></pre> <p>Carefully look at the output from the synthesis step (also stored in the <code>run.log</code> file). Look for the output after <code>Running PRESTO HDLC</code> for any warnings to ensure that all of your Verilog RTL is indeed synthesizable. Scan through the rest of the logs to ensure there are no worrying warnings or errors.</p> <p>Once you have explicitly run the first two steps to ensure there are no errors, you can run the remaning steps.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% 03-synopsys-vcs-ffglsim\n% 04-cadence-innovus-pnr\n% 05-synopsys-vcs-baglsim\n% 06-synopsys-pt-pwr\n% 07-summarize-results\n</code></pre> <p>If all looks good, then you would regenerate the with all of the tests and evals; however, we will stick to just running one test though to save time in this discussion section. pyhflow will also create a <code>run-flow</code> script which will run all of the steps in sequence for you, but only use this if you are confident there are no errors!</p> <p>For the results to be valid, the following must be true:</p> <ul> <li>all four-state RTL simulations pass</li> <li>all fast-functional gate-level simulations pass</li> <li>all back-annotated gate-level simulations pass</li> <li>place-and-route setup slack is positive</li> <li>place-and-route hold slack is positive</li> </ul> <p>If your design does not meet timing after synthesis but does meet timing after place-and-route then these are still valid results. It just means Synopsys DC was conservative and/or Cadence Innovus did a good job further optimizing the design.</p>"},{"location":"ece6745-sec03-asic-auto/#13-interactive-debugging","title":"1.3. Interactive Debugging","text":"<p>Let's start Cadence Innovus in interactive mode and then load the design.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% innovus\ninnovus&gt; source 04-cadence-innovus-pnr/post-pnr.enc\n</code></pre> <p>You can use Cadence Innovus to analyze the static timing of any path in the design. For example, let's look at the static timing for a path in the first stage:</p> <pre><code>innovus&gt; report_timing -path_type full_clock -net \\\n  -from v/gen[0].reg_incr/reg_out_reg[0] \\\n  -to v/gen[1].reg_incr/reg_out_reg[0]\n</code></pre> <p>You can use the Amobea workspace to help visualize how modules are mapped across the chip. Choose Windows &gt; Workspaces &gt; Amoeba from the menu. However, we recommend using the design browser to help visualize how modules are mapped across the chip. Here are the steps:</p> <ul> <li>Choose Windows &gt; Workspaces &gt; Design Browser + Physical from the menu</li> <li>Hide all of the metal layers by pressing the number keys</li> <li>Browse the design hierarchy using the panel on the left</li> <li>Right click on a module, click Highlight, select a color</li> </ul> <p>Go ahead and highlight each stage in a different color.</p> <p>You can use the following steps in Cadence Innovus to display where the critical path is on the actual chip.</p> <ul> <li>Choose Timing &gt; Debug Timing from the menu</li> <li>Click OK in the pop-up window</li> <li>Right click on first path in the Path List</li> <li>Choose Highlight &gt; Only This Path &gt; Color</li> </ul> <p>Finally, you can use Klayout to capture a screen shot demonstrating that you have successfully taken a design from RTL to layout.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% klayout -l $ECE6745_STDCELLS/klayout.lyp 04-cadence-innovus-pnr/post-pnr.gds\n</code></pre> <p>You can use Display &gt; Full Hierarchy to show all of the layout including the layout inside the standard cells. You can use Display &gt; Decrement Hierarchy and Display &gt; Decrement Hierarchy to show/hide the layout inside the standard cells to focus on the routing. Consider hiding M7, VIA7, M8, VIA8, and M9 to just show the clock and signal routing. Try toggling View &gt; Show Cell Frames to show/hide the standard cell bounding boxes.</p>"},{"location":"ece6745-sec03-asic-auto/#15-key-reports","title":"1.5. Key Reports","text":"<p>Let's look at some reports. Let's start by looking at the synthesis resources report.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% cat 02-synopsys-dc-synth/resources.rpt\n...\n===============================================================================\n|                    |                  | Current            | Set            |\n| Cell               | Module           | Implementation     | Implementation |\n===============================================================================\n| add_x_1            | DW01_inc         | apparch (area)     |                |\n===============================================================================\n</code></pre> <p>This means that Synopsys DC is using a DesignWare module named <code>DW01_inc</code>. You can read the datasheet here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_datasheets</li> </ul> <p>Notice that DesignWare provides four different microarchitectures: a ripple-carry adder, a carry-look-ahead adder, a delay optimized parallel-prefix adder, and an area-optimized parallel-prefix adder. Synopsys DC has chosen to use the area-optimized parallel-prefix adder in this case.</p> <p>Now let's look at the place-and-route setup and hold time reports.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% cat 04-cadence-innovus-pnr/timing-setup.rpt\n% cat 04-cadence-innovus-pnr/timing-hold.rpt\n</code></pre> <p>We can also look at the detailed area report.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr\n% cat 04-cadence-innovus-pnr/area.rpt\n</code></pre>"},{"location":"ece6745-sec03-asic-auto/#3-case-studies","title":"3. Case Studies","text":"<p>Now that we know how to push a design through the automated flow, let's consider two different case studies: (1) decreasing the clock period constraint; and (2) flattening the design.</p>"},{"location":"ece6745-sec03-asic-auto/#31-decreasing-the-clock-period-constraint","title":"3.1. Decreasing the Clock Period Constraint","text":"<p>We can use pyhflow to regenerate the flow with a different clock period by either: (1) changing the design YAML file (i.e., <code>sec03-regincr.yml</code>); or (2) specifying the clock period on the pyflow command line. Let's use the second approach. If you look at the setup timing report you will see with a 1ns clock period you have maybe 550ps of positive slack. So a good starting point would be to maybe try a clock period of 1ns - 550ps = 450ps. Let's try 400ps.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sec03-regincr-decrease-clk\n% cd $TOPDIR/asic/build-sec03-regincr-decrease-clk\n% pyhflow --one-test --clock_period=0.400 ../designs/sec03-regincr.yml\n% ./run-flow\n</code></pre> <p>Notice how we are working in a new build directory. You can use multiple build directories to build different blocks through the flow and/or for design-space exploration. Also notice how we are using <code>--one-test</code> so we can quickly experiment with pushing the design through the flow with a single test and no evals. You could continue to decrease the clock period in 100ps increments until the design no longer meets timing, but for now we will just stick with the shorter 400ps clock period. Do not be too zealous and push the tools to try and meet a clock period constraint that is way too small! This can cause the tools to freak out and run forever.</p> <p>Now compare the results from the longer and shorter clock periods. Start by looking at the summary statistics. How does the number of standard cells and area compare? We can also look at what kind of adder implementation Synopsys DC chose to meet the shorter clock period constraint.</p> <pre><code>% cd $TOPDIR/asic\n% cat build-sec03-regincr/02-synopsys-dc-synth/resources.rpt\n% cat build-sec03-regincr-decrease-clk/02-synopsys-dc-synth/resources.rpt\n</code></pre> <p>Here we can see Synopsys DC has chosen to use a different version of the parallel-prefix adder which is now optimized for both area and speed.</p> <p>We can also look compare the critical path; you should be able to see that the design with the shorter clock period has many fewer levels of logic on the critical path.</p> <pre><code>% cd $TOPDIR/asic\n% cat build-sec03-regincr/04-cadence-innovus-pnr/timing-setup.rpt\n% cat build-sec03-regincr-decrease-clk/04-cadence-innovus-pnr/timing-setup.rpt\n</code></pre>"},{"location":"ece6745-sec03-asic-auto/#31-flattening-the-design","title":"3.1. Flattening the Design","text":"<p>Let's modify our scripts to flatten our design and see how this impacts various metrics. We can run pyhflow to instantiate the flow scripts and then modify these flow scripts in the build directory. Use the shortest clock period that still meets timing from the previous case study.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sec03-regincr-flatten\n% cd $TOPDIR/asic/build-sec03-regincr-flatten\n% pyhflow --one-test --clock_period=0.400 ../designs/sec03-regincr.yml\n% code 02-synopsys-dc-synth/run.tcl\n</code></pre> <p>Where <code>XX</code> is the shortest clock period which meets timing. We are currently using the following command in <code>02-synopsys-dc-synth/run.tcl</code> to synthesize our design.</p> <pre><code>compile_ultra -no_autoungroup -gate_clock\n</code></pre> <p>Change this by removing <code>-no_autoungroup</code>.</p> <pre><code>compile_ultra -gate_clock\n</code></pre> <p>Now run the flow.</p> <pre><code>% cd $TOPDIR/asic/build-sec03-regincr-flatten\n% ./run-flow\n</code></pre> <p>Revisit the post-synthesis gate-level netlist without flattening.</p> <pre><code>% cd $TOPDIR/asic\n% less build-sec03-regincr-decrease-clk/02-synopsys-dc-synth/post-synth.v\n</code></pre> <p>Notice how the original gate-level netlist preserves the logical hierarchy. Now look at the post-synthesis gate-level netlist with flattening.</p> <pre><code>% cd $TOPDIR/asic\n% less build-sec03-regincr-flatten/02-synopsys-dc-synth/post-synth.v\n</code></pre> <p>Now notice who all of the logical hierarchy is gone and all of the gates are in a single \"flat\" module. Compare the area without and with flattening.</p> <pre><code>% cd $TOPDIR/asic\n% cat build-sec03-regincr-decrease-clk/04-cadence-innovus-pnr/area.rpt\n% cat build-sec03-regincr-flatten/04-cadence-innovus-pnr/area.rpt\n</code></pre> <p>Because the flattened module lacks logical hierarchy we cannot see the hierarchical breakdown. The advantage of flattening is that it can improve the area and also potentially enable a shorter clock period, but the disadvantage is that it significantly complicates our ability to deeply understand the area, energy, and timing of our designs and thus effectively explore an entire design space. So we will primarily turn off flattening in this course.</p> <p>Note that if we wanted to make it easier to experiment with flattening, we could modify the synthesis step template like this:</p> <pre><code>{% if flatten is defined and flatten %}\ncompile_ultra -gate_clock\n{% else %}\ncompile_ultra -no_autoungroup -gate_clock\n{% endif %}\n</code></pre> <p>Then in your design YAML file you can add this to control whether flattening is turned on or off; or we can specify the value of the flatten parameter as a pyhflow command line option (i.e., with <code>--flatten=true</code>).</p> <pre><code>flatten : true\n</code></pre> <p>Students should feel free to modify the step templates and/or the design YAML files for their labs and/or projects to experiment with the ASIC flow.</p>"},{"location":"ece6745-sec04-xcel-rtl/","title":"ECE 6745 Section 4: TinyRV2 Accelerator RTL Design","text":"<p>In this section, we will be discussing how to implement a simple medium-grain accelerator. Fine-grain accelerators are tightly integrated within the processor pipeline (e.g., a specialized functional unit for bit-reversed addressing useful in implementing an FFT), while coarse-grain accelerators are loosely integrated with a processor through the memory hierarchy (e.g., a graphics rendering accelerator sharing the last-level cache with a general-purpose processor). Medium-grain accelerators are often integrated as co-processors: the processor can directly send/receive messages to/from the accelerator with special instructions, but the co-processor is relatively decoupled from the main processor pipeline and can also independently interact with memory. To illustrate how to implement a medium-grain accelerator, we will be working on a simple \"accumulation\" accelerator that adds all of the values in an array stored in memory. More detailed tutorials for a vector-vector-add accelerator including how to push a complete processor, memory, and accelerator system will be posted on the public course website shortly.</p> <p>The first step is to access <code>ecelinux</code>. Use Microsoft Remote Desktop to log into a specific <code>ecelinux</code> server. Then use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-sec04-xcel-rtl sec04\n% cd sec04\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-sec04-xcel-rtl/#1-baseline-tinyrv2-processor-fl-and-rtl-models","title":"1. Baseline TinyRV2 Processor FL and RTL Models","text":"<p>The following figure illustrates the overall system we will be using with our TinyRV2 processors. The processor includes eight latency insensitive val/rdy interfaces. The mngr2proc/proc2mngr interfaces are used for the test harness to send data to the processor and for the processor to send data back to the test harness. The imem master/minion interface is used for instruction fetch, and the dmem master/minion interface is used for implementing load/store instructions. The system includes both instruction and data caches. The xcel master/minion interface is used for the processor to send messages to the accelerator. The cache is not ported to work with the ASIC flow so it is not currently included!</p> <p></p> <p>We provide two implementations of the TinyRV2 processor. The FL model in <code>sim/proc/ProcFL.py</code> is essentially an instruction-set-architecture (ISA) simulator; it simulates only the instruction semantics and makes no attempt to model any timing behavior. The RTL model in <code>sim/proc/ProcVRTL.v</code> is similar to the alternative design for lab 2 in ECE 4750. It is a five-stage pipelined processor that implements the TinyRV2 instruction set and includes full bypassing/forwarding to resolve data hazards. There are two important differences from the alternative design for lab 2 of ECE 4750. First, the new processor design uses a single-cycle integer multiplier. Second, the new processor design includes the ability to handle new CSRs for interacting with medium-grain accelerators. The datapath diagram for the processor is shown below.</p> <p></p> <p>We should run all of the unit tests on both the FL and RTL processor models to verify that we are starting with a working processor.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../proc\n</code></pre>"},{"location":"ece6745-sec04-xcel-rtl/#2-cross-compiling-and-executing-tinyrv2-microbenchmarks","title":"2. Cross-Compiling and Executing TinyRV2 Microbenchmarks","text":"<p>We will write our microbenchmarks in C. Let's start by writing a simple accumulation microbenchmark. Take a look at the code provided in <code>app/ubmark/ubmark-accum.c</code>:</p> <pre><code>__attribute__ ((noinline))\nint accum_scalar( int* src, int size )\n{\n  // ''' SECTION TASK ''''''''''''''''''''''''''''''''''''''''''''''''\n  // Implement a simple C function to add all of the elements in the\n  // source array and then return this result.\n  // '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n}\n</code></pre> <p>Go ahead and implement the <code>accum_scalar</code> function. We will a use microbenchmark test to verify the functionality of our microbenchmark and a microbenchmark eval to evaluate the performance of our microbenchmark. We will run both the microbenchmark test and eval on both FL and RTL TinyRV2 processor models.</p>"},{"location":"ece6745-sec04-xcel-rtl/#21-tinyrv2-microbenchmark-test","title":"2.1. TinyRV2 Microbenchmark Test","text":"<p>Let's go ahead and take a look at the microbenchmark test provided for the accumulation microbenchmark.</p> <pre><code>% cd $TOPDIR/app/ubmark\n% less ubmark-accum-test.c\n</code></pre> <p>Notice how we have various test case functions and then we call these test case functions in <code>main</code>. We have a build system that can compile microbenchmarks tests and evalutions natively for x86 and can also cross-compile these microbenchmarks for TinyRV2 so they can be executed on our simulators. Here is how we compile and execute the tests for the pure-software accumulation microbenchmark natively:</p> <pre><code>% cd $TOPDIR/app\n% mkdir build-native\n% cd build-native\n% ../configure\n% make ubmark-accum-test\n% ./ubmark-accum-test\n</code></pre> <p>You can run a single test case like this:</p> <pre><code>% cd $TOPDIR/app/build-native\n% ./ubmark-accum-test 1\n</code></pre> <p>Once we are confident the microbenchmark test passes on natively, we can cross-compile the microbenchmark test and run it on both FL and RTL TinyRV2 processor models. Let's start by cross-compiling the microbenchmark test.</p> <pre><code>% mkdir -p $TOPDIR/app/build\n% cd $TOPDIR/app/build\n% ../configure --host=riscv32-unknown-elf\n% make ubmark-accum-test\n</code></pre> <p>This will create a <code>ubmark-accum-test</code> binaries which contains TinyRV2 instructions and data. You can disassemble a TinyRV2 binary (i.e., turn a compiled binary back into an assembly text representation) with the <code>riscv32-objdump</code> command like this:</p> <pre><code>% cd $TOPDIR/app/build\n% riscv32-objdump ubmark-accum-test | less -p\"&lt;ubmark_accum&gt;:\"\n</code></pre> <p>Take a look at the <code>ubmark_accum</code> function in the disassembly and see if you can understand how this assembly implements the C function you wrote.</p> <p>We have provided you with a simulator that composes a processor, memory, and accelerator and is capable of executing TinyRV2 binaries. The simulator enables flexibly choosing the processor implementation (FL vs. RTL) and the type and implementation of the accelerator. By default, the simulator uses the processor FL model and a \"null\" accelerator. So let\u2019s execute both TinyRV2 binaries on the instruction-set simulator:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim ./ubmark-accum-test\n</code></pre> <p>The <code>--trace</code> command line option will display each instruction as it is executed on the ISA simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --trace ./ubmark-accum-test &gt; ubmark-accum-test-fl.trace\n% code ubmark-accum-test-fl.trace\n</code></pre> <p>Now that we have verified the microbenchmark works correctly on the ISA simulator, we can run the test on the baseline TinyRV2 pipelined processor RTL model:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl ./ubmark-accum-test\n</code></pre> <p>The simulation should show all tests are passing.</p>"},{"location":"ece6745-sec04-xcel-rtl/#22-tinyrv2-microbenchmark-eval","title":"2.2. TinyRV2 Microbenchmark Eval","text":"<p>Once we are sure the microbenchmark test is working natively, on the FL simulator, and the RTL simulator, we can then turn our focus to the microbenchmark eval.</p> <pre><code>% cd $TOPDIR/app/ubmark\n% less ubmark-accum-eval.c\n</code></pre> <p>The <code>eval_src</code> and <code>eval_ref</code> arrays are all defined in the <code>app/ubmark/ubmark-accum.dat</code> file. The microbenchmark turns stats on, does the actual computation, turns stats off, and finally verifies that the results are as expected. We need the <code>ece6745_stats_on()</code> and <code>ece6745_stats_off()</code> functions to make sure we can keep track of various statistics (e.g., the number of cycles) only during the important part of the microbenchmark. We do not want to count time spent in initialization or verification when comparing the performance of our various microbenchmarks. These two functions are defined in <code>app/ece6745/ece6745-misc.h</code>.</p> <p>Here is how we can compile and execute the evaluation for the accumulation microbenchmark eval natively:</p> <pre><code>% cd $TOPDIR/app/build-native\n% make ubmark-accum-eval\n% ./ubmark-accum-eval\n</code></pre> <p>The microbenchmark should display passed. Once you are sure your microbenchmark eval is working correctly natively, you can cross-compile the microbenchmark eval for TinyRV2 and run it on the FL simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% make ubmark-accum-eval\n% ../../sim/pmx/pmx-sim ./ubmark-accum-eval\n</code></pre> <p>Finally we can run the microbenchmark eval on the baseline TinyRV2 pipelined processor RTL model:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --stats ./ubmark-accum-eval\nnum_cycles = 613\n</code></pre> <p>The number of cycles for your experiment might be difference since you have written your own accumulation microbenchmark. Now generate a line trace to dig into the performance:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --trace \\\n    ./ubmark-accum-eval &gt; ubmark-accum-eval-rtl.trace\n</code></pre> <p>The instructor will walk through and explain the line trace.</p>"},{"location":"ece6745-sec04-xcel-rtl/#3-accumulation-accelerator-fl-and-rtl-models","title":"3. Accumulation Accelerator FL and RTL Models","text":"<p>We will take an incremental approach when designing, implementing, testing, and evaluating accelerators. We can use test sources, sinks, and memories to create a test harness that will enable us to explore the accelerator cycle-level performance and the ASIC area, energy, and timing in isolation. Only after we are sure that we have a reasonable design-point should we consider integrating the accelerator with the processor.</p> <p>We have provided you a FL model of the accumulation accelerator. Our accelerators will include a set of accelerator registers that can be read and written from the processor using special instructions and the xcelreq/xcelresp interface. The accumulator accelerator protocol defines the accelerator registers as follows:</p> <ul> <li>xr0 : go/done</li> <li>xr1 : base address of the array src</li> <li>xr2 : size of the array</li> </ul> <p>The actual protocol involves the following steps:</p> <ol> <li>Write the base address of src to xr1</li> <li>Write the number of elements in the array to xr2</li> <li>Tell accelerator to go by writing xr0</li> <li>Wait for accelerator to finish by reading xr0, result will be sum</li> </ol> <p>You can test this model like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut9_xcel/test/AccumXcelFL_test.py -v\n</code></pre> <p>We are now going to work on the accumulation accelerator RTL model. Our accelerator will use the following FSM:</p> <p></p> <p>While the accelerator is in the XCFG state, it will update its internal registers when it receives accelerator requests from the processor. When the accelerator receives a write to xr0 it moves into the M_RD state. In the M_RD state, the accelerator will send out one memory read request to read the current element from the source array. In the CALC state, the accelerator will wait for the response from memory and then do the actual accumulation. It then will either move back into the M_RD state if there is another element to be processed, or move into the XCFG state if we have processed all elements in the array.</p> <p>Open the accumulation accelerator RTL which is in <code>sim/tut9_xcel/AccumXcel.v</code> and take a look.</p> <pre><code>% cd $TOPDIR/sim/tut9_xcel\n% code AccumXcel.v\n</code></pre> <p>You can test the accelerator like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut9_xcel\n</code></pre> <p>We have also included a simulator for just the accumulation accelerator in isolation which can be used to evaluate its performance.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut9_xcel/accum-xcel-sim --impl rtl --input multiple --stats\nnum_cycles = 810\n</code></pre> <p>We could use the simulator to help evaluate the cycle-level performance of the accelerator on various different datasets as we try out various optimizations.</p>"},{"location":"ece6745-sec04-xcel-rtl/#4-accelerating-a-tinyrv2-microbenchmark","title":"4. Accelerating a TinyRV2 Microbenchmark","text":"<p>Now that we have unit tested and evaluated both the baseline TinyRV2 pipelined processor and the accumulation accelerator in isolation, we are finally ready to compose them. The processor will send messages to the accelerator by reading and writing 32 special CSRs using the standard CSRW and CSRR instructions. These 32 special CSRs are as follows:</p> <pre><code>0x7e0 : accelerator register  0 (xr0)\n0x7e1 : accelerator register  1 (xr1)\n0x7e2 : accelerator register  2 (xr2)\n...\n0x7ff : accelerator register 31 (xr31)\n</code></pre> <p>Here is a simple assembly sequence which will write the value 1 to an accelerator register, read that value back from the accelerator register, and write the value to general-purpose register x2.</p> <pre><code>addi x1, x0, 1\ncsrw 0x7e0, x1\ncsrr x2, 0x7e0\n</code></pre> <p>To use an accelerator from a C microbenchmark, we need to embed assembly instructions directly into a C program. We can do this using the GCC inline assembly extensions. Take a closer look at the accelerated version of the accumulation microbenchmark in <code>app/ubmark/ubmark-accum-xcel.c:</code></p> <pre><code>__attribute__ ((noinline))\nint accum_xcel( int* src, int size )\n{\n  int result = 0;\n\n  asm volatile (\n    \"csrw 0x7e1, %[src]; \\n\"\n    \"csrw 0x7e2, %[size];\\n\"\n    \"csrw 0x7e0, x0     ;\\n\"\n    \"csrr %[result], 0x7e0;\\n\"\n\n    // Outputs from the inline assembly block\n\n    : [result] \"=r\"(result)\n\n    // Inputs to the inline assembly block\n\n    : [src]    \"r\"(src),\n      [size]   \"r\"(size)\n\n    // Tell the compiler this accelerator read/writes memory\n\n    : \"memory\"\n  );\n\n  return result;\n}\n</code></pre> <p>The <code>asm</code> keyword enables embedding assembly into a C program. We have a sequence of strings, and each string is one assembly instruction. <code>%[src]</code> is special syntax that tells GCC to put the register that holds the <code>src</code> C variable into that location in the assembly. So if the compiler ends up allocating the <code>src</code> C variable to <code>x11</code> then it will put <code>x11</code> into the first assembly instruction.</p> <p>Let's compile and test our microbenchmark test and evaluation. Note that you cannot natively compile a microbenchmark that makes use of an accelerator, since x86 does not have any accelerators!</p> <pre><code>% cd $TOPDIR/app/build\n% make ubmark-accum-xcel-test\n% make ubmark-accum-xcel-eval\n% ../../sim/pmx/pmx-sim --xcel-impl accum-fl ./ubmark-accum-xcel-test\n% ../../sim/pmx/pmx-sim --xcel-impl accum-fl ./ubmark-accum-xcel-eval\n</code></pre> <p>Everything looks as expected, so we can now run our accelerated accumulation microbenchmark on the RTL implementation.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl accum-rtl ./ubmark-accum-xcel-test\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl accum-rtl \\\n    --stats ./ubmark-accum-xcel-eval\nnum_cycles = 314\n</code></pre> <p>Recall that the pure-software accumulation microbenchmark required 613 cycles. So our accelerator results in a cycle-level speedup of 2x. We might ask, where did this speedup come from? Why isn\u2019t the speedup larger? Let\u2019s look at the line trace.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl accum-rtl \\\n    --trace ./ubmark-accum-xcel-eval &gt; trace-alt.txt\n</code></pre> <p>See if you can figure out exactly what the accelerator is doing. Ideally, the accelerator would be able to sustain one accumulation per cycle for full throughput. Why is it not able to do this? What could we do to further improve the performance of this accelerator?</p>"},{"location":"ece6745-sec05-sram/","title":"ECE 6745 Section 5: SRAM Generators","text":"<p>In this section, we will be learning about SRAM generators. Small memories can be easily synthesized using flip-flop or latch standard cells, but synthesizing large memories can significantly impact the area, energy, and timing of the overall design. ASIC designers often use SRAM generators to \"generate\" arrays of memory bitcells and the corresponding peripheral circuitry (e.g., address decoders, bitline drivers, sense amps) which are combined into what is called an \"SRAM macro\". These SRAM generators are parameterized to enable generating a wide range of SRAM macros with different numbers of rows, columns, and column muxes, as well as optional support for partial writes, built-in self-test, and error correction. Similar to a standard-cell library, an SRAM generator must generate not just layout but also all of the necessary views to capture logical functionality, timing, geometry, and power usage. These views can then by used by the ASIC tools to produce a complete design which includes a mix of both standard cells and SRAM macros. We will first see how to use the open-source OpenRAM memory generator to generate various views of an SRAM macro. Then we will see how to use SRAMs in our RTL designs. Finally, we will put the these two pieces together to combine synthesizable RTL with SRAM macros and push the composition through the ASIC toolflow.</p> <p>The first step is to access <code>ecelinux</code>. Use Microsoft Remote Desktop to log into a specific <code>ecelinux</code> server. Then use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-sec05-sram sec05\n% cd sec05\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-sec05-sram/#1-openram-memory-generator","title":"1. OpenRAM Memory Generator","text":"<p>Just as with standard-cell libraries, acquiring real SRAM generators is a complex and potentially expensive process. It requires gaining access to a specific fabrication technology, negotiating with a company which makes the SRAM generator, and usually signing multiple non-disclosure agreements. The OpenRAM memory generator is based on the same \"fake\" 45nm technology that we are using for the Nangate standard-cell library. The \"fake\" technology is representative enough to provide reasonable area, energy, and timing estimates for our purposes. Let's take a look at how to use the OpenRAM memory generator to generate various views of an SRAM macro.</p> <p>An SRAM generator takes as input a configuration file which specifies the various parameters for the desired SRAM macro. Create a configuration file with the following content using your favorite text editor. You should name your file <code>SRAM_32x128_1rw_cfg.py</code> and it should be located in the directory shown below.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen\n% cat SRAM_32x128_1rw_cfg.py\n</code></pre> <p>The configuration file should look like this:</p> <pre><code>use_conda       = False\n\nnum_rw_ports    = 1\nnum_r_ports     = 0\nnum_w_ports     = 0\n\nword_size       = 32\nnum_words       = 128\nnum_banks       = 1\nwords_per_row   = 4\nwrite_size      = 8\n\ntech_name       = \"freepdk45\"\nprocess_corners = [\"TT\"]\nsupply_voltages = [1.1]\ntemperatures    = [25]\n\nroute_supplies  = True\ncheck_lvsdrc    = False\n\noutput_path     = \"SRAM_32x128_1rw\"\noutput_name     = \"SRAM_32x128_1rw\"\ninstance_name   = \"SRAM_32x128_1rw\"\n</code></pre> <p>In this example, we are generating a single-ported SRAM which has 128 rows and 32 bits per row for a total capacity of 4096 bits or 512B. This size is probably near the cross-over point where you might transition from using synthesized memories to SRAM macros. OpenRAM will take this configuration file as input and generate many different views of the SRAM macro including: schematics (<code>.sp</code>), layout (<code>.gds</code>), a Verilog behavioral model (<code>.v</code>), abstract logical, timing, power view (<code>.lib</code>), and a physical view (<code>.lef</code>). These views can then be used by the ASIC tools.</p> <p>You can use the following command to run the OpenRAM memory generator.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen\n% openram -v -v SRAM_32x128_1rw_cfg.py\n</code></pre> <p>It will take about 4-5 minutes to generate the SRAM macro. You can see the resulting views here:</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% ls -1\nSRAM_32x128_1rw.gds\nSRAM_32x128_1rw.lef\nSRAM_32x128_1rw.sp\nSRAM_32x128_1rw_TT_1p1V_25C.lib\nSRAM_32x128_1rw.v\nSRAM_32x128_1rw.html\n</code></pre> <p>You can find more information about the OpenRAM memory generator on the project's webpage here:</p> <ul> <li>https://openram.org</li> </ul> <p>Or in this research paper:</p> <ul> <li>M. Guthaus et. al, \"OpenRAM: An Open-Source Memory Compiler\", Int'l    Conf. on Computer-Aided Design (ICCAD), Nov. 2016.    (https://doi.org/10.1145/2966986.2980098)</li> </ul> <p>The following excerpt from the paper illustrates the microarchitecture used in the single-port SRAM macro.</p> <p></p> <p>The functionality of the pins are as follows:</p> <ul> <li><code>clk</code>: clock</li> <li><code>WEb</code>: write enable (active low)</li> <li><code>OEb</code>: output enable (active low)</li> <li><code>CSb</code>: whole SRAM enable (active low)</li> <li><code>ADDR</code>: address</li> <li><code>DATA</code>: read/write data</li> </ul> <p>Notice that there is a single address, and a single read/write data bus. This SRAM macro has a single read/write port and only supports executing a single transaction at a time. The following excerpt from the paper shows the timing diagram for a read and write transaction.</p> <p></p> <p>Prof. Batten will explain this timing diagram in more detail, especially the important distinction between a synchronous read SRAM and a combinational read register file. Take a few minutes to look at the behavioral verilog. See if you can see how this models a synchronous read SRAM.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% less SRAM_32x128_1rw.v\n</code></pre> <p>You can take a look at the generated transistor-level netlist for a single bit-cell like this:</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% less -p \" cell_1rw \" SRAM_32x128_1rw.sp\n</code></pre> <p>Now let's use Klayout look at the actual layout produced by the OpenRAM memory generator.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% klayout -l $ECE6745_STDCELLS/klayout.lyp SRAM_32x128_1rw.gds\n</code></pre> <p>In Klayout, you can show/hide layers by double clicking on them on the right panel. You can show more of the hierarchy by selecting Display &gt; Increment Hierarchy or less of the hierarchy by selecting Display &gt; Decrement Hierarchy from the menu.</p> <p>Take a quick look at the <code>.lib</code> file and the <code>.lef</code> file for the SRAM macro.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% less SRAM_32x128_1rw_TT_1p1V_25C.lib\n% less SRAM_32x128_1rw.lef\n</code></pre>"},{"location":"ece6745-sec05-sram/#2-sram-rtl-models","title":"2. SRAM RTL Models","text":"<p>Now that we understand how an SRAM generator works, let's see how to reference an SRAM in Verilog RTL. Our basic SRAMs are located in the <code>sim/sram</code> subdirectory.</p> <pre><code>% cd $TOPDIR/sim/sram\n% ls\n...\nSRAM_generic.v\nSRAM.v\n</code></pre> <p>Take a look the interface of the SRAM in <code>SRAM.v</code>.</p> <pre><code>module sram_SRAM\n#(\n  parameter p_data_nbits  = 32,\n  parameter p_num_entries = 256,\n\n  // Local constants not meant to be set from outside the module\n  parameter c_addr_nbits  = $clog2(p_num_entries),\n  parameter c_data_nbytes = (p_data_nbits+7)/8 // $ceil(p_data_nbits/8)\n)(\n  input  logic                        clk,\n  input  logic                        reset,\n  input  logic                        port0_val,\n  input  logic                        port0_type,\n  input  logic [c_addr_nbits-1:0]     port0_idx,\n  input  logic [(p_data_nbits/8)-1:0] port0_wben,\n  input  logic [p_data_nbits-1:0]     port0_wdata,\n  output logic [p_data_nbits-1:0]     port0_rdata\n);\n</code></pre> <p>The SRAM model is parameterized by the number of words and the bits per word, and has the following pin-level interface:</p> <ul> <li><code>port0_val</code>: port enable</li> <li><code>port0_type</code>: transaction type (0 = read, 1 = write)</li> <li><code>port0_idx</code>: which row to read/write</li> <li><code>port0_wben</code>: write byte enables</li> <li><code>port0_wdata</code>: write data</li> <li><code>port0_rdata</code>: read data</li> </ul> <p>Now look at the implementation of the SRAM. You will see a generate if statement which uses the parameters to either (1) instantiate a specific SRAM macro or (2) instantiate a generic SRAM. It is critical that the name of the specific SRAM macro matches the name generated by OpenRAM. In this discussion section we will be generating an SRAM with 128 words each of which is 32 bits, and we can see that this SRAM macro is already included.</p> <p>Let's run the tests for the specific SRAM we will be using in this discussion section.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_direct_32x128 -s\n</code></pre> <p>You can run the random test like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_random[32-128] -s\n</code></pre>"},{"location":"ece6745-sec05-sram/#3-sram-minion-wrapper-rtl","title":"3. SRAM Minion Wrapper RTL","text":"<p>SRAMs use a latency sensitive interface meaning a user must carefully manage the timing for correct operation (i.e., set the read address and then exactly one cycle later use the read data). In addition, the SRAM cannot be \"stalled\". To illustrate how to use SRAM macros, we will create a latency insensitive minion wrapper around an SRAM which enables writing and reading the SRAM using our standard memory messages. The following figure illustrates our approach to implementing this wrapper:</p> <p></p> <p>Here is a pipeline diagram that illustrates how this works.</p> <pre><code> cycle : 0  1  2  3  4  5  6  7  8\n msg a : M0 Mx\n msg b :    M0 Mx\n msg c :       M0 M1 M2 M2 M2\n msg d :          M0 M1 q  q  M2     # msg c is in skid buffer\n msg e :             M0 M0 M0 M0 Mx\n\n cycle M0 M1 [q ] M2\n    0: a\n    1: b  a       a  # a flows through bypass queue\n    2: c  b       b  # b flows through bypass queue\n    3: d  c          # M2 is stalled, c will need to go into bypq\n    4: e  d    c     #\n    5: e      dc     # d skids behind c into the bypq\n    6: e       d  c  # c is dequeued from bypq\n    7: e          d  # d is dequeued from bypq\n    8:    e       e  # e flows through bypass queue\n</code></pre> <p>Take a closer look at the SRAM minion wrapper we provide you.</p> <pre><code>% cd $TOPDIR/sim/tut10_sram\n% less SRAMMinion.v\n</code></pre> <p>To use an SRAM, simply include <code>sram/SRAM.v</code>, instantiate the SRAM, and set the number of words and number of bits per word. Here is what the instantiation of the SRAM looks like in the wrapper.</p> <pre><code>`include \"sram/SRAM.v\"\n...\nsram_SRAM#(32,128) sram\n(\n  .clk         (clk),\n  .reset       (reset),\n  .port0_idx   (sram_addr_M0),\n  .port0_type  (sram_wen_M0),\n  .port0_val   (sram_en_M0),\n  .port0_wben  (sram_wben_M0),\n  .port0_wdata (memreq_msg_data_M0),\n  .port0_rdata (sram_read_data_M1)\n);\n</code></pre> <p>We can run a test on the SRAM minion wrapper like this:</p> <pre><code> % cd $TOPDIR/sim/build\n % pytest ../tut10_sram/test/SRAMMinion_test.py -k random_0_3 -s\n</code></pre> <p>Here is what the trace output should look like.</p> <pre><code>  1r                           &gt; (  (). ) &gt; .\n  2r                           &gt; (  (). ) &gt; .\n  3:                           &gt; (  (). ) &gt; .\n  4: wr:00:00000000:0:55fceed9 &gt; (wr(). ) &gt; .\n  5: wr:01:00000004:0:5bec8a7b &gt; (wr()# ) &gt; #\n  6: #                         &gt; (# ()# ) &gt; #\n  7: #                         &gt; (# ()wr) &gt; wr:00:0:0:\n  8: #                         &gt; (# ()# ) &gt; #\n  9: #                         &gt; (# ()# ) &gt; #\n 10: #                         &gt; (# ()# ) &gt; #\n 11: #                         &gt; (# ()wr) &gt; wr:01:0:0:\n 12: wr:02:00000008:0:b1aa20f1 &gt; (wr(). ) &gt; .\n 13: wr:03:0000000c:0:a5b6b6bb &gt; (wr()# ) &gt; #\n 14: #                         &gt; (# ()# ) &gt; #\n 15: #                         &gt; (# ()wr) &gt; wr:02:0:0:\n</code></pre> <p>The first write transaction takes a single cycle to go through the SRAM minion wrapper, but then the response interface is not ready on cycles 5-6. The second write transaction is still accepted by the SRAM minion wrapper and it will end up in the bypass queue, but the later transactions are stalled because the request interface is not ready. No transactions are lost.</p> <p>Let's now use an interactive simulator to generate the pickled Verilog and a test bench for pushing through the ASIC flow.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut10_sram/sram-sim --impl rtl --input random --translate --dump-vtb\n</code></pre>"},{"location":"ece6745-sec05-sram/#4-asic-front-end-flow-with-sram-macros","title":"4. ASIC Front-End Flow with SRAM Macros","text":"<p>Now we will push our SRAM minion wrapper through the ASIC front-end flow. We have already generated the SRAM macro using OpenRAM at the beginning of the discussion section. We want to move the key generated files to make them easier to use by the ASIC tools.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen/SRAM_32x128_1rw\n% cp SRAM_32x128_1rw_TT_1p1V_25C.lib ../SRAM_32x128_1rw.lib\n% cp *.gds *.lef *.v ..\n</code></pre> <p>We need to convert the <code>.lib</code> file into a <code>.db</code> file using the Synopsys Library Compiler (LC) tool.</p> <pre><code>% cd $TOPDIR/asic/build-sram/00-openram-memgen\n% lc_shell\nlc_shell&gt; read_lib SRAM_32x128_1rw.lib\nlc_shell&gt; write_lib SRAM_32x128_1rw_TT_1p1V_25C_lib \\\n  -format db -output SRAM_32x128_1rw.db\nlc_shell&gt; exit\n</code></pre> <p>As always, we start by using four-state RTL simulation to further verify our design.</p> <pre><code>% mkdir -p ${TOPDIR}/asic/build-sram/01-synopsys-vcs-rtlsim\n% cd ${TOPDIR}/asic/build-sram/01-synopsys-vcs-rtlsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n   +vcs+dumpvars+waves.vcd \\\n   +incdir+${TOPDIR}/sim/build \\\n   ${TOPDIR}/sim/build/SRAMMinion_noparam__pickled.v \\\n   ${TOPDIR}/sim/build/SRAMMinion_noparam_sram-rtl-random_tb.v\n% ./simv\n</code></pre> <p>Now we can use Synopsys DC to synthesize the logic which goes around the SRAM macro.</p> <pre><code>% mkdir -p ${TOPDIR}/asic/build-sram/02-synopsys-dc-synth\n% cd ${TOPDIR}/asic/build-sram/02-synopsys-dc-synth\n% dc_shell-xg-t\ndc_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\ndc_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\ndc_shell&gt; analyze -format sverilog ../../../sim/build/SRAMMinion_noparam__pickled.v\ndc_shell&gt; elaborate SRAMMinion_noparam\ndc_shell&gt; create_clock clk -name ideal_clock1 -period 2.0\ndc_shell&gt; compile\ndc_shell&gt; write -format ddc     -hierarchy -output post-synth.ddc\ndc_shell&gt; write -format verilog -hierarchy -output post-synth.v\ndc_shell&gt; report_area   -hierarchy\ndc_shell&gt; report_timing -nets\ndc_shell&gt; exit\n</code></pre> <p>We are basically using the same steps we used in the ASIC front-end flow section. Notice how we must point Synopsys DC to the <code>.db</code> file generated by the OpenRAM memory generator so Synopsys DC knows the abstract logical and timing views of the SRAM.</p> <p>If you look for the SRAM module in the synthesized gate-level netlist, you will see that it is referenced but not declared. This is what we expect since we are not synthesizing the memory but instead using an SRAM macro.</p> <pre><code>% cd ${TOPDIR}/asic/build-sram/02-synopsys-dc-synth\n% less -p SRAM post-synth.v\n</code></pre> <p>We can use fast-functional gate-level simulation to simulate the gate-level netlist integrated with the Verilog RTL models for the SRAMs.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sram/03-synopsys-vcs-ffglsim\n% cd $TOPDIR/asic/build-sram/03-synopsys-vcs-ffglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +delay_mode_zero \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../00-openram-memgen/SRAM_32x128_1rw.v \\\n    ../02-synopsys-dc-synth/post-synth.v \\\n    ${TOPDIR}/sim/build/SRAMMinion_noparam_sram-rtl-random_tb.v\n% ./simv\n</code></pre>"},{"location":"ece6745-sec05-sram/#4-asic-back-end-flow-with-sram-macros","title":"4. ASIC Back-End Flow with SRAM Macros","text":"<p>Now we can use Cadence Innovus to place the SRAM macro and the standard cells, and then automatically route everything together.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n% cd $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n</code></pre> <p>As in the ASIC back-end flow section, we need to create two files before starting Cadence Innovus. Use VS Code to create a file named <code>constraints.sdc</code>.</p> <pre><code>% cd $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n% code constraints.sdc\n</code></pre> <p>The file should have the following constraint:</p> <pre><code>create_clock clk -name ideal_clock -period 2.0\n</code></pre> <p>Now use VS Code to create a file named <code>setup-timing.tcl</code>.</p> <pre><code>% cd $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n% code setup-timing.tcl\n</code></pre> <p>The file should have the following content:</p> <pre><code>create_rc_corner -name typical \\\n   -cap_table \"$env(ECE6745_STDCELLS)/rtk-typical.captable\" \\\n   -T 25\n\ncreate_library_set -name libs_typical \\\n   -timing [list \"$env(ECE6745_STDCELLS)/stdcells.lib\" \\\n                 \"../00-openram-memgen/SRAM_32x128_1rw.lib\" ]\n\ncreate_delay_corner -name delay_default \\\n   -library_set libs_typical \\\n   -rc_corner typical\n\ncreate_constraint_mode -name constraints_default \\\n   -sdc_files [list constraints.sdc]\n\ncreate_analysis_view -name analysis_default \\\n   -constraint_mode constraints_default \\\n   -delay_corner delay_default\n\nset_analysis_view -setup analysis_default -hold analysis_default\n</code></pre> <p>Notice that we are including the <code>.lib</code> file generated by the OpenRAM memory generator. Now let's start Cadence Innovus, load in the design, and complete power routing just as in the previous ASIC back-end section. We recommend working with a partner on this section to avoid overloading the ecelinux servers by running so many copies of Cadence Innovus as the same time.</p> <pre><code>% cd $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n% innovus\ninnovus&gt; set init_mmmc_file \"setup-timing.tcl\"\ninnovus&gt; set init_verilog   \"../02-synopsys-dc-synth/post-synth.v\"\ninnovus&gt; set init_top_cell  \"SRAMMinion_noparam\"\ninnovus&gt; set init_lef_file  \"$env(ECE6745_STDCELLS)/rtk-tech.lef \\\n                             $env(ECE6745_STDCELLS)/stdcells.lef \\\n                             ../00-openram-memgen/SRAM_32x128_1rw.lef\"\ninnovus&gt; set init_gnd_net   \"VSS\"\ninnovus&gt; set init_pwr_net   \"VDD\"\ninnovus&gt; init_design\ninnovus&gt; floorPlan -d 175 175 4.0 4.0 4.0 4.0\n</code></pre> <p>Now let's place the design.</p> <pre><code>innovus&gt; place_design\n</code></pre> <p>You should be able to see the SRAM macro as a black box in the middle of the layout and then various standard cells placed around the perimeter. Now let's go ahead and do some simple power and signal routing.</p> <pre><code>innovus&gt; globalNetConnect VDD -type pgpin -pin VDD -inst * -verbose\ninnovus&gt; globalNetConnect VSS -type pgpin -pin VSS -inst * -verbose\ninnovus&gt; sroute -nets {VDD VSS}\ninnovus&gt; routeDesign\ninnovus&gt; extractRC\n</code></pre> <p>You can now see all of the routing between the standard cells and the SRAM macro. We can now go ahead and add filler cells.</p> <pre><code>innovus&gt; setFillerMode -core {FILLCELL_X4 FILLCELL_X2 FILLCELL_X1}\ninnovus&gt; addFiller\n</code></pre> <p>Let's now save the final merged GDS file.</p> <pre><code>innovus&gt; streamOut post-pnr.gds \\\n  -merge \"$env(ECE6745_STDCELLS)/stdcells.gds \\\n          ../00-openram-memgen/SRAM_32x128_1rw.gds\" \\\n  -mapFile \"$env(ECE6745_STDCELLS)/rtk-stream-out.map\"\n</code></pre> <p>Notice how we need to provide the GDS for the SRAM macro when doing the final GDS merge. Finally we can look at some timing and area reports.</p> <pre><code>innovus&gt; report_timing -late  -path_type full_clock -net\ninnovus&gt; report_timing -early -path_type full_clock -net\ninnovus&gt; report_area\n</code></pre> <p>While the design should meet the setup time constraint it will likely fail the hold time constraint. A more advanced place-and-route script will include specific steps for fixing hold time violations.</p> <p>Let's exit Cadence Innovus.</p> <pre><code>innovus&gt; exit\n</code></pre> <p>Then we can use Klayout to take a look at the final layout.</p> <pre><code>% cd $TOPDIR/asic/build-sram/04-cadence-innovus-pnr\n% klayout -l ${ECE6745_STDCELLS}/klayout.lyp post-pnr.gds\n</code></pre>"},{"location":"ece6745-tut00-remote-access/","title":"Tutorial 0: ECE Linux Server Remote Access","text":"<p>All of the laboratory assignments for this course will be completed by remotely logging into a cluster of <code>ecelinux</code> servers. The <code>ecelinux</code> servers all run the Red Hat Enterprise Linux 8 operating system, and they all use an identical setup. You do not need to do anything special to create an <code>ecelinux</code> account. You will be using your NetID and Cornell password to login, and an <code>ecelinux</code> account will be automatically created for you when you first login. Any student enrolled in any ECE class should automatically be granted access to the <code>ecelinux</code> servers. Having said this, if you cannot log into the <code>ecelinux</code> servers please reach out to the course staff for assistance.</p> <p>Later tutorials will discuss how to use the Linux development environment and the Git distributed version control system. In this tutorial, we focus on how to setup remote access to the <code>ecelinux</code> servers by first connecting to the Cornell VPN and then using three different options to remotely access the <code>ecelinux</code> servers. The first remote access option is based on using PowerShell (for Windows OS users) or Mac Terminal (for Mac OS X users) and only supports primitive text-based interaction. We recommend using PowerShell or Mac Terminal as backup options to debug connection issues to the <code>ecelinux</code> servers. The second (and primary) remote access option recommended in this course is through Visual Studio Code (VS Code) which provides a very nice interface with support for working at the command line, graphic text editing, and graphic file browsing. The third remote access option is based on using Microsoft Remote Desktop and is required when executing a Linux application with a graphical user interface.</p>"},{"location":"ece6745-tut00-remote-access/#1-select-an-ecelinux-server","title":"1. Select an <code>ecelinux</code> Server","text":"<p>It is important to keep in mind that we will use <code>ecelinux</code> as shorthand for the entire cluster of 25 servers. These servers are named as follows:</p> <ul> <li><code>ecelinux-01.ece.cornell.edu</code> (avoid using this server!)</li> <li><code>ecelinux-02.ece.cornell.edu</code></li> <li><code>ecelinux-03.ece.cornell.edu</code></li> <li>...</li> <li><code>ecelinux-18.ece.cornell.edu</code></li> <li><code>ecelinux-19.ece.cornell.edu</code></li> <li><code>ecelinux-20.ece.cornell.edu</code></li> </ul> <p>At the beginning of the semester, select a server and always use that same server. Do not just log into <code>ecelinux.ece.cornell.edu</code>. Avoid using <code>ecelinux-01</code> since many students use this server by default and it can become overloaded. Continue to always use the same server unless you have trouble logging in in which case you can try switching to a different server.</p> <p>All of the <code>ecelinux</code> servers are identical. Every tool is available on every <code>ecelinux</code> server. All of your files are available on every <code>ecelinux</code> server.</p>"},{"location":"ece6745-tut00-remote-access/#2-connecting-to-the-cornell-vpn","title":"2. Connecting to the Cornell VPN","text":"<p>If you are logging into the <code>ecelinux</code> servers from on campus (i.e., using the Cornell wired or wireless network), then you do not need to enable the Cornell virtual private network (VPN). However, if you are off campus, then you will need to enable the Cornell VPN whenever you want to log into the <code>ecelinux</code> servers. The VPN provides very secure access to all on-campus network resources. More information about the Cornell VPN is available here:</p> <ul> <li>https://it.cornell.edu/cuvpn</li> </ul> <p>Simply follow the instructions at the following link to install the Cisco VPN software for the appropriate operating system you use on your laptop/workstation:</p> <ul> <li>https://it.cornell.edu/landing-page-kba/2605/5273</li> </ul> <p>Once the Cornell VPN is installed, then connect to the Cornell VPN by following these instructions and using your Cornell NetID and password:</p> <ul> <li>https://it.cornell.edu/landing-page-kba/2605/823</li> </ul> <p>The Cornell VPN uses the Cisco Secure Client shown below.</p> <p></p>"},{"location":"ece6745-tut00-remote-access/#3-remote-access-via-powershell-or-mac-terminal","title":"3. Remote Access via PowerShell or Mac Terminal","text":"<p>PowerShell is part of Windows OS and Mac Terminal is part of Mac OS X. Both enable interacting with your system from the command line (i.e., a powerful text-based environment where users type commands to manipulate files and directories and execute applications). Both also enable remotely accessing other systems (e.g., the <code>ecelinux</code> servers) via the command line using SSH, a highly secure network protocol and associated client/server program. Both will enable you to log into the <code>ecelinux</code> servers and to then manipulate files and directories and execute applications remotely on the <code>ecelinux</code> servers using the Linux command line. You must try logging in using PowerShell or Mac Terminal before attempting to use VS Code!</p>"},{"location":"ece6745-tut00-remote-access/#31-starting-powershell-or-mac-terminal","title":"3.1. Starting PowerShell or Mac Terminal","text":"<p>First, if you are off campus, then you must be connected to the Cornell VPN before attempting to use X2Go to access the <code>ecelinux</code> servers (see Section 1). To start PowerShell click the Start menu then search for Windows PowerShell. To start Mac Terminal go to your Applications folder and choose Utilities &gt; Terminal, or open Spotlight, type Terminal, and press enter.</p>"},{"location":"ece6745-tut00-remote-access/#32-logging-into-ecelinux-servers-with-powershell-or-mac-terminal","title":"3.2. Logging into <code>ecelinux</code> Servers with PowerShell or Mac Terminal","text":"<p>After starting PowerShell or Mac Terminal, type in the following command at the prompt to log into the <code>ecelinux</code> servers using SSH.</p> <pre><code>% ssh netid@ecelinux-XX.ece.cornell.edu\n</code></pre> <p>Replace <code>netid</code> with your Cornell NetID in the command above and replace <code>XX</code> with the number of <code>ecelinux</code> server you plan to use this semester. You should not enter the <code>%</code> character. We use the <code>%</code> character to indicate what commands we should enter on the command line. Executing the command will prompt you to enter your Cornell NetID password, and then you should be connected to the <code>ecelinux</code> servers.</p> <p>The very first time you log into the <code>ecelinux</code> servers you may see a warning like this:</p> <pre><code>The authenticity of host \u2019ecelinux-XX.ece.cornell.edu (128.253.51.206)\u2019\ncan\u2019t be established. ECDSA key fingerprint is\nSHA256:smwMnf9dyhs5zW5I279C5oJBrTFc5FLghIJMfBR1cxI.\nAre you sure you want to continue connecting (yes/no)?\n</code></pre> <p>The very first time you log into the <code>ecelinux</code> servers it is okay to enter yes, but from then on if you continue to receive this warning please contact the course staff.</p> <p>Once you have opened a terminal, the very first thing you need to do after logging into the <code>ecelinux</code> servers is source the course setup script. This will ensure your environment is setup with everything you need for working on the laboratory/programming assignments. Enter the following command on the command line:</p> <pre><code>% source setup-ece6745.sh\n</code></pre> <p>Again, you should not enter the <code>%</code> character. You should now see a blue <code>ECE 6745</code> in your prompt which means your environment is setup for the course. See the final section of this tutorial for more on how to automatically source the setup script every time you log into the <code>ecelinux</code> servers.</p> <p>You can log out of the <code>ecelinux</code> server with the <code>exit</code> command.</p> <pre><code>% exit\n</code></pre> <p>Try logging in, sourcing the setup script, and loging out multiple times using PowerShell or Mac Terminal. You must make sure you can do this successfully before attempting to setup VS Code!</p>"},{"location":"ece6745-tut00-remote-access/#33-troubleshooting-remote-access-via-powershell-or-mac-terminal","title":"3.3. Troubleshooting Remote Access via PowerShell or Mac Terminal","text":"<p>If you cannot source the setup script it might be because you either took a course in a previous semester which used <code>ecelinux</code> or you are currently taking a course which also uses <code>ecelinux</code> and you modified your <code>.bashrc</code> to automatically source the other course's setup script.</p> <p>You should only source a setup script for a single course at a time. If you modified your <code>.bashrc</code> to source a course setup script you need to remove those lines from your <code>.bashrc</code>. If you are taking two courses which use <code>ecelinux</code> in the same semester then you should make sure not to source either setup script in your <code>.bashrc</code>. You should instead always source the appropriate setup script each time you log into <code>ecelinux</code> for whatever course you are currently working on.</p> <p>You can use the simple <code>nano</code> text editor to edit your <code>.bashrc</code> like this:</p> <pre><code>% nano .bashrc\n</code></pre> <p>Notice that the editor specifies most of the useful commands at the bottom of the terminal screen. The symbol <code>\\^</code> indicates the <code>CONTROL</code> key. To type any text you want, just move the cursor to the required position and use the keyboard. To save your changes press <code>CONTROL+O1 (i.e., press the</code>CONTROL1 key and the <code>O1 key at the same time) and press the</code>1 key after specifying the filename you want to save to. You can quit by pressing <code>CONTROL+X1. Use</code>CONTROL+G1 for help. <p></p> <p>Delete every line which sets up <code>ecelinux</code> for any course. A pristine <code>.bashrc</code> should look like this:</p> <pre><code>if [ -f /etc/bashrc ]; then\n  . /etc/bashrc\nfi\n\nif ! [[ \"$PATH\" =~ \"$HOME/.local/bin:$HOME/bin:\" ]]\nthen\n    PATH=\"$HOME/.local/bin:$HOME/bin:$PATH\"\nfi\nexport PATH\n</code></pre> <p>Log out, log in, source the setup script, and log out multiple times using PowerShell or Mac Terminal. You must make sure you can do this successfully before attempting to setup VS Code!</p>"},{"location":"ece6745-tut00-remote-access/#4-remote-access-via-vs-code","title":"4. Remote Access via VS Code","text":"<p>While it is possible to use simple text editors directly within PowerShell or Mac Terminal, it is not the most productive development setup. We strongly recommend using VS Code as your primary remote access option for code development. VS Code offers a nice balance of productive features while also working well with moderate internet speeds.</p> <p>VS Code uses a unique approach where the GUI interface runs completely on your local laptop/workshop and then automatically handles copying files back and forth between your local laptop/workshop and the <code>ecelinux</code> servers. VS Code is portable across many operating systems and has a thriving ecosystem of extensions and plugins enabling it to function as a full-featured IDE for languages from C to Javascript. More information about VS Code is here:</p> <ul> <li>https://code.visualstudio.com</li> <li>https://code.visualstudio.com/docs</li> </ul>"},{"location":"ece6745-tut00-remote-access/#41-installing-vs-code-on-your-laptopworkstation","title":"4.1. Installing VS Code on Your Laptop/Workstation","text":"<p>You can download VS Code by simply going to the main VS Code webpage:</p> <ul> <li>https://code.visualstudio.com</li> </ul> <p>There should be an obvious link that says <code>Download for Windows'' or</code>Download for MacOS''. Click on that link. On Mac OS X, you will need to drag the corresponding Visual Student Code.app to your Applications folder.</p>"},{"location":"ece6745-tut00-remote-access/#42-starting-and-configuring-vs-code","title":"4.2. Starting and Configuring VS Code","text":"<p>First, if you are off campus, then you must be connected to the Cornell VPN before attempting to use VS Code to access the <code>ecelinux</code> servers (see Section 1). Start by opening VS Code. The exact way you do this will depend on whether you are using a Windows OS or Mac OS X laptop/workstation.</p> <p>The key to VS Code is installing the correct extensions. You will need extensions for the Verilog hardware description language (HDL), the Python programming language, and the C/C++ programming language. We also want to install a special extension which will enable remotely accessing the <code>ecelinux</code> servers using SSH. Choose View &gt; Extensions from the menubar. Enter the name of the extension in the ``Search Extensions in Marketplace'' and then click the blue \\IT{Install} button. Here are the names of the extensions to install:</p> <ul> <li>Remote - SSH (use the one from Microsoft)</li> <li>Verilog (use the one from Masahiro Hiramori)</li> <li>Python (use the one from Microsoft)</li> <li>C/C++ (use the one from Microsoft)</li> <li>Surfer (use the one from surfer-project)</li> </ul> <p></p> <p></p> <p></p> <p></p> <p></p>"},{"location":"ece6745-tut00-remote-access/#43-logging-into-ecelinux-servers-with-vs-code","title":"4.3. Logging into <code>ecelinux</code> Servers with VS Code","text":"<p>After starting VS Code, choose View &gt; Command Palette from the menubar. Enter the following command in the command palette:</p> <pre><code>Remote-SSH: Connect Current Window to Host...\n</code></pre> <p>Do not use Remote-SSH: Add new SSH host... and do not use Connect to Host. Use Remote-SSH: Connect Current Window to Host...</p> <p>VS Code will then ask you to Select configured SSH host or enter user@host, and you should enter the following:</p> <pre><code>netid@ecelinux-XX.ece.cornell.edu\n</code></pre> <p>Replace <code>netid</code> with your Cornell NetID in the command above and replace <code>XX</code> with the number of <code>ecelinux</code> server you plan to use this semester. If you are on a Windows OS laptop/workstation, then you may see a pop-up which stays that the Windows Defender Firewall as blocked some features of this app. This is not a problem. Simply click Cancel.</p> <p>You might also see a drop down which asks you to choose the operating system of the remote server with options like Linux and Windows. Choose Linux.</p> <p>Finally, the very first time you log into the <code>ecelinux</code> servers you may see a warning like this:</p> <pre><code>\"ecelinux-XX.ece.cornell.edu\" has fingerprint\n\"SHA256:YCh2FiadeTXEzuSkC0AOdglBgPciwc8WvcCPncvr2Fs\"\nAre you sure you want to continue?\nContinue\nCancel\n</code></pre> <p>The very first time you log into the <code>ecelinux</code> servers it is okay to enter yes, but from then on if you continue to receive this warning please contact the course staff.</p> <p>Hopefully, VS Code will now prompt you to enter your Cornell NetID password, and then you should be connected to the <code>ecelinux</code> servers.</p> <p>Also the very first time you log into the <code>ecelinux</code> servers you will see a pop up dialog box in the lower right-hand corner which says Setting up SSH host ecelinux-XX.ece.cornell.edu (details) Initializing.... It might take up to a minute for everything to be setup; please be patient! Once the pop up dialog box goes away and you see SSH: ecelinux-XX.ece.cornell.edu in the lower left-hand corner of VS Code then you know you are connected to the <code>ecelinux</code> servers.</p> <p>The final step is to make sure your extensions for the Verilog HDL are also installed on the server. Choose View &gt; Extensions from the menubar. Use the \"Search Extensions in Marketplace\" to search for the same extensions that we installed earlier. Instead of saying Install it should now say Install in SSH: ecelinux-XX.ece.cornell.edu. Install the extensions on the <code>ecelinux</code> servers. You only need to do this once, and then next time this extension will already be installed on the <code>ecelinux</code> servers.</p>"},{"location":"ece6745-tut00-remote-access/#44-using-vs-code","title":"4.4. Using VS Code","text":"<p>VS Code includes an integrated file explorer which makes it very productive to browse and open files. Choose View &gt; Explorer from the menubar, and then click on Open Folder. VS Code will then ask you to Open File Or Folder with a default of <code>/home/netid</code>. Click OK.</p> <p>You might see a pop-up which asks you Do you trust the authors of the files in this folder? Since you will only be browsing your own files on the <code>ecelinux</code> server, it is fine to choose Yes, I trust the authors.</p> <p>This will reload VS Code, and you should now you will see a file explore in the left sidebar. You can easily browse your directory hierarchy, open files by clicking on them, create new files, and delete files.</p> <p>VS Code includes an integrated terminal which will give you access to the Linux command line on the <code>ecelinux</code> servers. Choose Terminal &gt; New Terminal from the menubar. You should see the same kind of Linux command line prompt that you saw when using either PowerShell or Mac Terminal.</p> <p>If you see a course number for a course other than ECE 6745 in your prompt, then stop! This means you likely have sourced the setup script for a different course. You must fix this before you can work on this course. Exit VS Code, follow the instructions in Section 2.3, and then try connecting with VS Code again.</p> <p>The very first thing you need to do after logging into the <code>ecelinux</code> servers is source the setup script for this course. This will ensure your environment is setup with everything you need for working on the laboratory/programming assignments. Enter the following command on the command line:</p> <pre><code>% source setup-ece6745.sh\n</code></pre> <p>Again, you should not enter the <code>%</code> character. You should now see a blue <code>ECE 6745</code> in your prompt which means your environment is setup for the course. See the final section of this tutorial for more on how to automatically source the setup script every time you log into the <code>ecelinux</code> servers.</p> <p>To experiment with VS Code, we will first grab a text file using the <code>wget</code> command. The next tutorial discusses this command in more detail. Type the following command in the VS Code integrated terminal.</p> <pre><code>% wget http://www.csl.cornell.edu/courses/ece6745/overview.txt\n</code></pre> <p>You can open a file in the integrated text editor using the <code>code</code> command like this:</p> <pre><code>% code overview.txt\n</code></pre> <p>The following figure shows what VS Code should look like if you have sourced the course setup script and opened the <code>overview.txt</code> file. Notice how the <code>overview.txt</code> file opened in a new tab at the top and the terminal remains at the bottom. This enables you to have easy access to editing files and the Linux command line at the same time.</p> <p></p>"},{"location":"ece6745-tut00-remote-access/#45-troubleshooting-remote-access-via-vs-code","title":"4.5. Troubleshooting Remote Access via VS Code","text":"<p>There may be issues where sometimes VS Code just keeps asking you for your password or VS Code just hangs when you try and connect to the <code>ecelinux</code> servers. This might mean VS Code is getting wedged. You can definitely ask the course staff to help, but you can also try to fix it on your own.</p> <p>One thing to try is to kill the VS Code server on the host. Choose View &gt; Command Palette from the menubar. Enter the following command in the command palette:</p> <pre><code>Remote-SSH: Kill VS Code Server on Host...\n</code></pre> <p>Another thing to try is to delete the <code>.vscode-server</code> directory on the sever. Of course, how can you delete this directory if you cannot use VS Code to access the <code>ecelinux</code> servers? You can use PowerShell or Mac Terminal to log into the <code>ecelinux</code> servers (see Section 2).</p> <p>Once you have gained access to the Linux command line on the <code>ecelinux</code> servers using either PowerShell or Mac Terminal, then you can delete the <code>.vscode-server</code> directory like this:</p> <pre><code>% rm -rf .vscode-server\n</code></pre> <p>Be very careful with the <code>rm</code> command since it can permanently delete files!</p> <p>VS Code can sometimes \"cache\" your <code>.bashrc</code>. This means if you modfiy your <code>.bashrc</code>, log out, and log back in the changes to your <code>.bashrc</code> will not be reflected. If you modify your <code>.bashrc</code> we recommend: (1) using Remote-SSH: Kill VS Code Server on Host... as described above; (2) close all instances of VS Code; (3) either use PowerShell or Mac Terminal to remove the <code>.vscode-server</code> directory as described above; and (4) reconnect VS Code to <code>ecelinux</code>.</p> <p>Sometimes VS Code can take a very long time to save a file. This is usually because VS Code is trying to auto-format the file on the <code>ecelinux</code> servers. To turn off auto-formatting, open the VS Code settings menu. On Windows OS, choose File &gt; Preferences &gt; Settings from the menubar. On Mac OS X, choose Code &gt; Preferences &gt; Settings from the menubar. Click on Text Editor and then Formatting. Make sure Format On Save is not checked.</p>"},{"location":"ece6745-tut00-remote-access/#6-remote-access-via-microsoft-remote-desktop","title":"6. Remote Access via Microsoft Remote Desktop","text":"<p>We will primarily use VS Code for working at the terminal, developing our hardware, and debugging our designs. However, we need to use a different remote accesss option if we want to run a Linux application which has a graphical user interface (GUI). We will be using the Microsoft Remote Desktop application to log into the <code>ecelinux</code> servers to provide us a \"virtual desktop\" which we can then use to interact with Linux GUI applications.</p>"},{"location":"ece6745-tut00-remote-access/#61-installing-microsoft-remote-desktop-on-your-laptopworkstation","title":"6.1. Installing Microsoft Remote Desktop on Your Laptop/Workstation","text":"<p>Start by installing the Microsoft Remote Desktop application. On Windows, simply use the Start Menu to search for Microsoft Remote Desktop. On Mac OS X, download Microsoft Remote Desktop from the App Store:</p> <ul> <li>https://apps.apple.com/us/app/windows-app/id1295203466</li> </ul>"},{"location":"ece6745-tut00-remote-access/#62-starting-and-configuring-microsoft-remote-desktop-from-windows","title":"6.2. Starting and Configuring Microsoft Remote Desktop from Windows","text":"<p>Start Microsoft Remote Desktop. For the Computer you must choose the same <code>ecelinux</code> server you selected in Section 1; do not just use <code>ecelinux.ece.cornell.edu</code>. Then click on Connect. You may see a message like this:</p> <pre><code>The remote computer could not be authenticated due to problems with its\nsecurity certificate. It may be unsafe to proceed.\n</code></pre> <p>If you see this message then take the following steps:</p> <ul> <li>Click Don't ask me again for connections to this computer</li> <li>Click Yes</li> </ul> <p>This should launch a \"virtual desktop\" on <code>ecelinux</code>. You will need to enter your NetID and password in the xrdp login.</p>"},{"location":"ece6745-tut00-remote-access/#62-starting-and-configuring-microsoft-remote-desktop-from-mac-os-x","title":"6.2. Starting and Configuring Microsoft Remote Desktop from Mac OS X","text":"<p>Start Microsoft Remote Desktop and Connections &gt; Add PC from the menu. For the hostname you must choose the same <code>ecelinux</code> server you selected in Section 1; do not just use <code>ecelinux.ece.cornell.edu</code>. Then user the following setup</p> <ul> <li>Click the User Account drop down and choose Add User Account<ul> <li>Username: <code>netid@cornell.edu</code> (must have <code>@cornell.edu</code> at end!)</li> <li>Password: NetID password</li> </ul> </li> <li>Display tab<ul> <li>Uncheck Start session in full screen</li> </ul> </li> <li>Devices &amp; Audio tab<ul> <li>Uncheck Printers and Smart cards</li> </ul> </li> <li>Click Save</li> </ul> <p>To log into <code>ecelinux</code> double click on the corresponding entry in Microsoft Remote Desktop. You may see a message like this:</p> <pre><code>Your are connecting to the RDP host ... The certificate couldn't be\nverified back to a root certificate. Your connection may not be\nsecure. Do you want to continue?\n</code></pre> <p>If you see this message then take the following steps:</p> <ul> <li>Click Show Certificate</li> <li>Click Always trutst XRDP when connecting ...</li> <li>Click Continue</li> </ul> <p>This should launch a \"virtual desktop\" on <code>ecelinux</code>.</p>"},{"location":"ece6745-tut00-remote-access/#63-using-microsoft-remote-desktop","title":"6.3. Using Microsoft Remote Desktop","text":"<p>To use Linux GUI Applications you need to source another setup script in your VS Code terminal like this:</p> <pre><code>% source setup-gui.sh\n</code></pre> <p>If you see an error that the script cannot find a running instance of Xvnc this means you have not connected to your selected <code>ecelinux</code> server using Microsoft Remote Desktop. You cannot source <code>setup-gui.sh</code> in your <code>.bashrc</code>. It will not work.</p> <p>Assuming there are no errors, you can now try starting a Linux GUI application. Try running the <code>xclock</code> program in your VS Code terminal.</p> <pre><code>% xclock\n</code></pre> <p>You should see an analog clock pop up in Microsoft Remote Desktop. Close the analog clock window.</p> <p></p>"},{"location":"ece6745-tut00-remote-access/#7-sourcing-course-setup-script-with-auto-setup","title":"7. Sourcing Course Setup Script with Auto Setup","text":"<p>The previous sections have demonstrated how to remotely access the <code>ecelinux</code> servers, get to the Linux command line, and source the course setup script. Again, you must source the course setup script before doing any work related to this course! The course setup script configures everything so you have the right environment to work on the laboratory/programming assignments.</p> <p>Since it can be tedious to always remember to source the course setup script, you can also use auto setup which will automatically source the course setup for you when you open a terminal. Note that you should only do this if ECE 6745 is the only course you are taking this semester which is using <code>ecelinux</code>! If you are taking more than one course which is using <code>ecelinux</code>, then you will need to manually source the setup script when you are working on this course. Enter the following command on the command line to use auto setup:</p> <pre><code> % source setup-ece6745.sh --enable-auto-setup\n</code></pre> <p>Then you must kill the VS Code server on the host. Choose View &gt; Command Palette from the menubar. Enter the following command in the command palette:</p> <pre><code>Remote-SSH: Kill VS Code Server on Host...\n</code></pre> <p>Then connect again by choosing View &gt; Command Palette from the menubar. Enter the following command in the command palette:</p> <pre><code>Remote-SSH: Connect Current Window to Host...\n</code></pre> <p>You should see <code>ECE 6745</code> in the prompt meaning your environment is automatically setup for the course. If at anytime you need to disable auto setup you can use the following command:</p> <pre><code> % source setup-ece6745.sh --disable-auto-setup\n</code></pre> <p>Again, if for any reason running the setup script prevents you from using tools for another course, you cannot use the auto setup. You will need to run the setup script manually every time you want to work on a laboratory/programming assignment for this course.</p>"},{"location":"ece6745-tut01-linux/","title":"Tutorial 1: Linux Development Environment","text":"<p>The laboratory assignments for this course are designed assuming you will be using a Linux (or UNIX-like) operating system for development. Basic Linux knowledge is essential to successfully complete this work and a more in-depth understanding enhances productivity. This tutorial covers the computing resources to be used in the course and offers a brisk introduction to the Linux operating system for first time users including some details specific to this course.</p> <p>Before you begin, make sure that you have logged into the <code>ecelinux</code> servers as described in the remote access tutorial. You will need to open a terminal and be ready to work at the Linux command line using VS Code. To follow along with the tutorial, type the commands without the <code>%</code> character. In addition to working through the commands in the tutorial, you should also try the more open-ended activities.</p> <p>Before you begin, make sure that you have sourced the <code>setup-ece6745.sh</code> script as described in the remote access tutorial. Sourcing the setup script sets up the environment required for this tutorial.</p>"},{"location":"ece6745-tut01-linux/#1-the-linux-command-line","title":"1. The Linux Command Line","text":"<p>In this section, we introduce the basics of working at the Linux command line. Our goal is to get you comfortable with commands required to complete the laboratory assignments. The shell is the original Linux user interface which is a text-based command-line interpreter. The default shell on the <code>ecelinux</code> machines is Bash. While there are other shells such as <code>sh</code>, <code>csh</code>, and <code>tcsh</code>, for this course we will always assume you are using Bash. As mentioned above, we use the <code>%</code> character to indicate commands that should be entered at the Linux command line, but you should not include the actual <code>%</code> character when typing in the commands on your own. To make it easier to cut-and-paste commands from this tutorial document onto the command line, you can tell Bash to ignore the <code>%</code> character using the following command:</p> <pre><code>% alias %=\"\"\n</code></pre> <p>Now you can cut-and-paste a sequence of commands from this tutorial document and Bash will not get confused by the <code>%</code> character which begins each line.</p>"},{"location":"ece6745-tut01-linux/#11-hello-world","title":"1.1. Hello World","text":"<p>We begin with the ubiquitous \"Hello, World\" example. To display the message \"Hello, World\" we will use the <code>echo</code> command. The <code>echo</code> command simply \"echoes'' its input to the console.</p> <pre><code>% echo \"Hello, World\"\n</code></pre> <p>The string we provide to the <code>echo</code> command is called a \\IT{command   line argument}. We use command line arguments to tell commands what they should operate on. Although simple, the <code>echo</code> command can very useful for creating simple text files, displaying environment variables, and general debugging.</p> <p>Activity 1: Experiment with <code>echo</code></p> <p>Experiment with using the <code>echo</code> command to display different messages.</p>"},{"location":"ece6745-tut01-linux/#12-manual-pages","title":"1.2. Manual Pages","text":"<p>You can learn more about any Linux command by using the <code>man</code> command. Try using this to learn more about the <code>echo</code> command.</p> <pre><code>% man echo\n</code></pre> <p>You can use the up/down keys to scroll the manual one line at a time, the space bar to scroll down one page at a time, and the <code>q</code> key to quit viewing the manual. You can even learn about the <code>man</code> command itself by using <code>man man</code>. As you follow the tutorial, feel free to use the <code>man</code> command to learn more about the commands we cover.</p> <p>Activity 2: Experiment with <code>man</code></p> <p>Use the <code>man</code> command to learn more about the <code>cat</code> command.</p>"},{"location":"ece6745-tut01-linux/#13-create-view-and-list-files","title":"1.3. Create, View, and List Files","text":"<p>We can use the <code>echo</code> command and a feature called ecommand output redirection to create simple text files. We will discuss command output redirection in more detail later in the tutorial. Command output redirection uses the <code>&gt;</code> operator to take the output from one command and \"redirect\" it to a file. The following commands will create a new file named <code>ece6745-tut01.txt</code> that simply contains the text \"Complex Digital ASIC Design\"</p> <pre><code>% echo \"Complex Digital ASIC Design\" &gt; ece6745-tut01.txt\n</code></pre> <p>We can use the <code>cat</code> command to quickly display the contents of a file.</p> <pre><code>% cat ece6745-tut01.txt\n</code></pre> <p>For larger files, <code>cat</code> will output the entire file to the console so it may be hard to read the file as it streams past. We can use the <code>less</code> command to show one screen-full of text at a time. You can use the up/down keys to scroll the file one line at a time, the space bar to scroll down one page at a time, and the <code>q</code> key to quit viewing the file.</p> <pre><code>% less ece6745-tut01.txt\n</code></pre> <p>You can use the <code>ls</code> command to list the filenames of the files you have created.</p> <pre><code>% ls\n</code></pre> <p>We can provide command line options to the <code>ls</code> command to modify the command's behavior. For example, we can use the <code>-1</code> (i.e., a dash followed by the number one) command line option to list one file per line, and we can we can use the <code>-l</code> (i.e., a dash followed by the letter l) command line option to provide a longer listing with more information about each file.</p> <pre><code>% ls -1\n% ls -l\n</code></pre> <p>You should see the newly created <code>ece6745-tut01.txt</code> file along with some additional directories or folders. We will discuss directories in the next section. Use the following commands to create a few more files using the <code>echo</code> command and command output redirection, and then list the files again.</p> <pre><code>% echo \"Application\" &gt; ece6745-tut01-layer1.txt\n% echo \"Algorithm\"   &gt; ece6745-tut01-layer2.txt\n% ls -1\n</code></pre> <p>Activity 3: Create New File</p> <p>Create a new file named <code>ece6745-tut01-layer3.txt</code> which contains the third layer in the computing systems stack (i.e., programming language). Use <code>cat</code> and <code>less</code> to verify the file contents.</p>"},{"location":"ece6745-tut01-linux/#14-create-change-and-list-directories","title":"1.4. Create, Change, and List Directories","text":"<p>Obviously, having all files in a single location would be hard to manage effectively. We can use directories (also called folders) to logically organize our files, just like one can use physical folders to organize physical pieces of paper. The mechanism for organizing files and directories is called the file system. When you first login to an <code>ecelinux</code> machine, you will be in your home directory. This is your own private space on the server that you can use to work on the laboratory assignments and store your files. You can use the <code>pwd</code> command to print the directory in which you are currently working, which is known as the current working directory.</p> <pre><code>% pwd\n/home/netid\n</code></pre> <p>You should see output similar to what is shown above, but instead of <code>netid</code> it should show your actual NetID. The <code>pwd</code> command shows a directory path. A directory path is a list of nested directory names; it describes a \"path\" to get to a specific file or directory. So the above path indicates that there is a toplevel directory named <code>home</code> that contains a directory named <code>netid</code>. This is the directory path to your home directory. As an aside, notice that Linux uses a forward slash (<code>/</code>) to separate directories, while Windows uses a back slash (<code>\\</code>) for the same purpose.</p> <p>We can use the <code>mkdir</code> command to make new directories. The following command will make a new directory named <code>ece6745</code> within your home directory.</p> <pre><code>% mkdir ece6745\n</code></pre> <p>We can use the <code>cd</code> command to change our current working directory. The following command will change the current working directory to be the newly created <code>ece6745</code> directory, before displaying the current working directory with the <code>pwd</code> command.</p> <pre><code>% cd ece6745\n% pwd\n/home/netid/ece6745\n</code></pre> <p>Use the <code>mkdir</code>, <code>cd</code>, and <code>pwd</code> commands to make another directory.</p> <pre><code>% mkdir tut01\n% cd tut01\n% pwd\n/home/netid/ece6745/tut01\n</code></pre> <p>We sometimes say that <code>tut01</code> is a subdirectory or a child directory of the <code>ece6745</code> directory. We might also say that the <code>ece6745</code> directory is the parent directory of the <code>tut01</code> directory.</p> <p>There are some important shortcuts that we can use with the <code>cd</code> command to simplify navigating the file system. The special directory named <code>.</code> (i.e., one dot) always refers to the current working directory. The special directory named <code>..</code> (i.e., two dots) always refers to the parent of the current working directory. The special directory named <code>~</code> (i.e., a tilde character) always refers to your home directory. The special directory named <code>/</code> (e.g., single forward slash) always refers to the highest-level root directory. The following commands illustrate how to navigate up and down the directory hierarchy we have just created.</p> <pre><code>% pwd\n/home/netid/ece6745/tut01\n% cd .\n% pwd\n/home/netid/ece6745/tut01\n% cd ..\n% pwd\n/home/netid/ece6745\n% cd ..\n% pwd\n/home/netid\n% cd ece6745/tut01\n% pwd\n/home/netid/ece6745/tut01\n% cd\n% pwd\n/home/netid\n% cd /\n% pwd\n/\n% cd ~/ece6745\n% pwd\n/home/netid/ece6745\n</code></pre> <p>Notice how we can use the <code>cd</code> command to change the working directory to another arbitrary directory by simply using a directory path (e.g., <code>ece6745/tut01</code>). These are called relative paths because the path is relative to your current working directory. You can also use an absolute path which always starts with the root directory to concretely specify a directory irrespective of the current working directory. A relative path is analogous to directions to reach a destination from your current location (e.g., How do I get to the coffee shop from my current location?), while an absolute path is analogous to directions to reach a destination from a centralized location (e.g., How do I get to the coffee shop from the center of town?).</p> <pre><code>% pwd\n/home/netid/ece6745\n% cd /home/netid/ece6745/tut01\n% pwd\n/home/netid/ece6745/tut01\n% cd\n% pwd\n/home/netid\n</code></pre> <p>This example illustrates one more useful shortcut. The <code>cd</code> command with no command line arguments always changes the current working directory to your home directory. We can use the <code>ls</code> command to list files as well as directories. Use the following commands to create a new file and directory in the <code>ece6745/tut01</code> subdirectory, and then list the file and directory.</p> <pre><code>% cd ~/ece6745/tut01\n% echo \"Computer Systems Programming\" &gt; ece6745-tut01.txt\n% mkdir dirA\n% ls -1\n</code></pre> <p>You should see both the <code>dirA</code> subdirectory and the newly created <code>ece6745-tut01.txt</code> file listed. Feel free to use the <code>cat</code> command to verify the file contents of the newly created file. We can use the <code>tree</code> command to recursively list the contents of a directory. The following commands create a few more directories before displaying the directory hierarchy.</p> <pre><code>% cd ~/ece6745/tut01\n% mkdir -p dirB/dirB_1\n% mkdir -p dirB/dirB_2\n% mkdir -p dirC/dirC_1\n% cd ~/ece6745/tut01\n% tree\n.\n+-- dirA\n+-- dirB\n|   |-- dirB_1\n|   `-- dirB_2\n|-- dirC\n|   `-- dirC_1\n`-- ece6745-tut01.txt\n</code></pre> <p>Note that we are using the <code>-p</code> command line option with the <code>mkdir</code> command to make multiple nested directories in a single step.</p> <p>Activity 4: Creatring Directories and Files</p> <p>Experiment with creating additional directories and files within the <code>ece6745/tut01</code> subdirectory. Try creating deeper hierarchies with three or even four levels of nesting using the <code>-p</code> option to the <code>mkdir</code> command. Experiment with using the <code>.</code> and <code>..</code> special directories. Use the <code>tree</code> command to display your newly created directory hierarchy.</p>"},{"location":"ece6745-tut01-linux/#15-copy-move-and-remove-files-and-directories","title":"1.5. Copy, Move, and Remove Files and Directories}","text":"<p>We can use the <code>cp</code> command to copy files. The first argument is the name of the file you want to copy, and the second argument is the new name to give to the copy. The following commands will make two copies of the files we created in the previous section.</p> <pre><code>% cd ~/ece6745/tut01\n% cp ece6745-tut01.txt ece6745-tut01-a.txt\n% cp ece6745-tut01.txt ece6745-tut01-b.txt\n% ls -1\n</code></pre> <p>We can also copy one or more files into a subdirectory by using multiple source files and a final destination directory as the arguments to the <code>cp</code> command.</p> <pre><code>% cd ~/ece6745/tut01\n% cp ece6745-tut01.txt dirA\n% cp ece6745-tut01-a.txt ece6745-tut01-b.txt dirA\n% tree\n</code></pre> <p>We can use the <code>-r</code> command line option to enable the <code>cp</code> command to recursively copy an entire directory.</p> <pre><code>% cd ~/ece6745/tut01\n% tree\n% cp -r dirA dirD\n% tree\n</code></pre> <p>If we want to move a file or directory, we can use the <code>mv</code> command. As with the <code>cp</code> command, the first argument is the name of the file you want to move and the second argument is the new name of the file.</p> <pre><code>% cd ~/ece6745/tut01\n% mv ece6745-tut01.txt ece6745-tut01-c.txt\n% ls -1\n</code></pre> <p>Again, similar to the <code>cp</code> command, we can also move one or more files into a subdirectory by using multiple source files and a final destination directory as the arguments to the <code>mv</code> command.</p> <pre><code>% cd ~/ece6745/tut01\n% tree\n% mv ece6745-tut01-a.txt dirB\n% mv ece6745-tut01-b.txt ece6745-tut01-c.txt dirB\n% tree\n</code></pre> <p>We do not need to use the <code>-r</code> command line option to move an entire directory at once.</p> <pre><code>% cd ~/ece6745/tut01\n% tree\n% mv dirD dirE\n% tree\n</code></pre> <p>The following example illustrates how we can use the special <code>.</code> directory to move files from a subdirectory into the current working directory.</p> <pre><code>% cd ~/ece6745/tut01\n% tree\n% mv dirE/ece6745-tut01.txt .\n% tree\n</code></pre> <p>We can use the <code>rm</code> command to remove files. The following command removes a file from within the <code>ece6745/tut01</code> subdirectory.</p> <pre><code>% cd ~/ece6745/tut01\n% ls -1\n% rm ece6745-tut01.txt\n% ls -1\n</code></pre> <p>To clean up, we might want to remove the files we created in your home directory earlier in this tutorial.</p> <pre><code>% cd\n% rm ece6745-tut01.txt\n% rm ece6745-tut01-layer1.txt\n% rm ece6745-tut01-layer2.txt\n% rm ece6745-tut01-layer3.txt\n</code></pre> <p>We can use the <code>-r</code> command line option with the <code>rm</code> command to remove entire directories, but please be careful because it is relatively easy to permanently delete many files at once. See Section 2.3 for a useful command that you might want to use instead of the <code>rm</code> command to avoid accidentally deleting important work.</p> <pre><code>% cd ~/ece6745/tut01\n% ls -1\n% rm -r dirA dirB dirC dirE\n% ls -1\n</code></pre> <p>Activity 5: Copy, Move, and Remove Directories and Files</p> <p>Creating additional directories and files within the <code>ece6745/tut01</code> subdirectory, and then use the <code>cp</code>, <code>mv</code>, and <code>rm</code> commands to copy, move, and remove the newly created directories and files. Use the <code>ls</code> and <code>tree</code> commands to display your file and directory organization.</p>"},{"location":"ece6745-tut01-linux/#16-using-wget-to-download-files","title":"1.6. Using <code>wget</code> to Download Files","text":"<p>We can use the <code>wget</code> command to download files from the internet. For now, this is a useful way to retrieve a text file that we can use in the following examples.</p> <pre><code>% cd ~/ece6745/tut01\n% wget http://www.csl.cornell.edu/courses/ece6745/overview.txt\n% cat overview.txt\n</code></pre>"},{"location":"ece6745-tut01-linux/#17-using-grep-to-search-files","title":"1.7. Using <code>grep</code> to Search Files","text":"<p>We can use the <code>grep</code> command to search and display lines of a file that contain a particular pattern. The <code>grep</code> command can be useful for quickly searching the contents of the source files in your laboratory assignments. The command takes the pattern and the files to search as command line arguments. The following command searches \"chip\" in the <code>overview.txt</code> file downloaded in the previous section.</p> <pre><code>% cd ~/ece6745/tut01\n% grep \"chip\" overview.txt\n</code></pre> <p>You should see just the lines within the <code>overview.txt</code> file that contain the words \"digital logic\". We can use the <code>--line-number</code> command line option with the <code>grep</code> command to display the line number of each match.</p> <pre><code>% cd ~/ece6745/tut01\n% grep --line-number \"chip\" overview.txt\n</code></pre> <p>We can use the <code>-r</code> command line option to recursively search all files within a given directory hierarchy. In the following example, we create a subdirectory, copy the <code>overview.txt</code> file, and illustrate how we can use the <code>grep</code> command to recursively search for the word \"digital logic\".</p> <pre><code>% cd ~/ece6745/tut01\n% mkdir dirA\n% cp overview.txt dirA\n% grep -r --line-number \"chip\" .\n</code></pre> <p>Notice how we specify a directory as a command line argument (in this case the special <code>.</code> directory) to search the current working directory. You should see the three lines from both copies of the <code>overview.txt</code> file. The <code>grep</code> command also shows which file contains the match.</p> <p>As another example, we will search two special files named <code>/proc/cpuinfo</code> and <code>proc/meminfo</code>. These files are present on every modern Linux system, and they contain information about the processor and memory hardware in that system. The following command first uses the <code>less</code> command so you can browse the file, and then uses the <code>grep</code> command to search for <code>processor</code> in the <code>/proc/cpuinfo</code> file. Recall that with the <code>less</code> command, we use the up/down keys to scroll the file one line at a time, the space bar to scroll down one page at a time, and the <code>q</code> key to quit viewing the file.</p> <pre><code>% cd ~/ece6745/tut01\n% less /proc/cpuinfo\n% grep \"processor\" /proc/cpuinfo\n</code></pre> <p>It should be pretty clear that you are using a system with multiple processors. You can also search to find out which company makes the processors and what clock frequency they are running at:</p> <pre><code>% cd ~/ece6745/tut01\n% grep \"vendor_id\" /proc/cpuinfo\n% grep \"cpu MHz\" /proc/cpuinfo\n</code></pre> <p>We can find out how much memory is in the system by searching for <code>MemTotal</code> in the <code>/proc/meminfo</code> file.</p> <pre><code>% cd ~/ece6745/tut01\n% grep \"MemTotal\" /proc/meminfo\n</code></pre> <p>Activity 6: Experimenting with <code>grep</code></p> <p>Try using <code>grep</code> to search for the words \"computer\" in the <code>overview.txt</code> file.</p>"},{"location":"ece6745-tut01-linux/#18-using-find-to-find-files","title":"1.8. Using <code>find</code> to Find Files","text":"<p>We can use the <code>find</code> command to recursively search a directory hierarchy for files or directories that match a specified criteria. While the <code>grep</code> command is useful for searching file contents, the <code>find</code> command is useful for quickly searching the file and directory names in your laboratory assignments. The <code>find</code> command is very powerful, so we will just show a very simple example. First, we create a few new files and directories.</p> <pre><code>% cd ~/ece6745/tut01\n% mkdir -p dirB/dirB_1\n% mkdir -p dirB/dirB_2\n% mkdir -p dirC/dirC_1\n% echo \"test\" &gt; dirA/file0.txt\n% echo \"test\" &gt; dirA/file1.txt\n% echo \"test\" &gt; dirB/dirB_1/file0.txt\n% echo \"test\" &gt; dirB/dirB_1/file1.txt\n% echo \"test\" &gt; dirB/dirB_2/file0.txt\n% tree\n</code></pre> <p>We will now use the <code>find</code> command to find all files named <code>file0.txt</code>. The <code>find</code> command takes one command line argument to specify where we should search and a series of command line options to describe what files and directories we are trying to find. We can also use command line options to describe what action we would like to take when we find the desired files and directories. In this example, we use the <code>--name</code> command line option to specify that we are searching for files with a specific name. We can also use more complicated patterns to search for all files with a specific filename prefix or extension.</p> <pre><code>% cd ~/ece6745/tut01\n% find . -name \"file0.txt\"\n</code></pre> <p>Notice that we are using the special <code>.</code> directory to tell the <code>find</code> command to search the current working directory and all subdirectories. The <code>find</code> command always searches recursively.</p> <p>Activity 7: Experimenting with <code>find</code></p> <p>Create additional files named <code>file2.txt</code> in some of the subdirectories we have already created. Use the <code>find</code> command to search for files named <code>file2.txt</code>.</p>"},{"location":"ece6745-tut01-linux/#19-using-tar-to-archive-files","title":"1.9. Using <code>tar</code> to Archive Files","text":"<p>We can use the <code>tar</code> command to \"pack\" files and directories into a simple compressed archive, and also to \"unpack\" these files and directories from the archive. This kind of archive is sometimes called a tarball. Most open-source software is distributed in this compressed form. It makes it easy to distribute code among collaborators and it is also useful to create backups of files. We can use the following command to create an archive of our tutorial directory and then remove the tutorial directory.</p> <pre><code>% cd ~/ece6745\n% tar -czvf tut01.tgz tut01\n% rm -r tut01\n% ls -l\n</code></pre> <p>Several command line options listed together as a single option (<code>-czvf</code>), where <code>c</code> specifies we want to create an archive, <code>z</code> specifies we should use \"gzip\" compression, <code>v</code> specifies verbose mode, and <code>f</code> specifies we will provide filenames to archive. The first command line argument is the name of the archive to create, and the second command line argument is the directory to archive. We can now extract the contents of the archive to recreate the tutorial directory. We also remove the archive.</p> <pre><code>% cd ~/ece6745\n% tar -xzvf tut01.tgz\n% rm tut01.tgz\n% tree tut01\n</code></pre> <p>Note that we use the <code>x</code> command line option with the <code>tar</code> command to specify that we intend to extract the archive.</p> <p>Activity 8: Experimenting with <code>tar</code></p> <p>Create an example directory within the <code>ece6745/tut01</code> subdirectory. Copy the <code>overview.txt</code> file and rename it to add example files to your new directory. Use the <code>tar</code> command to create and extract an archive of just this one new directory.</p>"},{"location":"ece6745-tut01-linux/#110-using-top-to-view-running-processes","title":"1.10. Using <code>top</code> to View Running Processes","text":"<p>You can use the <code>top</code> command to view what commands are currently running on the Linux system in realtime. This can be useful to see if there are many commands running which are causing the system to be sluggish. When finished you can use the <code>q</code> character to quit.</p> <pre><code>% top\n</code></pre> <p>The first line of the <code>top</code> display shows the number of users currently logged into the system, and the load average. The load average indicates how \"overloaded\" the system was over the last one, five, and 15 minutes. If the load average is greater than the number of processors in the system, it means your system will probably be sluggish. You can always try logging out and then back into the <code>ecelinux</code> servers to see if you get assigned to a different server in the cluster.</p>"},{"location":"ece6745-tut01-linux/#111-environment-variables","title":"1.11. Environment Variables","text":"<p>In the previous sections, we have been using the Bash shell to run various commands, but the Bash shell is actually a full-featured programming language. One aspect of the shell that is similar in spirit to popular programming languages, is the ability to write and read environment variables. The following commands illustrate how to write an environment variable named <code>ece6745_tut01_layer1</code>, and how to read this environment variable using the <code>echo</code> command.</p> <pre><code>% ece6745_tut01_layer1=\"application\"\n% echo ${ece6745_tut01_layer1}\n</code></pre> <p>Keep in mind that the names of environment variables can only contain letters, numbers, and underscores. Notice how we use the <code>${}</code> syntax to read an environment variable. There are a few built-in environment variables that might be useful:</p> <pre><code>% echo ${HOSTNAME}\n% echo ${HOME}\n% echo ${PWD}\n</code></pre> <p>We often use the <code>HOME</code> environment variable in directory paths like this:</p> <pre><code>% cd ${HOME}/ece6745\n</code></pre> <p>The <code>PWD</code> environment variable always holds the current working directory. We can use environment variables as options to commands other than <code>echo</code>. A common example is to use an environment variable to \"remember\" a specific directory location, which we can quickly return to with the <code>cd</code> command like this:</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% TUT01=${PWD}\n% cd\n% pwd\n/home/netid\n% cd ${TUT01}\n% pwd\n/home/netid/ece6745/tut01\n</code></pre> <p>Activity 9: Experimenting with Environment Variables</p> <p>Create a new environment variable named <code>ece6745_tut01_layer2</code> and write it with the second layer in the computer systems stack (i.e., algorithm). Use the <code>echo</code> command to display this environment variable. Experiment with creating a new subdirectory within <code>ece6745/tut01</code> and then using an environment variable to \"remember\" that location.</p>"},{"location":"ece6745-tut01-linux/#112-command-output-redirection","title":"1.12. Command Output Redirection","text":"<p>We have already seen using the <code>echo</code> command and command output redirection to create simple text files. Here is another example:</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% echo \"Application\" &gt; computing-stack.txt\n% cat computing-stack.txt\n</code></pre> <p>The <code>&gt;</code> operator tells the Bash shell to take the output from the command on the left and overwrite the file named on the right. We can use any command on the left. For example, we can save the output from the <code>pwd</code> command or the <code>man</code> command to a file for future reference.</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% pwd &gt; cmd-output.txt\n% cat cmd-output.txt\n% man pwd &gt; cmd-output.txt\n% cat cmd-output.txt\n</code></pre> <p>We can also use the <code>&gt;&gt;</code> operator which tells the Bash shell to take the output from the command on the left and append the file named on the right. We can use this to create multiline text files:</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% echo \"Application\"           &gt; computing-stack.txt\n% echo \"Algorithm\"            &gt;&gt; computing-stack.txt\n% echo \"Programming Language\" &gt;&gt; computing-stack.txt\n% echo \"Operating System\"     &gt;&gt; computing-stack.txt\n% cat computing-stack.txt\n</code></pre> <p>Activity 10: Experimenting with Output Redirection</p> <p>Add the remaining levels of the computing stack (i.e., compiler, instruction-set architecture, microarchitecture, register-transfer-level, gate-level, circuits, devices, technology) to the <code>computing-stack.txt</code> text file. Use the <code>cat</code> command to verify the file contents.</p>"},{"location":"ece6745-tut01-linux/#113-command-chaining","title":"1.13. Command Chaining","text":"<p>We can use the <code>&amp;&amp;</code> operator to specify two commands that we want to chaining together. The second command will only execute if the first command succeeds. Below is an example.</p> <pre><code>% cd ${HOME}/ece6745/tut01 &amp;&amp; cat computing-stack.txt\n</code></pre> <p>Activity 11: Experimenting with Command Chaining</p> <p>Create a single-line command that combines creating a new directory with the <code>mkdir</code> command and then immediately changes into the directory using the <code>cd</code> command.</p>"},{"location":"ece6745-tut01-linux/#114-command-pipelining","title":"1.14. Command Pipelining","text":"<p>The Bash shell allows you to run multiple commands simultaneously, with the output of one command becoming the input to the next command. We can use this to assemble \"pipelines\"; we \"pipe\" the output of one command to another command for further actions using the <code>|</code> operator.</p> <p>The following example uses the <code>grep</code> command to search the special <code>proc/cpuinfo</code> file for lines containing the word \"processor\" and then pipes the result to the <code>wc</code> command. The <code>wc</code> command counts the number of characters, words, or lines of its input. We use the <code>-l</code> command line option with the <code>wc</code> command to count the number of lines.</p> <pre><code>% grep processor /proc/cpuinfo | wc -l\n</code></pre> <p>This is a great example of the Linux philosophy of providing many simple commands that can be combined to create more powerful functionality. Essentially the pipeline we have created is a command that tells us the number of processors in our system.</p> <p>As another example, we will pipe the output of the <code>last</code> command to the <code>grep</code> command. The <code>last</code> command lists the names of all of the users that have logged into the system since the system was rebooted. We can use <code>grep</code> to search for your NetID and thus quickly see how when you previously have logged into this system.</p> <pre><code>% last | grep netid\n</code></pre> <p>We can create even longer pipelines. The following pipeline will report the number of times you have logged into the system since it was rebooted.</p> <pre><code>% last | grep netid | wc -l\n</code></pre> <p>Activity 12: Experimenting with Command Pipelines</p> <p>Use the <code>cat</code> command with the <code>overview.txt</code> file and pipe the output to the <code>grep</code> command to search for the word \"\"memories\". While this is not as fast as using <code>grep</code> directly on the file, it does illustrate how many commands (e.g., <code>grep</code>) can take their input specified as a command line argument or through a pipe.</p>"},{"location":"ece6745-tut01-linux/#114-bash-shell-scripts","title":"1.14. Bash Shell Scripts","text":"<p>If you find yourself continually having to use the same complex commands over and over, consider creating a Bash shell script to automatically execute those commands. A Bash shell script is just a text file with a list of commands that you can run using the <code>source</code> command.</p> <p>For example, let's create a Bash shell script to automatically grep for information about the processor and memory in a single step. Use VS Code to open a new file called <code>get-processor-memory-info.sh</code> (note that by convention we usually use the <code>.sh</code> extension for Bash shell scripts).</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% code get-processor-memory-info.sh\n</code></pre> <p>Then enter the following commands into this new Bash shell script.</p> <pre><code>grep \"processor\" /proc/cpuinfo\ngrep \"vendor_id\" /proc/cpuinfo\ngrep \"cpu MHz\"   /proc/cpuinfo\ngrep \"MemTotal\"  /proc/meminfo\n</code></pre> <p>Then save the Bash shell script and execute it using the <code>source</code> command.</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% source get-processor-memory-info.sh\n</code></pre> <p>Activity 13: Experimenting with Bash Shell Scripts</p> <p>Create a new Bash shell script named <code>wget-and-grep.sh</code>. The Bash shell script should use <code>wget</code> to get the <code>overview.txt</code> file for the course and then uses grep to find instances of the word \"chip\" in this file. See earlier examples in this tutorial for the commands required for both steps. Then use <code>source</code> to execute the new Bash shell script.</p>"},{"location":"ece6745-tut01-linux/#115-aliases-wildcards-command-history-and-tab-completion","title":"1.15. Aliases, Wildcards, Command History, and Tab Completion","text":"<p>In this section, we describe some miscellaneous features of the Bash shell which can potentially be quite useful in increasing your productivity.</p> <p>Aliases are a way to create short names for command sequences to make it easier to quickly execute those command sequences in the future. For example, assume that you frequently want to change to a specific directory. We can create an alias to make this process take just two keystrokes.</p> <pre><code>% alias ct=\"cd ${HOME}/ece6745/tut01\"\n% ct\n% pwd\n/home/academic/netid/ece6745/tut01\n</code></pre> <p>If you always want this alias to be available whenever you login to the system, you can save it in your <code>.bashrc</code> file. The <code>.bashrc</code> is a special Bash script that is run on every invocation of a Bash shell.</p> <pre><code>% echo \"alias ct=\\\"cd ${HOME}/ece6745/tut01\\\"\" &gt;&gt; ${HOME}/.bashrc\n</code></pre> <p>The reason we have to use a back slash (<code>\\</code>) in front of the double quotes is to make sure the <code>echo</code> command sees this command line argument as one complete string.</p> <p>Wildcards make it easy to manipulate many files and directories at once. Whenever we specify a file or directory on the command line, we can often use a wildcard instead. In a wildcard, the asterisk (<code>*</code>) will match any sequence of characters. The following example illustrates how to list all files that end in the suffix <code>.txt</code> and then copies all files that match the wildcard from one directory to another.</p> <pre><code>% cd ${HOME}/ece6745/tut01\n% ls *.txt\n% cp dirA/file*.txt dirB\n% tree\n</code></pre> <p>The Bash shell keeps a history of everything you do at the command line. You can display the history with the <code>history</code> command. To rerun a previous command, you can use the <code>!</code> operator and the corresponding command number shown with the <code>history</code> command.</p> <pre><code>% history\n</code></pre> <p>You can pipe the output of the <code>history</code> command to the <code>grep</code> command to see how you might have done something in the past.</p> <pre><code>% history | grep wc\n</code></pre> <p>If you press the up arrow key at the command line, the Bash shell will show you the previous command you used. Continuing to press the up/down keys will enable you to step through your history. It is very useful to press the up arrow key once to rerun your last command.</p> <p>The Bash shell supports tab completion. When you press the tab key twice after entering the beginning of a filename or directory name, Bash will try to automatically complete the filename or directory name. If there is more than one match, Bash will show you all of these matches so you can continue narrowing your search.</p>"},{"location":"ece6745-tut01-linux/#2-course-specific-linux-commands","title":"2. Course-Specific Linux Commands","text":"<p>In this section, we describe various aspects of the development environment that are specific to the severs used in the course.</p>"},{"location":"ece6745-tut01-linux/#21-course-setup-script","title":"2.1. Course Setup Script","text":"<p>As discussed in the remote access tutorial, the very first thing you need to do after logging into the <code>ecelinux</code> servers is source the course setup script. This will ensure your environment is setup with everything you need for working on the laboratory assignments. Enter the following command on the command line:</p> <pre><code>% source setup-ece6745.sh\n</code></pre> <p>You should now see <code>ECE 6745</code> in your prompt which means your environment is setup for the course.</p> <p>It can be tedious to always remember to source the course setup script. You can also use auto setup which will automatically source the course setup for you when you open a terminal. Note that if the environment for ECE 6745 conflicts with the environment required by a different course then you will need to manually source the setup script when you are working on this course. Enter the following command on the command line to use auto setup:</p> <pre><code>% source setup-ece6745.sh --enable-auto-setup\n</code></pre> <p>Now close the terminal and log out completely from the <code>ecelinux</code> servers. Log back in and you should see <code>ECE 6745</code> in the prompt meaning your environment is automatically setup for the course. If at anytime you need to disable auto setup you can use the following command:</p> <pre><code>% source setup-ece6745.sh --disable-auto-setup\n</code></pre> <p>Again, if for any reason running the setup script prevents you from using tools for another course, you cannot use the auto setup. You will need to run the setup script manually every time you want to work on this course.</p>"},{"location":"ece6745-tut01-linux/#22-using-quota-to-check-your-space-usage","title":"2.2. Using <code>quota</code> to Check Your Space Usage","text":"<p>Students are allocated 10GB of storage on the servers. You can use the following command to show much space you are using:</p> <pre><code>% quota -s\n</code></pre> <p>The <code>blocks</code> column is how much data you are using, and the <code>quota</code> column is your quota. If you have exceed the 10GB quota, you can browse your home directory and list the size of files and the contents of directories with the <code>du</code> command:</p> <pre><code>% cd ${HOME}\n% du -sh *\n</code></pre> <p>By recursively changing directories and examining the sizes of files and directories you can figure out what you need to delete. We can pipe the output of <code>du</code> to the <code>sort</code> and <code>head</code> commands to find the top 20 largest files and directories like this:</p> <pre><code>% cd ${HOME}\n% du -xak . | sort -nr | head --lines=20\n</code></pre> <p>Or just use the following to generate a human readable summary of the size of files/directories in the current working directory. Note that it can take 20--30 seconds for this command to finish, so please be patient.</p>"},{"location":"ece6745-tut01-linux/#23-using-trash-to-safely-remove-files","title":"2.3. Using <code>trash</code> to Safely Remove Files","text":"<p>We have installed a simple program called <code>trash</code> which moves files you wish to delete into a special subdirectory of your home directory located at <code>${HOME}/tmp/trash</code>. The following commands create a file and then deletes it using <code>trash</code>.</p> <pre><code>% cd ${HOME}\n% echo \"This file will be deleted.\" &gt; testing.txt\n% trash testing.txt\n% echo \"This file will also be deleted.\" &gt; testing.txt\n% trash testing.txt\n% ls ${HOME}/tmp/trash\n</code></pre> <p>If you look in <code>${HOME}/tmp/trash</code> you will see subdirectories organized by date. Look in the subdirectory with today's date and you should two files corresponding to the two files you deleted. We highly recommend always using the <code>trash</code> command instead of <code>rm</code> since this avoids accidentally deleting your work.</p>"},{"location":"ece6745-tut02-git/","title":"Tutorial 2: Git Distributed Version Control System","text":"<p>In this course, we will be using Git as our revision control and source code management system. We will be using GitHub for centralized online repository hosting, and GitHub Actions for online continuous integration testing. These tools will enable us to adopt an agile hardware development methodology so your group can rapidly collaborate and iterate on the design, verification, and evaluation of the lab assignments. This tutorial covers how to: setup your GitHub account, use Git for basic incremental development, use GitHub to collaborate with your group, manage Git branches and GitHub pull requests, and use GitHub actions. This tutorial assumes that you have completed the remote access and Linux tutorials.</p> <p>Before you begin, make sure that you have logged into the <code>ecelinux</code> servers as described in the remote access tutorial. You will need to open a terminal and be ready to work at the Linux command line using VS Code. To follow along with the tutorial, type the commands without the <code>%</code> character. In addition to working through the commands in the tutorial, you should also try the more open-ended activities.</p> <p>Before you begin, make sure that you have sourced the setup-ece6745.sh script or that you have enabled auto setup. Sourcing the setup script sets up the environment required for this tutorial.</p>"},{"location":"ece6745-tut02-git/#1-setting-up-your-github-account","title":"1. Setting up Your GitHub Account","text":"<p>GitHub is an online service that hosts centralized Git repositories for a growing number of open-source projects. It has many useful features including a web-based source browser, history browser, branch management, merge requests, code review, issue tracking, and even a built-in wiki attached to every repository. We have created a dedicated GitHub organization for the course located here:</p> <ul> <li>https://github.com/cornell-ece6745</li> </ul> <p>The course staff will add all officially registered students to the course organization. For most of this tutorial you will be using a public repository in your own personal GitHub account, but you will be using a private repository in our course GithHub organization for all of your lab assignments. Note that we will not be using the version of GitHub hosted at Cornell We will instead be using the public version of GitHub at <code>github.com</code>. You can check to see if you have a GitHub account on the public version of GitHub here:</p> <ul> <li>https://github.com/githubid</li> </ul> <p>where <code>githubid</code> is your GitHub username on the public version of GitHub. You must replace <code>githubid</code> with your real GitHub username for this link to work! If the above link still does not work, then you do not have an account on the public version of GitHub. You will need to create one here:</p> <ul> <li>https://github.com/join</li> </ul> <p>Your NetID makes a great GitHub username. If you are creating a new GitHub account, then be sure to use your Cornell email address. If you have an existing account it is fine for it to use a non-Cornell email address. Once your account is setup, please make sure you set your full name so we can know who you are on GitHub. Please also consider uploading a profile photo to GitHub; it makes it more fun to interact on GitHub if we all know what each other look like. Go to the following page and enter your first and last name in the Name field, and then consider uploading a profile photo.</p> <ul> <li>https://github.com/settings/profile</li> </ul> <p>Once you have a GitHub username, please fill out the following form on Canvas so the instructors know the mapping from your NetID to your GitHub username.</p> <ul> <li>http://www.csl.cornell.edu/courses/ece6745/githubid</li> </ul> <p>Before you can begin using GitHub, you need to create an SSH key pair on an <code>ecelinux</code> machine and upload the corresponding SSH public key to GitHub. GitHub uses these keys for authentication. The course setup script takes care of creating an SSH key pair which you can use. Login to an <code>ecelinux</code> machine, source the course setup script, and then view the contents of your public key using the following commands:</p> <pre><code>% source setup-ece6745.sh\n% cat ~/.ssh/ece6745-github.pub\n</code></pre> <p>Use the following page to upload the public key to GitHub:</p> <ul> <li>https://github.com/settings/ssh</li> </ul> <p>Click on New SSH Key, and then cut-and-paste the public key you displayed using <code>cat</code> into the key textbox. Give the key the title \"ece6745-github\". Then click Add SSH key. To test things out try the following on an <code>ecelinux</code> machine.</p> <pre><code>% ssh -T git@github.com\n</code></pre> <p>You may see a warning about the authenticity of the host. Don't worry, this is supposed to happen the first time you access GitHub using your new key. Just enter \"yes\". The GitHub server should output some text including your GitHub username. Verify that the GitHub username is correct, and then you should be all set. There are two good GitHub Guides you might want to take a look at:</p> <ul> <li>https://guides.github.com/activities/hello-world</li> <li>https://guides.github.com/introduction/flow</li> </ul> <p>GitHub has two integrated tools that students might find useful: an issue tracker and a wiki. Consider using the GitHub issue tracker to track bugs you find in your code or to manage tasks required to complete the lab assignment. You can label issues, comment on issues, and attach them to commits. See the following links for more information about GitHub issues:</p> <ul> <li>https://help.github.com/articles/about-issues</li> </ul> <p>Consider using the GitHub per-repository wiki to create task lists, brainstorm design ideas, rapidly collaborate on text for the lab assignment report, or keep useful command/code snippets. See the following links for more information about GitHub wikis:</p> <ul> <li>https://help.github.com/articles/about-github-wikis</li> </ul>"},{"location":"ece6745-tut02-git/#2-git-and-github","title":"2. Git and GitHub","text":"<p>In this section, we begin with a basic single-user workflow before demonstrating how Git and Github can be used for effective collaboration among multiple users. We discuss how to resolve conflicts and how to manage branches and pull requests.</p>"},{"location":"ece6745-tut02-git/#21-single-user-workflow","title":"2.1. Single-User Workflow","text":"<p>In this section, we cover some basic Git commands and illustrate a simple Git workflow. We have created a Git repository that we will be using as an initial template, so the first step is to fork this tutorial repository. Forking is the process of making a personal copy of someone else's repository on GitHub. Start by going to the GitHub page for the tutorial repository located here:</p> <ul> <li>https://github.com/cornell-ece6745/ece6745-tut02-git</li> </ul> <p></p> <p>Click on Fork in the upper right-hand corner. If asked where to fork this repository, choose your personal GitHub account. After a few seconds, you should have a brand new repository in your account:</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git</li> </ul> <p>Where <code>githubid</code> is your GitHub username on the public version of GitHub. Now that you have your own copy of the tutorial repository, the next step is to clone this repository to an <code>ecelinux</code> machine so you can manipulate the content within the repository. We call the repository on GitHub the remote repository and we call the repository on the <code>ecelinux</code> machine the local repository. A local repository is a first-class mirror of the remote repository with the entire history of the repository, and thus almost all operations are essentially local requiring no communication with GitHub. The following commands write an environment variable with your GitHub username, create a subdirectory for this tutorial in your home directory before using the <code>git clone</code> command to clone the remote repository and thus create a local repository.</p> <pre><code>% source setup-ece6745.sh\n% GITHUBID=\"githubid\"\n% mkdir -p ${HOME}/ece6745\n% cd ${HOME}/ece6745\n% git clone git@github.com:${GITHUBID}/ece6745-tut02-git tut02\n% cd tut02\n% TUTROOT=${PWD}\n</code></pre> <p>Where again <code>githubid</code> is your GitHub username on the public version of GitHub. The <code>git clone</code> command takes two command line arguments. The first argument specifies the remote repository on GitHub you would like to clone, and the second argument specifies the name to give to the new local repository. Note that we created an environment variable with the directory path to the local repository to simplify navigating the file system in the rest of this tutorial.</p> <p>The repository currently contains two files: a <code>README</code> file, and <code>overview.txt</code> which contains an overview of the course. These files are contained within what we call the working directory. The repository also includes a special directory named <code>.git</code> which contains all of the extra repository metadata. You should never directly manipulate anything within the <code>.git</code> directory.</p> <pre><code>% cd ${TUTROOT}\n% ls -la\n</code></pre> <p>Let's assume we want to create a new file that contains a list of fruits, and that we want to manage this file using Git version control. First, we create the new file.</p> <pre><code>% cd ${TUTROOT}\n% echo \"apple\" &gt; fruit.txt\n</code></pre> <p>To manage a file using Git, we need to first use the <code>git add</code> command to tell Git that it should track this file from now on. We can then use <code>git commit</code> to commit our changes to this file into the repository, and <code>git log</code> to confirm the result.</p> <pre><code>% cd ${TUTROOT}\n% git add fruit.txt\n% git commit -m \"initial fruit list\"\n% git log\n</code></pre> <p>The <code>-m</code> command line option with the <code>git commit</code> command enables you to specify a commit message that describes this commit. All commit messages should include a \"subject line\" which is a single short line briefly describing the commit. Many commits will just include a subject line (e.g., the above commit). If you want to include more information in your commit message then skip the <code>-m</code> command line option and Git will launch Nano. You still want to include a subject line at the top of your commit message, but now you can include more information separated from the subject line by a blank line.</p> <p>Note, you can learn about any Git command and its usage by typing <code>git help command</code>, where <code>command</code> should be substituted by the actual name of the command. This would display the output similar to the manual pages for a Linux command, as seen in Tutorial 1. Students are encouraged to learn more about each Git command beyond the details covered in this tutorial.</p> <p>The <code>git log</code> command displays information about the commit history. The beginning of the output from <code>git log</code> should look something like this:</p> <pre><code>commit a8ac41ea8dba1371888ec7a2341f79de20521a4d (HEAD -&gt; main)\nAuthor: cb &lt;cb535@cornell.edu&gt;\nDate:   Mon Sep 2 13:17:32 2024 -0400\n\n    initial fruit list\n</code></pre> <p>Conceptually, we should think of each commit as a copy of all of the tracked files in the project at the time of the commit. This commit just included changes to one file, but as we add more files each commit will include more and more information. The history of a git repository is just a long sequence of commits that track how the files in the repository have evolved over time. Notice that Git has recorded the name of who made the commit, the date and time of the commit, and the log message. The first line is the commit id which uniquely identifies this commit. Git does not use monotonically increasing revision numbers like other version control systems, but instead uses a 40-digit SHA1 hash as the commit id. This is a hash of all the files included as part of this commit (not just the changes). We can refer to a commit by the full hash or by just the first few digits as long as we provide enough digits to unambiguously reference the commit. Now let's add a fruit to our list and commit the change.</p> <pre><code>% cd ${TUTROOT}\n% echo \"mango\" &gt;&gt; fruit.txt\n% git commit -m \"added mango to fruit list\"\n</code></pre> <p>Unfortunately, this doesn't work. The output from <code>git commit</code> indicates that there have been no changes since the last commit so there is no need to create a new commit. Git has a concept of an index which is different compared to other version control systems. We must \"stage\" files (really we stage content not files) into the index, and then <code>git commit</code> will commit that content into the repository. We can see this with the <code>git status</code> command.</p> <pre><code>% cd ${TUTROOT}\n% git status\n</code></pre> <p>which should show that <code>fruit.txt</code> is modified but not added to the index. We stage files in the index with <code>git add</code> like this:</p> <pre><code>% cd ${TUTROOT}\n% git add fruit.txt\n% git status\n</code></pre> <p>Now <code>git status</code> should show that the file is modified and also added to the index. Our commit should now complete correctly.</p> <pre><code>% cd ${TUTROOT}\n% git commit -m \"added mango to fruit list\"\n% git status\n</code></pre> <p>So even though Git is tracking <code>fruit.txt</code> and knows it has changed, we still must explicitly add the files we want to commit. You definitely want to avoid using something like <code>git add .</code> to add all files, since this will inevitably end up adding files that you don't really want to commit. There is a short cut which uses the <code>-a</code> command line option with the <code>git commit</code> command. This command line option tells Git to add any file which has changed and was previously added to the repository before doing the commit.</p> <pre><code>% cd ${TUTROOT}\n% echo \"orange\" &gt;&gt; fruit.txt\n% git commit -a -m \"added orange to fruit list\"\n% git status\n</code></pre> <p>Staging files is a useful way to preview what we will commit before we actually do the commit. This helps when we have many changes in our working directory but we don't want to commit them all at once. Instead we might want to break them into smaller, more meaningful commits or we might want to keep working on some of the modified files while committing others.</p> <p>The following figure illustrates how the commands we have used so far create a single-user development workflow. The <code>git clone</code> command copies the remote repository to create a local repository which includes both the working directory and the special <code>.git</code> directory. The <code>git add</code> command adds files to the index from the working directory. The <code>git commit</code> command moves files from the index into the special <code>.git</code> directory. The <code>-a</code> command line option with the <code>git commit</code> command can commit files directly from the working directory to the special <code>.git</code> directory.</p> <p></p> <p>Now that we have made some changes, we can use <code>git log</code> to view the history of last few commits and then add another line to the <code>fruit.txt</code> file.</p> <pre><code>% cd ${TUTROOT}\n% git log\n% echo \"plum\" &gt;&gt; fruit.txt\n% cat fruit.txt\n</code></pre> <p>Imagine you didn't like your changes and want to revert the changes, you would use the <code>git checkout</code> command as below.</p> <pre><code>% cd ${TUTROOT}\n% git checkout fruit.txt\n% cat fruit.txt\n</code></pre> <p>As illustrated in the above single-user development workflow figure, the <code>git checkout</code> command resets any a file or directory to the state it was in at the time of the last commit. The output from the <code>git status</code> command should look something like this:</p> <pre><code>% cd ${TUTROOT}\n% git status\n On branch main\n Your branch is ahead of 'origin/main' by 3 commits.\n   (use \"git push\" to publish your local commits)\n nothing to commit, working directory clean\n</code></pre> <p>The <code>git status</code> command is telling us that the local clone of the repository now has more commits than the remote repository on GitHub. If you visit the GitHub page for this repository you will not see any changes. This is a critical difference from other centralized version control systems. In Git, when we use the <code>git commit</code> command it only commits these changes to your local repository.</p> <p>If we have done some local work that we are happy with, we can push these changes to the remote repository on GitHub using the <code>git push</code> command.</p> <pre><code>% cd ${TUTROOT}\n% git push\n% git status\n</code></pre> <p>Notice that the output of the <code>git status</code> command indicates that our local repository is up-to-date with the remote repository on GitHub. The above single-user development workflow figure shows visually the idea that the <code>git push</code> command moves commits from your local repository to the remote repository on GitHub. Visit the GitHub page to verify that our new commits have been pushed to the remote repository:</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git</li> </ul> <p>Click on commits at the top of the GitHub page to view the log of commits. You can browse who made each commit, what changed in each commit, and the state of the repository at each commit. Return to the main GitHub page for the repository and click on the <code>fruit.txt</code> file to view it.</p> <p>Activity 1: Experiment with Commiting Files</p> <p>Create a new file called <code>shapes.txt</code> that includes a list of different shapes. Commit the new file, make some edits, and commit these edits. Use <code>git status</code> and <code>git log</code> to keep track of your changes. Push your changes to GitHub and browse the updated files on GitHub.</p>"},{"location":"ece6745-tut02-git/#22-multi-user-workflow","title":"2.2. Multi-User Workflow","text":"<p>Since your tutorial repository is public on GitHub, any other user can also clone this repository. If you would like to collaborate with another GitHub user, you would need to give that user read/write permission. The instructors will take care of setting up the appropriate teams for the lab assignments when you work with a partner. To emulate how collaboration with GitHub works, we will \"pretend\" to be different users by cloning extra copies of the tutorial repository.</p> <pre><code>% cd ${HOME}/ece6745\n% git clone git@github.com:${GITHUBID}/ece6745-tut02-git tut02-alice\n% cd tut02-alice\n% ALICE=${PWD}\n% cd ${HOME}/ece6745\n% git clone git@github.com:${GITHUBID}/ece6745-tut02-git tut02-bob\n% cd tut02-bob\n% BOB=${PWD}\n</code></pre> <p>We can now emulate different users by simply working in these different local repositories: when we work in <code>ALICE</code> we will be acting as the user Alice, and when we work in <code>BOB</code> we will be acting as the user Bob. The following figure illustrates a multi-user development environment: both Alice and Bob have their own separate local repositories (including their own working directories, index, and special <code>.git</code> directories), yet they will both communicate with the same centralized remote repository on GitHub.</p> <p></p> <p>Let's have Alice add another entry to the <code>fruit.txt</code> file, commit her changes to her local repository, and then push those commits to the remote repository on GitHub:</p> <pre><code>% cd ${ALICE}\n% echo \"banana\" &gt;&gt; fruit.txt\n% git commit -a -m \"ALICE: added banana to fruit list\"\n% git log --oneline\n% git push\n% cat fruit.txt\n</code></pre> <p>If you view the GitHub page for this repository it will appear that you are the one making the commit (remember we are just pretending to be Alice), which is why we used <code>ALICE:</code> as a prefix in the commit message.</p> <p>Now let's assume Bob wants to retrieve the changes that Alice just made to the repository. Bob can use the <code>git pull</code> command to pull all new commits from the remote repository into his local repository. The <code>git pull</code> command performs two actions, it first fetches all the updates and then merges or applies them to the local project. If there are no conflicts in the file contents, the command executes successfully. If there are conflicts, the command does not merge all the changes and reports the conflicting content. We will learn how to resolve conflicts in a later section.</p> <pre><code>% cd ${BOB}\n% git pull\n% git log --oneline\n% cat fruit.txt\n</code></pre> <p>The multi-user development workflow figure shows visually the idea that the <code>git pull</code> command moves commits from the remote repository on GitHub to your local repository. Bob's copy of tutorial repository should contain Alice's most recent commit and his copy of the <code>fruits.txt</code> file should include <code>banana</code>. Now let's assume Bob also wants to make some changes and push those changes to the remote repository on GitHub:</p> <pre><code>% cd ${BOB}\n% echo \"peach\" &gt;&gt; fruit.txt\n% git commit -a -m \"BOB: added peach to fruit list\"\n% git log --oneline\n% git push\n% cat fruit.txt\n</code></pre> <p>Similar to before, Alice can now retrieve the changes that Bob just made to the repository using the <code>git pull</code> command.</p> <pre><code>% cd ${ALICE}\n% git pull\n% git log --oneline\n% cat fruit.txt\n</code></pre> <p>This process is at the key to collaborating via GitHub. Each student works locally on his or her part of the lab assignment and periodically pushes/pulls commits to synchronize with the remote repository on GitHub.</p> <p>Activity 2: Experimenting with a Multi-User Workflow</p> <p>Create a new file called <code>letters.txt</code> in Bob's local repository that includes a list of letters from A to M, one per line. Commit the new file, make some edits to add say more letters from say M to Z, and commit these edits. Use <code>git push</code> to push these commits to the centralized repository. Switch to Alice's local repository and use <code>git pull</code> to pull in the new commits. Verify that all of your files and commits are in both Bob's and Alice's local repositories.</p>"},{"location":"ece6745-tut02-git/#23-resolving-conflicts","title":"2.3. Resolving Conflicts","text":"<p>Of course the real challenge occurs when both Alice and Bob modify content at the same time. There are two possible scenarios: Alice and Bob modify different content such that it is possible to combine their commits without issue, or Alice and Bob have modified the exact same content resulting in a conflict. We will address how to resolve both scenarios.</p> <p>Let us assume that Alice wants to add <code>lemon</code> to the list and Bob would like to create a new file named <code>vegetables.txt</code>. Alice would go ahead and first pull from the central repository to grab any new commits from the remote repository on GitHub. On seeing that there are no new commits, she edits the file, commits, and pushes this new commit.</p> <pre><code>% cd ${ALICE}\n% git pull\n% echo \"lemon\" &gt;&gt; fruit.txt\n% git commit -a -m \"ALICE: added lemon to fruit list\"\n% git push\n</code></pre> <p>Since Bob recently pulled from the remote repository on GitHub, let's say he assumes that there have been no new commits. He would then go ahead and create his new file, commit, and attempt to push this new commit.</p> <pre><code>% cd ${BOB}\n% echo \"spinach\"  &gt;  vegetables.txt\n% echo \"broccoli\" &gt;&gt; vegetables.txt\n% echo \"turnip\"   &gt;&gt; vegetables.txt\n% git add vegetables.txt\n% git commit -m \"BOB: initial vegetable list\"\n% git push\n To git@github.com:githubid/ece6745-tut02-git\n  ! [rejected]        main -&gt; main (fetch first)\n error: failed to push some refs to 'git@github.com:githubid/ece6745-tut02-git'\n hint: Updates were rejected because the remote contains work that you do\n hint: not have locally. This is usually caused by another repository pushing\n hint: to the same ref. You may want to first integrate the remote changes\n hint: (e.g., 'git pull ...') before pushing again.\n hint: See the 'Note about fast-forwards' in 'git push --help' for details.\n</code></pre> <p>On executing the sequence of commands above, you should notice that Git does not allow Bob to push his changes to the central repository as the version of the central repository has been updated by Alice. You should see a message similar to the one above. Git suggests us to merge the remote commits before pushing the local commits. We can do so by first using the <code>git pull</code> command to merge the local commits.</p> <pre><code>% cd ${BOB}\n% git pull\n</code></pre> <p>Git will launch Nano because we need to merge your local commits and the remote commits. You will need to enter a commit message, although usually the default message provided by Git is fine. We can take a look at the Git history using <code>git log</code> to see what happened.</p> <pre><code>% cd ${BOB}\n% git log --oneline --graph\n *   f5c1361 (HEAD -&gt; main) Merge branch 'main' of github.com:githubid/ece6745-tut02-git\n |\\\n | * c13f30e (origin/main, origin/HEAD) ALICE: added lemon to fruit list\n * | 3ef8c85 BOB: initial vegetable list\n |/\n * 5877142 BOB: added peach to fruit list\n * 7896fff ALICE: added banana to fruit list\n</code></pre> <p>The <code>--graph</code> command line option with the <code>git log</code> command will display a visual graph of the commit history. You can see that Bob and Alice worked on two different commits at the same time. Alice worked on commit <code>c13f30e</code> while Bob was working on commit <code>3ef8c85</code>. Bob then merged these two sets of commits using a new commit <code>f5c1361</code>. Your exact commit hashes might be different. Bob can now push his changes to the remote repository in GitHub.</p> <pre><code>% cd ${BOB}\n% git push\n</code></pre> <p>GitHub has a nice commit history viewer which shows a similar commit graph as we saw above:</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git/network</li> </ul> <p>Sometimes Alice and Bob are editing the exact same lines in the exact same file. In this case, Git does not really know how to resolve this conflict. It does not know how to merge the two sets of commits to create a consistent view of the repository. The user will have to manually resolve the conflict. Let's explore what happens when Alice and Bob want to add a new fruit to the <code>fruits.txt</code> file at the exact same time. First, Alice adds <code>kiwi</code> and pushes her updates to the remote repository on GitHub.</p> <pre><code>% cd ${ALICE}\n% git pull\n% echo \"kiwi\" &gt;&gt; fruit.txt\n% git commit -a -m \"ALICE: added kiwi to fruit list\"\n% git push\n</code></pre> <p>Now Bob adds <code>date</code> and tries to push his update to the remote repository on GitHub.</p> <pre><code>% cd ${BOB}\n% echo \"date\" &gt;&gt; fruit.txt\n% git commit -a -m \"BOB: added date to fruit list\"\n% git push\n To git@github.com:githubid/ece6745-tut02-git\n  ! [rejected]        main -&gt; main (fetch first)\n</code></pre> <p>Let's see what happens if Bob uses the <code>git pull</code> command to pull and merge the commits from the remote repository on GitHub.</p> <pre><code>% cd ${BOB}\n% git pull\n Unpacking objects: 100% (3/3), done.\n From github.com:cbatten/ece6745-tut02-git\n    f5c1361..3d43934  main     -&gt; origin/main\n Auto-merging fruit.txt\n CONFLICT (content): Merge conflict in fruit.txt\n Automatic merge failed; fix conflicts and then commit the result.\n</code></pre> <p>Git indicates that it was not able to complete the merge. There is a conflict in the <code>fruit.txt</code> file. We can also use the <code>git status</code> command to see which files have conflicts. They will be marked as <code>both modified</code>:</p> <pre><code>% cd ${BOB}\n% git status\n</code></pre> <p>Git instructs Bob to first resolve the conflict and then use the <code>git commit</code> command to finish the merge. If you take a look at the <code>fruit.txt</code> file you will see that it now includes conflict markers showing exactly where the conflict occurred.</p> <pre><code>% cd ${BOB}\n% cat fruit.txt\n apple\n mango\n orange\n banana\n peach\n lemon\n &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n date\n =======\n kiwi\n &gt;&gt;&gt;&gt;&gt;&gt;&gt; 3d43934f045d6ab3c354893a97fd4967997bcb35\n</code></pre> <p>This shows that the commit from the local repository has <code>date</code> on the last line in the file, while the remote repository on GitHub has <code>kiwi</code> as the last line in the file. To resolve the conflict we can directly edit this file so that it reflects how we want to merge. We can choose one fruit over the other, choose to include neither fruit, or choose to include both fruit. Edit the file using VS Code to remove the lines with markers <code>&lt;&lt;&lt;&lt;</code>, <code>===</code>, and <code>&gt;&gt;&gt;&gt;</code> so that the file includes both fruit.</p> <pre><code>% cd ${BOB}\n% code fruit.txt\n% cat fruit.txt\n apple\n mango\n orange\n banana\n peach\n lemon\n date\n kiwi\n</code></pre> <p>Now that we have resolved the conflict we just need to commit these new changes.</p> <pre><code>% cd ${BOB}\n% git status\n% git commit -a -m \"fixed conflict\"\n% git push\n% git status\n% git log --oneline --graph\n</code></pre> <p>Resolving conflicts is tedious, so to avoid conflicts you should communicate with your group members which student is going to be executing which files. Try to avoid having multiple students working on the same file at the same time, or at least avoid having multiple students working on the same lines of the same file at the same time.</p> <p>Activity 3: Experimenting with Resolving Conflicts</p> <p>Experiment with both Alice and Bob editing the same lines in the <code>overview.txt</code> file at the same time. Try to force a conflict, and then carefully resolve the conflict.</p>"},{"location":"ece6745-tut02-git/#24-branches-and-pull-requests","title":"2.4. Branches and Pull Requests","text":"<p>In this section, we describe branches and pull requests which are slightly more advanced topics but tremendously useful. Students could probably skim this section initially, and then revisit this information later in the semester. Branches and pull requests enable different students to work on different aspects at the project at the same time while keeping their commits separated in the remote repository on GitHub. So far, all of our work has been on the main branch. The main branch is the primary default branch. Creating additional branches can enable one student to work on a new feature while also fixing bugs on the main branch, or branches can enable students to experiment with some more advanced ideas but easily revert back to the \"stable\" main branch.</p> <p>Let's say that Alice wants to work on a new list of animals in Alice and Bob's shared repository, but she wants to keep her work separate from the primary work they are focusing on. Alice can create a branch called <code>alice-animals</code> and commit her new ideas on that branch. It is usually good practice to prefix branch names with your NetID to ensure that branch names are unique. The following commands will first display the branches in the local repository using the <code>git branch</code> command before creating a new branch called <code>alice-animals</code>.</p> <pre><code>% cd ${ALICE}\n% git pull\n% git branch\n% git checkout -b alice-animals\n% git branch\n% git status\n</code></pre> <p>The <code>git branch</code> command uses an asterisk (<code>*</code>) to indicate the current branch. The <code>git status</code> command also indicates the current branch. Alice can now create a new file and commit her changes to this new branch.</p> <pre><code>% cd ${ALICE}\n% git branch\n% echo \"cow\"  &gt; animals.txt\n% echo \"pig\" &gt;&gt; animals.txt\n% echo \"dog\" &gt;&gt; animals.txt\n% git add animals.txt\n% git commit -m \"ALICE: initial animal list\"\n% git log --oneline --graph\n</code></pre> <p>It should be clear that the <code>alice-animals</code> branch is one commit ahead of the <code>main</code> branch. Pushing this branch to the remote repository on GitHub requires a slightly more complicated syntax. We need to specify which branch to push to which remote repository:</p> <pre><code>% cd ${ALICE}\n% git push -u origin alice-animals\n% cat animals.txt\n</code></pre> <p>The name <code>origin</code> refers to the remote repository that the local repository was originally cloned from (i.e., the remote repository on GitHub). You can now see this new branch on GitHub here:</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git/branches</li> </ul> <p>You can browse the commits and source code in the <code>alice-animals</code> just like the <code>main</code> branch. If Bob wants to checkout Alice's new branch, he needs to use a slightly different syntax.</p> <pre><code>% cd ${BOB}\n% git pull\n% git checkout --track origin/alice-animals\n% git branch\n% cat animals.txt\n</code></pre> <p>Alice and Bob can switch back to the <code>main</code> branch using the <code>git checkout</code> command.</p> <pre><code>% cd ${ALICE}\n% git checkout main\n% git branch\n% ls\n% cd ${BOB}\n% git checkout main\n% git branch\n% ls\n</code></pre> <p>The <code>git branch</code> command should indicate that both Alice and Bob are now on the <code>main</code> branch, and there should no longer be an <code>animals.txt</code> file in the working directory. One strength of Git is that it makes it very easy to switch back and forth between branches.</p> <p>Once Alice has worked on her new branch, she might be ready to merge that branch back into the <code>main</code> branch so it becomes part of the primary project. GitHub has a nice feature called pull requests that simply this process. To create a pull request, Alice would first go to the branch page on GitHub for this repository.</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git/branches</li> </ul> <p>She then just needs to click on the three dots next to her branch and choose New pull request. You must carefully select the base fork! If you simply choose the default you will try to merge your branch into the repository that is part of the <code>cornell-ece6745</code> GitHub organization. Click on base fork and select githubid/ece6745-tut02-git. Alice can leave a comment about what this new branch does. Other students can use the pull request page on GitHub to comment on and monitor the new branch.</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git/pull/1</li> </ul> <p>Users can continue to develop and work on the branch until it is ready to be merged into <code>main</code>. When the pull request is ready to be accepted, a user simply clicks on Merge pull request on the GitHub pull request page. When this is finished the Git history for this example would look like this:</p> <pre><code>% cd ${ALICE}\n% git pull\n% git log --oneline --graph\n*   3e523c8 (HEAD -&gt; main, origin/main, origin/HEAD) Merge pull request #1 fr&gt;\n|\\\n| * 651eb8c (origin/alice-animals, alice-animals) ALICE: initial animal list\n|/\n*   e6c85c3 fixed conflict\n|\\\n| * 3d43934 ALICE: added kiwi to fruit list\n* | 9d12ba9 BOB: added date to fruit list\n|/\n*   f5c1361 Merge branch 'main' of github.com:cbatten/ece6745-tut02-git\n|\\\n| * c13f30e ALICE: added lemon to fruit list\n* | 3ef8c85 BOB: initial vegetable list\n|/\n* 5877142 BOB: added peach to fruit list\n* 7896fff ALICE: added banana to fruit list\n* bf6a25f added orange to fruit list\n* bc0e024 added mango to fruit list\n* a8ac41e initial fruit list\n* bb9506b initial import\n</code></pre> <p>Activity 4: Experimenting with Branches</p> <p>Have Bob create his own branch for development, and then create a new file named <code>states.txt</code> with the names of states. Have Bob commit his changes to a new branch and push this branch to the remote repository on GitHub. Finally, have Alice pull this new branch into her local repository.</p>"},{"location":"ece6745-tut02-git/#3-github-actions-for-continuous-integration","title":"3. GitHub Actions for Continuous Integration","text":"<p>GitHub Actions is an online continuous integration service that is integrated within GitHub. GitHub Actions will automatically run all tests for a student's lab assignment every time the students push their code to GitHub. We will be using the results reported by GitHub Actions to evaluate the code functionality of the lab assignments. In this section, we do a small experiment to illustrate how GitHub Actions work.</p> <p>GitHub Actions looks for specials file in the <code>.github/workflows</code> subdirectory in the top of your repository to determine how to build and test your project. We have already created one of those files for you, and you can see it here:</p> <pre><code>% cd ${TUTROOT}\n% cat .github/workflows/git-tutorial.yml\n</code></pre> <p>The <code>git-tutorial.yml</code> file for this tutorial is very simple. It just uses the <code>grep</code> command to check if the fruit <code>blueberry</code> is in the <code>fruit.txt</code> file. If the <code>blueberry</code> is present then the test passes, otherwise the test fails. Click on the Actions tab in your repository on GitHub and click I understand my workflows, go ahead and enable them as shown in the following figure.</p> <p></p> <p>Let's add <code>melon</code> to the list of fruits in our local repository and then push the corresponding commit to the remote repository on GitHub.</p> <pre><code>% cd ${TUTROOT}\n% git pull\n% echo \"melon\" &gt;&gt; fruit.txt\n% git commit -a -m \"added melon to fruit list\"\n% git push\n</code></pre> <p>Notice how we first use the <code>git pull</code> command to ensure our local repository has all of the commits from the remote repository on GitHub. To see the results of the workflow run go to the Actions tab for the corresponding repository on GitHub. You can also use a link like this:</p> <ul> <li>https://github.com/githubid/ece6745-tut02-git/actions</li> </ul> <p>where <code>githubid</code> is your GitHub username on the public version of GitHub. You should be able to see a list of workflow runs as illustrated below.</p> <p></p> <p>Each run corresponds to a push to GitHub. A green checkmark means that run passed, while a red X means that run failed. If you click on the name of a run, and then click on check you can see a list of steps that GitHub actions ran. Click on the little <code>&gt;</code> next to Run grep blueberry fruit.txt to see the output from running <code>grep</code>.</p> <p></p> <p>The test should fail because <code>blueberry</code> is not currently in the <code>fruit.txt</code> file. Now let's add <code>blueberry</code> and then push the corresponding to commit to trigger another build on GitHub Actions.</p> <pre><code>% cd ${TUTROOT}\n% echo \"blueberry\" &gt;&gt; fruit.txt\n% git commit -a -m \"added blueberry to fruit list\"\n% git push\n</code></pre> <p>If you revisit the GitHub Actions page for this repository, you should now see that the check has passed!</p> <p>Using GitHub Actions to perform continuous integration testing is a key component of an agile development methodology. It means the entire group can quickly spot commits which break certain tests, and always be certain that their <code>main</code> branch is passing all tests before submitting the lab assignment. The course staff will actually be using GitHub Actions to grade your lab assignments. The staff will be able to look at the build log in GitHub Actions to see if your assignment is passing your own test suite, and then the staff can add more tests to see if your assignment passes a more exhaustive test suite.</p> <p>Activity 5: Experimenting with GitHub Actions</p> <p>Edit the <code>git-tutorial.yml</code> file to search for <code>apple</code> instead. Experiment with removing and adding <code>apple</code> from the <code>fruits.txt</code> file to see the tests on GitHub Actions pass and fail.</p>"},{"location":"ece6745-tut02-git/#4-course-specific-git-scripts","title":"4. Course-Specific Git Scripts","text":"<p>This section describes some useful scripts we have installed that make it easier to use Git. Each script is invoked by typing the name along with the standard <code>git</code> command.</p>"},{"location":"ece6745-tut02-git/#41-using-git-xstatus-to-compactly-see-status-information","title":"4.1. Using <code>git xstatus</code> to Compactly See Status Information","text":"<p>The <code>git xstatus</code> command produces a status output somewhat similar to subversion's status command. It first shows the status of all tracked files which are modified, deleted, or added, then shows the status of all files in the index (marked with an asterisk), and finally shows which files and directories are untracked. Here is an example output:</p> <pre><code>% cd ${TUTROOT}\n% echo \"cyan\" &gt;&gt; colors.txt\n% echo \"rabbit\" &gt;&gt; animals.txt\n% git add colors.txt animals.txt\n% git commit -m \"added some colors and animals\"\n% echo \"grape\" &gt;&gt; fruit.txt\n% git add fruit.txt\n% echo \"strawberry\" &gt;&gt; fruit.txt\n% echo \"bird\" &gt;&gt; animals.txt\n% echo \"tulip\"  &gt;&gt; flowers.txt\n% rm colors.txt\n% git xstatus\n  M animals.txt\n  D colors.txt\n  M fruit.txt\n *M fruit.txt\n  ? flowers.txt\n</code></pre> <p>This shows that the file <code>colors.txt</code> has been deleted from the working directory, but this deletion has not been added to the index yet (<code>colors.txt</code> is not listed with an asterisk). The file <code>animals.txt</code> has been modified buy not added to the index yet. Note that the file named <code>fruit.txt</code> has been modified and added to the index, but it has been modified since it was added to the index as indicated by its double listing. The file named <code>flowers.txt</code> is currently untracked.</p> <p>The possible status codes are as follows:</p> <pre><code> - A : addition of a file\n - C : copy of a file into a new one\n - D : deletion of a file\n - M : modification of the contents or mode of a file\n - R : renaming of a file\n - T : change in the type of the file\n - U : file is unmerged (you must complete the merge before commit)\n - ? : file is untracked (you need to add it if you want to track it)\n</code></pre>"},{"location":"ece6745-tut02-git/#42-using-git-xadd-to-add-all-changed-files","title":"4.2. Using <code>git xadd</code> to Add All Changed Files","text":"<p>The <code>git xadd</code> command adds all files which are currently tracked and display the new status in a format similar to the <code>git xstatus</code> command. You can use this to quickly stage files for commit and see what would be committed before actually executing the commit.</p> <pre><code>% cd ${TUTROOT}\n% git xstatus\n% git xadd\n</code></pre>"},{"location":"ece6745-tut02-git/#43-using-git-xlog-to-compactly-see-log-information","title":"4.3. Using <code>git xlog</code> to Compactly See Log Information","text":"<p>The <code>git xlog</code> command displays a compact log format with one commit per line and a graph representing the commit history. This script passes along whatever the additional options are included straight onto <code>git log</code>. Here is a simple example of the log output.</p> <pre><code>% cd ${TUTROOT}\n% git xlog\n* be57e36 cb added some colors and animals\n* d2c0ecd cb added blueberry to fruit list\n* 1e4792f cb added melon to fruit list\n*   3e523c8 cb Merge pull request #1 from cbatten/alice-animals\n|\\\n| * 651eb8c cb ALICE: initial animal list\n|/\n*   e6c85c3 cb fixed conflict\n|\\\n| * 3d43934 cb ALICE: added kiwi to fruit list\n* | 9d12ba9 cb BOB: added date to fruit list\n|/\n*   f5c1361 cb Merge branch 'main' of github.com:cbatten/ece6745-tut02-git\n|\\\n| * c13f30e cb ALICE: added lemon to fruit list\n</code></pre> <p>You can see one line per commit along with the commit hash, the committer's name, and the short commit message. The graph shows a merge between commits <code>3d43934</code> and <code>6ee31c69d12ba9</code>.</p>"},{"location":"ece6745-tut05-asic-stdcells/","title":"ECE 6745 Tutorial 5: ASIC Standard Cells","text":"<p>A standard-cell library is a collection of combinational and sequential logic gates that adhere to a standardized set of logical, electrical, and physical policies. For example, all standard cells are usually the same height, include pins that align to a predetermined vertical and horizontal grid, include power/ground rails and nwells in predetermined locations, and support a predetermined number of drive strengths. A standard-cell-based ASIC toolflow involves using automated tools to transform register-transfer-level (RTL) designs into placed and routed standard cells on a chip. This tutorial will explore the specific standard-cell library we will use in this course along with the various \"views\" of the standard-cell library. This tutorial assumes you have already completed the tutorials on Linux, Git, and Verilog.</p> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into a specific <code>ecelinux</code> server and then use Microsoft Remote Desktop to log into the same server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut05-asic-stdcells tut05\n% cd tut05\n% TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut05-asic-stdcells/#1-freepdk45-process-design-kit","title":"1. FreePDK45 Process Design Kit","text":"<p>Before you can gain access to a standard-cell library, you need to gain access to a \"physical design kit\" (PDK). A PDK includes all of the design files required for full-custom circuit design for a specific technology. So this will include a design-rule manual as well as SPICE circuit models for transistors and other devices. Gaining access to a real PDK is difficult. It requires negotiating with the foundry and signing multiple non-disclosure agreements. So in this course we will be using the FreePDK45 PDK:</p> <ul> <li>https://eda.ncsu.edu/freepdk/freepdk45</li> </ul> <p>This is an open PDK for a \"fake\" technology. It was created by universities using publically available data on several different commercial 45nm processes. This means you cannot actually tapeout a chip using this PDK, but the technology is representative enough to provide reasonable area, energy, and timing estimates for research and teaching purposes. You can find the FreePDK45 PDK installed here:</p> <pre><code>% cd ${ECE6745_INSTALL}/adks/freepdk-45nm/pkgs/FreePDK45-1.4\n</code></pre>"},{"location":"ece6745-tut05-asic-stdcells/#2-nangate-standard-cell-library","title":"2. NanGate Standard-Cell Library","text":"<p>A standard-cell designer will use the PDK to implement the standard-cell library. A standard-cell designer will usually create a high-level behavioral specification (in Verilog), circuit schematics (in SPICE), and the actual layout (in <code>.gds</code> format) for each logic gate. The standard-cell-based ASIC tools do not actually use these low-level implementations, since they are actually too detailed. Instead these tools use abstract views of the standard cells, which capture logical functionality, timing, geometry, and power usage at a much higher level.</p> <p>Just like with a PDK, gaining access to a real standard-cell library is difficult. It requires gaining access to the PDK first, negotiating with a company which makes standard cells, and usually signing more non-disclosure agreements. In this course, we will be using the Nangate 45nm standard-cell library which is based on the open FreePDK45 PDK.</p> <p>Nangate is a company which makes a tool to automatically generate standard-cell libraries, so they have made this library publically available a way to demonstrate their tool. Since it is an open library it is a great resource for research and teaching. Even though the standard-cell library is based on a \"fake\" 45nm PDK, the library provides a very reasonable estimate of a real commercial standard library in a real 45nm technology. In this section, we will take a look at both the low-level implementations and high-level views of the Nangate standard-cell library.</p> <p>A standard-cell library distribution can contain gigabytes of data in thousands of files. For example, here is the distribution for the Nangate standard-cell library.</p> <pre><code>% cd ${ECE6745_INSTALL}/adks/freepdk-45nm/pkgs/NangateOpenCellLibrary_PDKv1_3_v2010_12\n</code></pre> <p>To simplify using the Nangate standard-cell library in this course, we have created a much smaller set of well-defined symlinks which point to just the key files we want to use in this course. We call this collection of symlinks an \"ASIC design kit\" (ADK). Here is the directory which contains these symlinks.</p> <pre><code>% cd ${ECE6745_STDCELLS}\n% ls\npdk-models.sp          # spice models for transistors\n\nrtk-stream-out.map     # gds layer map\nrtk-tech.lef           # interconnect technology information\nrtk-tech.tf            # interconnect technology information\nrtk-typical.captable   # interconnect technology information\n\nstdcells.spi           # circuit schematics for each cell\nstdcells.gds           # layout for each cell\nstdcells.v             # behavioral specification for each cell\n\nstdcells-lpe.spi       # circuit schematics with parasitics for each cell\nstdcells.lib           # abstract logical, timing, power view for each cell (typical)\nstdcells-bc.lib        # best case .lib\nstdcells-wc.lib        # worst case .lib\nstdcells.lef           # abstract physical view for each cell\n\nstdcells.db            # binary compiled version of .lib file\nstdcells.mwlib         # Milkyway database built from .lef file\n\nstdcells-databook.pdf  # standard-cell library databook\n\nklayout.lyp            # layer settings for Klayout\n</code></pre> <p>A standard-cell library will always include a databook, which is a document that describes the details of every cell in the library. Take a few minutes to browse through the Nangate standard-cell library databook located on the course webpage here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/resources/nangate-freepdk45nm-stdcell-databook.pdf</li> </ul>"},{"location":"ece6745-tut05-asic-stdcells/#21-verilog-behavioral-view","title":"2.1. Verilog Behavioral View","text":"<p>Let's begin by looking at the Verilog behavioral view for a 3-input NAND standard cell which is named NAND3_X1.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.v\nmodule NAND3_X1 (A1, A2, A3, ZN);\n  input A1;\n  input A2;\n  input A3;\n  output ZN;\n\n  not(ZN, i_8);\n  and(i_8, i_9, A3);\n  and(i_9, A1, A2);\n\n  specify\n    (A1 =&gt; ZN) = (0.1, 0.1);\n    (A2 =&gt; ZN) = (0.1, 0.1);\n    (A3 =&gt; ZN) = (0.1, 0.1);\n  endspecify\n\nendmodule\n</code></pre> <p>Note that the Verilog implementation of the 3-input NAND standard cell looks nothing like the Verilog we used in ECE 4750. This cell is implemented using Verilog primitive gates (e.g., <code>not</code>, <code>and</code>) and it includes a <code>specify</code> block which is used for advanced gate-level simulation with back-annotated delays.</p> <p>Let's use <code>iverilog</code> to simulate the Verilog behavorial view of the 3-input NAND standard cell. Take a look at the provided Verilog test bench.</p> <pre><code>% cd $TOPDIR\n% cat nand3-test.v\n</code></pre> <p>The test bench looks as follows.</p> <pre><code>`include \"/classes/ece6745/install/adks/freepdk-45nm/stdview/stdcells.v\"\n\nmodule top();\n\n  logic a;\n  logic b;\n  logic c;\n  logic y;\n\n  NAND3_X1 nand3( a, b, c, y );\n\n  initial begin\n    $dumpfile(\"nand3-test.vcd\");\n    $dumpvars;\n\n    a = 0; b = 0; c = 0;\n    #10;\n    $display( \"a=%b, b=%b, c=%b, y=%b\", a, b, c, y );\n\n    a = 1; b = 1; c = 1;\n    #10;\n    $display( \"a=%b, b=%b, c=%b, y=%b\", a, b, c, y );\n\n    a = 0; b = 1; c = 0;\n    #10;\n    $display( \"a=%b, b=%b, c=%b, y=%b\", a, b, c, y );\n\n    a = 1; b = 1; c = 1;\n    #10;\n    $display( \"a=%b, b=%b, c=%b, y=%b\", a, b, c, y );\n\n  end\n\nendmodule\n</code></pre> <p>The test bench simply tries four different combinations of input values. Run the simulation and view the result using Surfer.</p> <pre><code>% cd $TOPDIR/sim\n% iverilog -g2012 -s top -o nand3-test nand3-test.v\n% ./nand3-test\n% code nand3-test.vcd\n</code></pre> <p>The waveforms should look similar to what is shown below. Because this is a Verilog behavioral view all signals change immediately without any kind of delay.</p> <p></p>"},{"location":"ece6745-tut05-asic-stdcells/#22-spice-schematic-view","title":"2.2. SPICE Schematic View","text":"<p>Now that we understand the Verilog behavioral view, let's look at how we would implement this same standard cells at the transistor level. We can look at the SPICE schematic view for a 3-input NAND cell (NAND3_X1).</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.spi\n.SUBCKT NAND3_X1 A1 A2 A3 ZN VDD VSS\n*.PININFO A1:I A2:I A3:I ZN:O VDD:P VSS:G\n*.EQN ZN=!((A1 * A2) * A3)\nM_i_2 net_1 A3 VSS   VSS NMOS_VTL W=0.415000U L=0.050000U\nM_i_1 net_0 A2 net_1 VSS NMOS_VTL W=0.415000U L=0.050000U\nM_i_0 ZN    A1 net_0 VSS NMOS_VTL W=0.415000U L=0.050000U\nM_i_5 ZN    A3 VDD   VDD PMOS_VTL W=0.630000U L=0.050000U\nM_i_4 VDD   A2 ZN    VDD PMOS_VTL W=0.630000U L=0.050000U\nM_i_3 ZN    A1 VDD   VDD PMOS_VTL W=0.630000U L=0.050000U\n.ENDS\n</code></pre> <p>For students with a circuits background, there should be no surprises here, and for those students with less circuits background we will cover basic static CMOS gate design later in the course. Essentially, this schematic includes three NMOS transistors arranged in series in the pull-down network, and three PMOS transistors arranged in parallel in the pull-up network. The PMOS transistors are larger than the NMOS transistors (see <code>W=</code> parameter) because the mobility of holes is less than the mobility of electrons.</p> <p>Let's use ngspice to simulate the SPICE schematic view of the 3-input NAND standard cell. Take a look at the provided SPICE test bench.</p> <pre><code>% cd $TOPDIR/sim\n% cat nand3-test.sp\n</code></pre> <p>Although it is not too important for you to understand how to write a SPICE test bench, it can still be fun to look at one.</p> <pre><code>* Simple NAND3_X1 simulation\n* ------------------------------------------------------------------------\n\n.param VDD='1.1V'\n.temp  70\n.inc   \"/classes/ece6745/install/adks/freepdk-45nm/stdview/pdk-models.sp\"\n.inc   \"/classes/ece6745/install/adks/freepdk-45nm/stdview/stdcells.spi\"\n\n* Instantiate a voltage supply, standard cell, and output load\n* ------------------------------------------------------------------------\n\nVdd vdd gnd VDD\n\nX1 a b c y vdd gnd NAND3_X1\n\nCload y gnd 7fF\n\n* Instantiate three input sources\n* ------------------------------------------------------------------------\n\nA1 [a_ b_] nand3_source\n.model nand3_source d_source (input_file=\"nand3-source.txt\")\n\nAa [a_] [a] dac_a\n.model dac_a dac_bridge (out_low=0V out_high='VDD' t_rise=0.2ns t_fall=0.2ns)\n\nAb [b_] [b] dac_b\n.model dac_b dac_bridge (out_low=0V out_high='VDD' t_rise=0.2ns t_fall=0.2ns)\n\nAc [b_] [b] dac_c\n.model dac_c dac_bridge (out_low=0V out_high='VDD' t_rise=0.2ns t_fall=0.2ns)\n\n* Run a simulation\n* ------------------------------------------------------------------------\n\n.ic   V(y)=VDD\n.tran 0.01ns 4ns\n\n.control\nrun\nset color0=white\nset color1=black\nset color2=red\nset xbrushwidth=2\nplot V(a) V(b) V(c) V(y)\n.endc\n\n.end\n</code></pre> <p>See Tutorial 8 for much more detail on SPICE simulation. You can run the simulation using ngspice like this:</p> <pre><code>% cd $TOPDIR/sim\n% nsgpice nand3-test.sp\n</code></pre> <p>Note that if we use ngspice to display plots, then it is a Linux GUI application so you will need to use Microsoft Remote Desktop. The waveforms should look similar to what is shown below. The input signals ramp up and down based on the <code>t_rise</code> and <code>t_fall</code> parameters above. Because this is a SPICE schematic view you can see the output does not change instantly but instead takes some amount of time due to the parasitic resistance and capacitances associated with the transistors in the schematic.</p> <p></p>"},{"location":"ece6745-tut05-asic-stdcells/#23-gds-layout-view","title":"2.3. GDS Layout View","text":"<p>Now that we understand the SPICE schematic view, let's look at the actual layout for the 3-input NAND cell using the open-source Klayout GDS viewer. Note that since Klayout is a Linux GUI application you will need to use Microsoft Remote Desktop.</p> <pre><code>% klayout -l ${ECE6745_STDCELLS}/klayout.lyp ${ECE6745_STDCELLS}/stdcells.gds\n</code></pre> <p>Note that we are using the <code>.lyp</code> file which is a predefined layer color scheme that makes it easier to view GDS files. To view the 3-input NAND cell, find the NAND3_X1 cell in the left-hand cell list, and then choose Display &gt; Show as New Top from the menu. Here is a picture of the layout for this cell.</p> <p></p> <p>Diffusion is green, polysilicon is red, contacts are solid dark blue, metal 1 (M1) is blue, and the nwell is the large gray rectangle over the top half of the cell. All standard cells will be the same height and have the nwell in the same place. Notice the three NMOS transistors arranged in series in the pull-down network, and three PMOS transistors arranged in parallel in the pull-up network. The power rail is the horizontal strip of M1 at the top, and the ground rail is the horizontal strip of M1 at the bottom. All standard cells will have the power and ground rails in the same place so they will connect via abutment if these cells are arranged in a row. Although it is difficult to see, the three input pins and one output pin are labeled squares of M1, and these pins are arranged to be on a predetermined grid.</p>"},{"location":"ece6745-tut05-asic-stdcells/#24-spice-extracted-schematic-view","title":"2.4. SPICE Extracted Schematic View","text":"<p>The SPICE schematic view was saw earlier includes just the transistors. We can use sophisticated tools to extract detailed parasitic resistance and capacitance values from the layout, and then we can add these parasitics to the circuit schematic to create a much more accurate model for experimenting with the circuit timing and power. Let's look at a snippet of the extracted circuit for the 3-input NAND cell:</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells-lpe.spi\n.SUBCKT NAND3_X1 VDD VSS A3 ZN A2 A1\n*.PININFO VDD:P VSS:G A3:I ZN:O A2:I A1:I\n*.EQN ZN=!((A1 * A2) * A3)\nM_M3 N_ZN_M0_d  N_A3_M0_g N_VDD_M0_s VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M4 N_VDD_M1_d N_A2_M1_g N_ZN_M0_d  VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M5 N_ZN_M2_d  N_A1_M2_g N_VDD_M1_d VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M0 net_1      N_A3_M3_g N_VSS_M3_s VSS NMOS_VTL W=0.415000U L=0.050000U\nM_M1 net_0      N_A2_M4_g net_1      VSS NMOS_VTL W=0.415000U L=0.050000U\nM_M2 N_ZN_M5_d  N_A1_M5_g net_0      VSS NMOS_VTL W=0.415000U L=0.050000U\nC_x_PM_NAND3_X1%VDD_c0 x_PM_NAND3_X1%VDD_39 VSS 3.704e-17\nC_x_PM_NAND3_X1%VDD_c1 x_PM_NAND3_X1%VDD_36 VSS 2.74884e-18\nC_x_PM_NAND3_X1%VDD_c2 x_PM_NAND3_X1%VDD_26 VSS 2.61603e-16\nC_x_PM_NAND3_X1%VDD_c3 N_VDD_M1_d           VSS 6.57971e-17\nC_x_PM_NAND3_X1%VDD_c4 x_PM_NAND3_X1%VDD_19 VSS 1.89932e-17\nC_x_PM_NAND3_X1%VDD_c5 x_PM_NAND3_X1%VDD_18 VSS 3.74888e-17\nC_x_PM_NAND3_X1%VDD_c6 N_VDD_M0_s           VSS 3.64134e-17\n...\n.ENDS\n</code></pre> <p>The full model is a couple of hundred lines long, so you can see how detailed this model is!</p>"},{"location":"ece6745-tut05-asic-stdcells/#25-lib-logical-view","title":"2.5. LIB Logical View","text":"<p>The ASIC tools do not actually interact with the low-level SPICE schematic views and GDS layour views. We can use a special set of tools to create a much higher level abstract view of the timing and power of this circuit suitable for use by the ASIC tools. Essentially, these tools run many, many circuit-level simulations to create characterization data stored in a <code>.lib</code> (Liberty) file. Let's look at snippet of the <code>.lib</code> file for the 3-input NAND cell.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.lib\ncell (NAND3_X1) {\n drive_strength          : 1;\n area                    : 1.064000;\n cell_leakage_power      : 18.104768;\n leakage_power () {\n   when                  : \"!A1 &amp; !A2 &amp; !A3\";\n   value                 : 3.318854;\n }\n ...\n pin (A1) {\n   direction             : input;\n   related_power_pin     : \"VDD\";\n   related_ground_pin    : \"VSS\";\n   capacitance           : 1.590286;\n   fall_capacitance      : 1.562033;\n   rise_capacitance      : 1.590286;\n }\n ...\n pin (ZN) {\n   direction             : output;\n   related_power_pin     : \"VDD\";\n   related_ground_pin    : \"VSS\";\n   max_capacitance       : 58.364900;\n   function              : \"!((A1 &amp; A2) &amp; A3)\";\n\n   timing () {\n\n     related_pin         : \"A1\";\n     timing_sense        : negative_unate;\n\n     cell_fall(Timing_7_7) {\n       index_1 (\"0.00117378,0.00472397,0.0171859,0.0409838,0.0780596,0.130081,0.198535\");\n       index_2 (\"0.365616,1.823900,3.647810,7.295610,14.591200,29.182500,58.364900\");\n       values (\"0.0106270,0.0150189,0.0204521,0.0312612,0.0528211,0.0959019,0.182032\", \\\n               \"0.0116171,0.0160692,0.0215549,0.0324213,0.0540285,0.0971429,0.183289\", \\\n               \"0.0157475,0.0207077,0.0261030,0.0369216,0.0585239,0.101654,0.187820\", \\\n               \"0.0193780,0.0263217,0.0337702,0.0462819,0.0677259,0.110616,0.196655\", \\\n               \"0.0218025,0.0305247,0.0399593,0.0560603,0.0822203,0.125293,0.210827\", \\\n               \"0.0229784,0.0334449,0.0447189,0.0640615,0.0959700,0.146382,0.231434\", \\\n               \"0.0227986,0.0349768,0.0480836,0.0705081,0.107693,0.167283,0.259623\");\n     }\n     ...\n\n     internal_power () {\n       related_pin       : \"A1\";\n       fall_power(Power_7_7) {\n         index_1 (\"0.00117378,0.00472397,0.0171859,0.0409838,0.0780596,0.130081,0.198535\");\n         index_2 (\"0.365616,1.823900,3.647810,7.295610,14.591200,29.182500,58.364900\");\n         values (\"0.523620,0.538965,0.551079,0.556548,0.561151,0.564018,0.564418\", \\\n                 \"0.459570,0.484698,0.509668,0.529672,0.543887,0.554682,0.559331\", \\\n                 \"0.434385,0.457202,0.470452,0.498312,0.517651,0.538469,0.550091\", \\\n                 \"0.728991,0.630651,0.581024,0.559124,0.551408,0.553714,0.557387\", \\\n                 \"1.306597,1.153240,1.010684,0.831268,0.727155,0.657699,0.616287\", \\\n                 \"2.170611,1.965158,1.760932,1.459438,1.140559,0.930355,0.781393\", \\\n                 \"3.276307,3.084566,2.831754,2.426623,1.913607,1.439055,1.113950\");\n       }\n       ...\n     }\n ...\n}\n</code></pre> <p>This is just a small subset of the information included in the <code>.lib</code> file for this cell. We will talk more about the details of such <code>.lib</code> files later in the course, but you can see that the <code>.lib</code> file contains information about area, leakage power, capacitance of each input pin, logical functionality, and timing. Units for all data is provided at the top of the <code>.lib</code> file. In this snippet you can see that the area of the cell is 1.064 square micron and the leakage power is 18.1nW. The capacitance for the input pin <code>A1</code> is 1.59fF, although there is additional data that captures how the capacitance changes depending on whether the input is rising or falling. The output pin <code>ZN</code> implements the logic equation <code>!((A1 &amp; A2) &amp; A3)</code> (i.e., a three-input NAND gate). Data within the <code>.lib</code> file is often represented using one- or two-dimensional lookup tables (i.e., a <code>values</code> table). You can see two such tables in the above snippet.</p> <p>Let's start by focusing on the first table. This table captures the delay from input pin <code>A1</code> to output pin <code>ZN</code> as a function of two parameters: the input transition time (horizontal direction in lookup table) and the load capacitance (vertical direction in lookup table). Note that this delay is when <code>ZN</code> is \"falling\" (i.e., when it is transitioning from high to low). There is another table for the delay when <code>ZN</code> is rising, and there are additional tables for every input. Gates are slower when the inputs take longer to transition and/or when they are driving large output loads. Each entry in the lookup table reflects characterization of one or more detailed circuit-level simulations. So in this example the delay from input pin <code>A1</code> to output pin <code>ZN</code> is 16ps when the input transition rate is 4.7ps and the output load is 1.82fF. This level of detail can enable very accurate static timing analysis of our designs.</p> <p>Let's now focus on the second table. This table captures the internal power, which is the power consumed within the gate itself, again as a function of two paramers: the input transition time (horizontal direction in lookup table) and the load capacitance (vertical direction in lookup table). Each entry in the lookup table is calculated by measuring the current drawn from the power supply during a detailed SPICE simulation and subtracting any current used to charge the output load. In other words all of the energy that is not consumed charging up the output load is considered internal energy. Note that sometimes the internal power is negative. This is simply due to how we account for energy. We can either assume all energy is consumed only when the output node is charged and no energy is consumed when the output node is discharged, or we can assume half the energy is consumed when the output is node is charged and half the energy is consumed when the output node is discharged in which case you will sometimes see negative internal power.</p> <p>Note that some of the ASIC tools actually do not use the <code>.lib</code> file directly, but instead use a pre-compiled binary version of the <code>.lib</code> file stored in <code>.db</code> format. The binary <code>.db</code> file is usually much more compact that the text <code>.lib</code> file. The <code>.lib</code> file captures the abstract logical, timing, and power aspects of the standard-cell library, but it does not capture the physical aspects of the standard-cell library.</p>"},{"location":"ece6745-tut05-asic-stdcells/#26-lef-physical-view","title":"2.6. LEF Physical View","text":"<p>While the ASIC tools could potentially use the <code>.gds</code> file directly, the ASIC tools do not really need this much detail. We can use a special set of tools to create a much higher level abstract view of the physical aspects of the cell suitable for use by the ASIC tools. These tools create <code>.lef</code> files. Let's look at snippet of the the <code>.lef</code> file for the 3-input NAND cell.</p> <pre><code>% less -p NAND3_X1 ${ECE6745_STDCELLS}/stdcells.lef\nMACRO NAND3_X1\n  CLASS core ;\n  FOREIGN NAND3_X1 0.0 0.0 ;\n  ORIGIN 0 0 ;\n  SYMMETRY X Y ;\n  SITE FreePDK45_38x28_10R_NP_162NW_34O ;\n  SIZE 0.76 BY 1.4 ;\n\n  PIN A1\n    DIRECTION INPUT ;\n    ANTENNAPARTIALMETALAREA 0.0175 LAYER metal1 ;\n    ANTENNAPARTIALMETALSIDEAREA 0.0715 LAYER metal1 ;\n    ANTENNAGATEAREA 0.05225 ;\n    PORT\n      LAYER metal1 ;\n        POLYGON 0.44 0.525 0.54 0.525 0.54 0.7 0.44 0.7  ;\n    END\n  END A1\n\n  PIN ZN\n    DIRECTION OUTPUT ;\n    ANTENNAPARTIALMETALAREA 0.1352 LAYER metal1 ;\n    ANTENNAPARTIALMETALSIDEAREA 0.4992 LAYER metal1 ;\n    ANTENNADIFFAREA 0.197925 ;\n    PORT\n      LAYER metal1 ;\n        POLYGON 0.235 0.8 0.605 0.8 0.605 0.15 0.675 0.15\n         0.675 1.25 0.605 1.25 0.605 0.87 0.32 0.87 0.32 1.25 0.235 1.25  ;\n    END\n  END ZN\n\n  PIN VDD\n    DIRECTION INOUT ;\n    USE power ;\n    SHAPE ABUTMENT ;\n    PORT\n      LAYER metal1 ;\n        POLYGON 0 1.315 0.04 1.315 0.04 0.975 0.11 0.975 0.11 1.315\n         0.415 1.315 0.415 0.975 0.485 0.975 0.485 1.315 0.76 1.315 0.76 1.485 0 1.485  ;\n    END\n  END VDD\n\n  ...\nEND NAND3_X1\n</code></pre> <p>This is just a small subset of the information included in the <code>.lef</code> file for this cell. You can see the <code>.lef</code> file includes information on the dimensions of the cell and the location and dimensions of both power/ground and signal pins. The file also includes information on \"obstructions\" (or blockages) indicated with a <code>OBS</code> entry. Take a look at the NAND4_X4 gate to see an obstruction. These are regions of the cell which should not be used by the ASIC tools. For example, if a cell needs to use metal 2 (M2), it would create a blockage on M2 so that the ASIC tools know not to route any M2 wires in that area. You can use Klayout to view <code>.lef</code> files as well.</p> <pre><code>% klayout ${ECE6745_STDCELLS}/stdcells.lef\n</code></pre> <p>Here is a picture of the <code>.lef</code> for the 3-input NAND gate.</p> <p></p> <p>If you compare the <code>.lef</code> to the <code>.gds</code> you can see that the <code>.lef</code> is a much simpler representation that only captures the boundary, pins, and obstructions.</p>"},{"location":"ece6745-tut05-asic-stdcells/#27-routing-technology-files","title":"2.7. Routing Technology Files","text":"<p>The standard-cell library also includes several files (e.g., <code>rtk-tech.tf</code>, <code>rtk-tech.lef</code>, <code>rtk-typical.captable</code>) that capture information about the metal interconnect including the wire width, pitch, and parasitics. For example, let's take a look at the <code>.captable</code> file:</p> <pre><code>% less -p M1 ${ECE6745_STDCELLS}/rtk-typical.captable\nLAYER M1\n  MinWidth              0.07000\n  MinSpace              0.06500\n  Height                0.37000\n  Thickness             0.13000\n  TopWidth              0.07000\n  BottomWidth           0.07000\n  WidthDev              0.00000\n  Resistance            0.38000\nEND\n...\nM1\nwidth(um)  space(um) Ctot(Ff/um)  Cc(Ff/um)    Carea(Ff/um) Cfrg(Ff/um)\n0.070       0.052       0.1986       0.0723       0.0311       0.0115\n0.070       0.065       0.1705       0.0509       0.0311       0.0143\n0.070       0.200       0.1179       0.0115       0.0311       0.0319\n0.070       0.335       0.1150       0.0030       0.0311       0.0388\n0.070       0.470       0.1148       0.0009       0.0311       0.0409\n0.070       0.605       0.1147       0.0002       0.0311       0.0416\n0.070       0.740       0.1147       0.0001       0.0311       0.0417\n</code></pre> <p>This file contains information about the minimum dimenisions of wires on M1 and the resistance of these wires. It also contains a table of wire capacitances with different rows for different wire widths and spacings. The ASIC tools can use this kind of technology information to optimize and analyze the design.</p>"},{"location":"ece6745-tut05-asic-stdcells/#3-to-do-on-your-own","title":"3. To Do On Your Own","text":"<p>Great ASIC designers spend time getting to know their standard cell library. Spend some time exploring other important standard cells in the NanGate standard cell library. We recommend you look at:</p> <ul> <li>NAND3_X2: Three-input NAND gate with 2x drive strength</li> <li>NAND3_X4: Three-input NAND gate with 4x drive strength</li> <li>MUX2_X1: Two-input 1-bit multiplexor</li> <li>INV_X1: Inverter</li> <li>FA: 1-bit full adder</li> <li>DFF_X1: D flip-flop</li> </ul> <p>Compare the GDS layout views and LIB logic views for the three different three-input NAND gates each with a different drive strength. Look at the SPICE schematic view to see if you can figure out how the MUX2 gate is implemented at the transistor level (i.e., try to draw a transistor-level schematic diagram). Compare the complexity of the full adder and D flip-flop to a basic inverter by looking at the Verilog behavioral views and the GDS layout.</p>"},{"location":"ece6745-tut06-asic-front-end/","title":"ECE 6745 Tutorial 6: ASIC Front-End Flow","text":"<p>The tutorial will discuss the key tools used for ASIC front-end flow which includes RTL simulation, synthesis, and fast-functional gate-level simulation. This tutorial requires entering commands manually for each of the tools to enable students to gain a better understanding of the detailed steps involved in this process. A later tutorial will illustrate how this process can be automated to facilitate rapid design-space exploration. This tutorial assumes you have already completed the tutorials on Linux, Git, and Verilog.</p> <p>The following diagram illustrates the five primary tools we will be using in ECE 6745 along with a few smaller secondary tools. The tools that make-up the ASIC front-end flow are highlighted in red. Notice that the ASIC tools all require various views from the standard-cell library. Before starting this tutorial, you must complete the ASIC standard-cell tutorial so you can understand all of these views.</p> <p></p> <ol> <li> <p>We write our RTL models in Verilog, and we use the PyMTL framework to     test, verify, and evaluate the execution time (in cycles) of our     design. This part of the flow is very similar to the flow used in     ECE 4750. Once we are sure our design is working correctly, we can     then start to push the design through the flow.</p> </li> <li> <p>We use Synopsys VCS to compile and run both 4-state RTL and     gate-level simulations. These simulations help us to build confidence     in our design as we push our designs through different stages of the     flow. From these simulations, we also generate waveforms in <code>.vcd</code>     (Verilog Change Dump) format, and per-net average activity factors     stored in <code>.saif</code> format. These activity factors will be used for     power analysis. Gate-level simulation is an valuable tool for     ensuring the tools did not optimize something away which impacts the     correctness of the design, and also provides an avenue for obtaining     a more accurate power analysis than RTL simulation. While static     timing analysis (STA) analyzes all paths, GL simulation can also     serve as a backup to check for hold and setup time violations (chip     designers must be paranoid!)</p> </li> <li> <p>We use Synopsys Design Compiler (DC) to synthesize our design,     which means to transform the Verilog RTL model into a Verilog     gate-level netlist where all of the gates are selected from the     standard-cell library. We need to provide Synopsys DC with abstract     logical and timing views of the standard-cell library in <code>.db</code>     format. In addition to the Verilog gate-level netlist, Synopsys DC     can also generate a <code>.ddc</code> file which contains information about the     gate-level netlist and timing, and this <code>.ddc</code> file can be inspected     using Synopsys Design Vision (DV). We will also use Synopsys DC to     generate a <code>.sdc</code> which captures timing constraints which can then be     used as input to the place-and-route tool.</p> </li> <li> <p>We use Cadence Innovus to place-and-route our design, which means     to place all of the gates in the gate-level netlist into rows on the     chip and then to generate the metal wires that connect all of the     gates together. We need to provide Cadence Innovus with the same     abstract logical and timing views used in Synopsys DC, but we also     need to provide Cadence Innovus with technology information in     <code>.lef</code>, and <code>.captable</code> format and abstract physical views of the     standard-cell library also in <code>.lef</code> format. Cadence Innovus will     generate an updated Verilog gate-level netlist, a <code>.spef</code> file which     contains parasitic resistance/capacitance information about all nets     in the design, and a <code>.gds</code> file which contains the final layout. The     <code>.gds</code> file can be inspected using the open-source Klayout GDS     viewer. Cadence Innovus also generates reports which can be used to     accurately characterize area and timing.</p> </li> <li> <p>We use Synopsys PrimeTime (PT) to perform power analysis of our     design. We need to provide Synopsys PT with the same abstract     logical, timing, and power views used in Synopsys DC and Cadence     Innovus, but in addition we need to provide switching activity     information for every net in the design (which comes from the <code>.saif</code>     file), and capacitance information for every net in the design (which     comes from the <code>.spef</code> file). Synopsys PT puts the switching     activity, capacitance, clock frequency, and voltage together to     estimate the power consumption of every net and thus every module in     the design, and these estimates are captured in various reports.</p> </li> </ol> <p>Extensive documentation is provided by Synopsys and Cadence for these ASIC tools. We have organized this documentation and made it available to you on the public course webpage:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into a specific <code>ecelinux</code> server and then use Microsoft Remote Desktop to log into the same server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut06-asic-front-end tut06\n% cd tut06\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#1-pymtl3-based-testing-simulation-translation","title":"1. PyMTL3-Based Testing, Simulation, Translation","text":"<p>Our goal in this tutorial is to generate a gate-level netlist for the sort unit from the Verilog tutorial using the ASIC tools. As a reminder, the sort unit takes as input four integers and a valid bit and outputs those same four integers in increasing order with the valid bit. The sort unit is implemented using a three-stage pipelined, bitonic sorting network and the datapath is shown below.</p> <p></p>"},{"location":"ece6745-tut06-asic-front-end/#11-implement-test-and-translate-a-sort-unit","title":"1.1. Implement, Test, and Translate a Sort Unit","text":"<p>Let's start by running the tests for the sort unit and note that the tests for the <code>SortUnitStruct</code> will fail.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort\n</code></pre> <p>You can just copy over your implementation of the <code>MinMaxUnit</code> from when you completed the Verilog tutorial. If you have not completed the Verilog tutorial then you might want to go back and do that now. Basically the <code>MinMaxUnit</code> should look like this:</p> <pre><code>module tut3_verilog_sort_MinMaxUnit\n#(\n  parameter p_nbits = 1\n)(\n  input  logic [p_nbits-1:0] in0,\n  input  logic [p_nbits-1:0] in1,\n  output logic [p_nbits-1:0] out_min,\n  output logic [p_nbits-1:0] out_max\n);\n\n  always_comb begin\n\n    // Find min/max\n\n    if ( in0 &gt;= in1 ) begin\n      out_max = in0;\n      out_min = in1;\n    end\n    else if ( in0 &lt; in1 ) begin\n      out_max = in1;\n      out_min = in0;\n    end\n\n    // Handle case where there is an X in the input\n\n    else begin\n      out_min = 'x;\n      out_max = 'x;\n    end\n\n  end\n\nendmodule\n</code></pre> <p>Once you have your design working rerun the tests with the <code>--test-verilog</code> and <code>--dump-vtb</code> command line options.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort --test-verilog --dump-vtb\n</code></pre> <p>The <code>--test-verilog</code> and <code>--dump-vtb</code> command line options tells the PyMTL3 framework to dump a Verilog testbench. While PyMTL3 enables combining Python testbenches with Verilator Verilog simulation, we need to translate our testbenches to Verilog so that we can use Synopsys VCS to do 4-state and gate-level simulation. Let's look at a testbench cases file generated from using the <code>--dump-vtb</code> flag.</p> <pre><code>% cd $TOPDIR/sim/build\n% cat SortUnitStruct__p_nbits_8_test_basic_tb.v.cases\n\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h04,'h02,'h03,'h01,'h1,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h01,'h02,'h03,'h04,'h1);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n `T('h00,'h00,'h00,'h00,'h0,'h00,'h00,'h00,'h00,'h0);\n</code></pre> <p>This file is generated by logging the inputs and outputs of the Verilator RTL simulation each cycle. It will be passed into a Verilog testbench runner that will use these values to set the inputs each cycle and to verify the outputs each cycle. So note that when we utilize these testbenches later on, we are running a simulation that is simply confirming that we acheive the same behavior as the Verilator RTL simulation we ran using PyMTL3, and it is not actually using any assertions you wrote in your Python tests for your design. Therefore, it is important that your RTL simulations pass using PyMTL3 and Verilator before you move on to other simulations. Also take a look at the testbench itself to get a sense for how it works. It essentially instantiates your top module as <code>DUT</code>, sets the inputs, and performs a check every cycle on the outputs.</p> <pre><code>% cd $TOPDIR/sim/build\n% less SortUnitStruct__p_nbits_8_test_basic_tb.v\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#22-interactive-simulator-for-sort-unit","title":"2.2. Interactive Simulator for Sort Unit","text":"<p>After running the tests we use the interactive simulator for the sort unit to do the final evaluation.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/sort/sort-sim --short-mname --impl rtl-struct --stats \\\n                                --translate --dump-vtb\nnum_cycles          = 106\nnum_cycles_per_sort = 1.06\n</code></pre> <p>Take a moment to open up the translated Verilog which should be in a file named <code>SortUnitStruct__pickled.v</code>. The Verilog module name includes a suffix to make it unique for a specific set of parameters.</p>"},{"location":"ece6745-tut06-asic-front-end/#2-synopsys-vcs-for-4-state-rtl-simulation","title":"2. Synopsys VCS for 4-state RTL simulation","text":"<p>Using the PyMTL simulation framework can give us a good foundation in verifying a design. However, the Verilator RTL simulator is only a 2-state simulation, meaning a signal can only be <code>0</code> or <code>1</code>. An alternative form of RTL simulation is a 4-state simulation, in which signals can be <code>0</code>, <code>1</code>, <code>x</code>, or <code>z</code>.</p> <p>It is important to note a key difference between 2-state and 4-state simulation. In 2-state simulation, each variable is initialized to a predetermined value. This initial condition assumption may or may not be what happens in actual silicon! As a result, a different initial condition could introduce a bug that was not caught by our 2-state Verilator RTL simulation. In 4-state simulations no such assumptions are made. Instead, every signal begins as <code>x</code>, and only resolves to a <code>0</code> or <code>1</code> after it is driven or resolved using x-propagation. Consider the following pseudocode:</p> <pre><code>always @(*)\nbegin\n  if ( control_signal )\n    // set signal \"signal_a\", but bug causes chip to fail\n  else\n    // set signal \"signal_a\" such that everything works fine\nend\n</code></pre> <p>If <code>control_signal</code> is not reset, then in 2-state simulation if you initialize all state to zero it will look like the chip works fine, but this is not a safe assumption! The real chip does not guarantee that all state is initialized to zero, so we can model that in four state simulation as an <code>x</code>. Since the control signal could initialize to 1, this could non-deterministically cause the chip to fail! What you would see in simulation is that <code>signal_a</code> would become an <code>x</code>, because we do not know the value of <code>control_signal</code> on reset. This <code>x</code> is propagated through the design, and some simulators are more optimistic/pessimistic about x's than others. For example, a pessimistic simulator may just assume that any piece of logic that has an x on the input, outputs an x. This is pessimistic because it is possible that you can still resolve the output (imagine a mux where two inputs are the same but the select bit is an <code>x</code>). Optimism is the opposite, resolving signals to <code>0</code> or <code>1</code> that should remain an <code>x</code>.</p> <p>If your design is passing every 2-state simulation, but failing every 4-state simulation, it may be because invalid fields are being set to <code>x</code>'s. Our test harnesses require all outputs to always be <code>0</code> or <code>1</code> even if a field is invalid. So you may need to force invalid fields to zero and ensure that during a correct execution the outputs of your module are never <code>x</code>'s. You can see this in the implementation of <code>SortUnitStruct</code>:</p> <pre><code>assign out_val = val_S3;\nassign out0    = elm0_S3         &amp; {p_nbits{val_S3}};\nassign out1    = mmuA_out_min_S3 &amp; {p_nbits{val_S3}};\nassign out2    = mmuA_out_max_S3 &amp; {p_nbits{val_S3}};\nassign out3    = elm3_S3         &amp; {p_nbits{val_S3}};\n</code></pre> <p>We run Synopsys VCS to compile a simulation, and <code>./simv</code> to run the simulation. Let's run a 4-state simulation for <code>test_basic</code> using the design <code>SortUnitStruct__pickled.v</code>.</p> <pre><code>% cd $TOPDIR/asic/build-sort/01-synopsys-vcs-rtlsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${TOPDIR}/sim/build/SortUnitStruct__p_nbits_8_test_basic_tb.v \\\n    ${TOPDIR}/sim/build/SortUnitStruct__p_nbits_8__pickled.v\n% ./simv\n</code></pre> <p>Here some of the key command line options for Synopsys VCS:</p> <pre><code>-sverilog                     indicates we are using SystemVerilog\n-xprop=tmerge                 use more advanced X propoagation\n-override_timescale=1ns/1ps   changes the timescale. Units/precision\n-top Top                      name of the top module (located within the VTB)\n+vcs+dumpvars+filename.vcd    dump VCD in current dir with the name filename.vcd\n+incdir+$TOPDIR/sim/build     specifies directories to search for `include\n</code></pre> <p>Synopsys VCS is a sophisticated tool with many command line options. If you want to learn more on your own about other options that are available to you with Synopsys VCS, you can look at the user guides on the course webpage:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>Open up the resulting VCD filea and notice how all of the input ports start as X values and then eventually become non-X values after reset. Notice how the pipeline registers are not reset so it takes a few cycles for them to be output non-X values.</p> <p></p> <p>Let's run another 4-state simulation, this time using the testbench from the sort-rtl simulator run that we ran earlier. Note that while we can use this VCD for power analysis, for the purposes of this tutorial we will only be doing power analysis using the gate-level netlist.</p> <pre><code>% cd $TOPDIR/asic/build-sort/01-synopsys-vcs-rtlsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n      +vcs+dumpvars+waves.vcd \\\n      +incdir+${TOPDIR}/sim/build \\\n      ${TOPDIR}/sim/build/SortUnitStruct_random_tb.v \\\n      ${TOPDIR}/sim/build/SortUnitStruct__pickled.v\n% ./simv\n</code></pre> <p>To simplify rerunning a simulation, we can put the above command lines in a shell script. We have created such a run script for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./01-synopsys-vcs-rtlsim/run\n</code></pre> <p>You can rerun four-state RTL simulation as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./01-synopsys-vcs-rtlsim/run\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#3-synopsys-design-compiler-for-synthesis","title":"3. Synopsys Design Compiler for Synthesis","text":"<p>We use Synopsys Design Compiler (DC) to synthesize Verilog RTL models into a gate-level netlist where all of the gates are from the standard cell library. So Synopsys DC will synthesize the Verilog <code>+</code> operator into a specific arithmetic block at the gate-level. Based on various constraints it may synthesize a ripple-carry adder, a carry-look-ahead adder, or even more advanced parallel-prefix adders.</p> <p>We start by creating a subdirectory for our work, and then launching Synopsys DC.</p> <pre><code>% cd $TOPDIR/asic/build-sort/02-synopsys-dc-synth\n% dc_shell-xg-t\n</code></pre> <p>To make it easier to copy-and-paste commands from this document, we tell Synopsys DC to ignore the prefix <code>dc_shell&gt;</code> using the following:</p> <pre><code>dc_shell&gt; alias \"dc_shell&gt;\" \"\"\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#31-initial-setup","title":"3.1. Initial Setup","text":"<p>There are two important variables we need to set before starting to work in Synopsys DC. The <code>target_library</code> variable specifies the standard cells that Synopsys DC should use when synthesizing the RTL. The <code>link_library</code> variable should search the standard cells, but can also search other cells (e.g., SRAMs) when trying to resolve references in our design. These other cells are not meant to be available for Synopsys DC to use during synthesis, but should be used when resolving references. Including <code>*</code> in the <code>link_library</code> variable indicates that Synopsys DC should also search all cells inside the design itself when resolving references.</p> <pre><code>dc_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\ndc_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>Note that we can use <code>$env(ECE6745_STDCELLS)</code> to get access to the <code>$ECE6745_STDCELLS</code> environment variable which specifies the directory containing the standard cells, and that we are referencing the abstract logical and timing views in the <code>.db</code> format.</p> <p>We also need to tell Synopsys DC not use scan flip-flops and clock-gating cells which are included in our standard-cell library. If Synopsys DC uses these cells it can cause isses with gate-level simulation. We can do this using the <code>set_dont_use</code> command as follows.</p> <pre><code>dc_shell&gt; set_dont_use -power {\n  NangateOpenCellLibrary/SDFF_X1\n  NangateOpenCellLibrary/SDFF_X2\n  NangateOpenCellLibrary/SDFFS_X1\n  NangateOpenCellLibrary/SDFFS_X2\n  NangateOpenCellLibrary/SDFFR_X1\n  NangateOpenCellLibrary/SDFFR_X2\n  NangateOpenCellLibrary/SDFFRS_X1\n  NangateOpenCellLibrary/SDFFRS_X2\n  NangateOpenCellLibrary/CLKGATETST_X1\n  NangateOpenCellLibrary/CLKGATETST_X2\n  NangateOpenCellLibrary/CLKGATETST_X4\n  NangateOpenCellLibrary/CLKGATETST_X8\n}\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#32-inputs","title":"3.2. Inputs","text":"<p>As an aside, if you want to learn more about any command in any Synopsys tool, you can simply type <code>man toolname</code> at the shell prompt. We are now ready to read in the Verilog file which contains the top-level design and all referenced modules. We do this with two commands. The <code>analyze</code> command reads the Verilog RTL into an intermediate internal representation. The <code>elaborate</code> command recursively resolves all of the module references starting from the top-level module, and also infers various registers and/or advanced data-path components.</p> <pre><code>dc_shell&gt; analyze -format sverilog ../../../sim/build/SortUnitStruct__pickled.v\ndc_shell&gt; elaborate SortUnitStruct\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#33-timing-constraints","title":"3.3. Timing Constraints","text":"<p>We need to create a clock constraint to tell Synopsys DC what our target cycle time is. Synopsys DC will not synthesize a design to run \"as fast as possible\". Instead, the designer gives Synopsys DC a target cycle time and the tool will try to meet this constraint while minimizing area and power. The <code>create_clock</code> command takes the name of the clock signal in the Verilog (which in this course will always be <code>clk</code>), the label to give this clock (i.e., <code>ideal_clock1</code>), and the target clock period in nanoseconds. So in this example, we are asking Synopsys DC to see if it can synthesize the design to run at 1.4GHz (i.e., a cycle time of 700ps).</p> <pre><code>dc_shell&gt; create_clock clk -name ideal_clock1 -period 0.7\n</code></pre> <p>In addition to the clock constraint we also need to constrain the max transition time to ensure no net takes a very long time to transition. Here we constrain the max transition to be 250ps.</p> <pre><code>dc_shell&gt; set_max_transition 0.250 SortUnitStruct\n</code></pre> <p>We need to constrain what kind of cells are expected to drive the input pins and what kind of load is expected at the output pin so Synopsys DC can properly synthesize the design. here we constrain the input cells to be inverters with 2x drive strength and the output load to be 7fF.</p> <pre><code>dc_shell&gt; set_driving_cell -no_design_rule -lib_cell INV_X2 [all_inputs]\ndc_shell&gt; set_load -pin_load 7 [all_outputs]\n</code></pre> <p>In an ideal world, all inputs would change immediately with the clock edge. In reality, this is not the case since there will be some logic before this block on the chip as shown in the following figure.</p> <p></p> <p>We need to include reasonable propagation and contamination delays for the input ports so Synopsys DC can factor these into its timing analysis. Here, we choose the max input delay constraint to be 50ps (i.e., the block needs to meet the setup time constraints even if the inputs change 50ps after the rising edge of the clock), and we choose the min input delay constraint to be 0ps (i.e., the block needs to meet the hold time constraints even if the inputs change right on the rising edge clock).</p> <pre><code>dc_shell&gt; set_input_delay -clock ideal_clock1 -max 0.050 [all_inputs -exclude_clock_ports]\ndc_shell&gt; set_input_delay -clock ideal_clock1 -min 0.000 [all_inputs -exclude_clock_ports]\n</code></pre> <p>We also need to constrain the output ports since there will be some logic after this block on the chip as shown in the following figure.</p> <p></p> <p>We need to include reasonable setup and hold time constraints for the output ports so Synopsys DC can factor these into into its timing analysis. Here we choose a setup time constraint of 50ps meaning the output data must be stable 50ps before the rising edge of the clock, and we choose a hold time constraint of 0ps meaning the outputs can change right on the rising edge of the clock.</p> <pre><code>dc_shell&gt; set_output_delay -clock ideal_clock1 -max 0.050 [all_outputs]\ndc_shell&gt; set_output_delay -clock ideal_clock1 -min 0.000 [all_outputs]\n</code></pre> <p>Finally we also need to constraint any combinational paths which go directly from the input ports to the output ports. Here we constrain such paths to be no longer than one cycle cycle.</p> <pre><code>dc_shell&gt; set_max_delay 0.7 -from [all_inputs -exclude_clock_ports] -to [all_outputs]\n</code></pre> <p>Once we have finished setting all of the constraints we can use <code>check_timing</code> to make sure there are no unconstrained paths or other issues.</p>"},{"location":"ece6745-tut06-asic-front-end/#34-synthesis","title":"3.4. Synthesis","text":"<p>We can use the <code>check_design</code> command to make sure there are no obvious errors in our Verilog RTL.</p> <pre><code>dc_shell&gt; check_design\n</code></pre> <p>It is critical that you carefully review all warnings and errors when you analyze and elaborate a design with Synopsys DC. There may be many warnings, but you should still skim through them. Often times there will be something very wrong in your Verilog RTL which means any results from using the ASIC tools is completely bogus. Synopsys DC will output a warning, but Synopsys DC will usually just keep going, potentially producing a completely incorrect gate-level model!</p> <p>Finally, the <code>compile</code> command will do the synthesis.</p> <pre><code>dc_shell&gt; compile\n</code></pre> <p>During synthesis, Synopsys DC will display information about its optimization process. It will report on its attempts to map the RTL into standard-cells, optimize the resulting gate-level netlist to improve the delay, and then optimize the final design to save area.</p> <p>The <code>compile</code> command does not flatten your design. Flatten means to remove module hierarchy boundaries; so instead of having module A and module B within module C, Synopsys DC will take all of the logic in module A and module B and put it directly in module C. You can enable flattening with the <code>-ungroup_all</code> option. Without extra hierarchy boundaries, Synopsys DC is able to perform more optimizations and potentially achieve better area, energy, and timing. However, an unflattened design is much easier to analyze, since if there is a module A in your RTL design that same module will always be in the synthesized gate-level netlist.</p> <p>The <code>compile</code> command does not perform many optimizations. Synopsys DC also includes <code>compile_ultra</code> which does many more optimizations and will likely produce higher quality of results. Keep in mind that the <code>compile</code> command will not flatten your design by default, while the <code>compile_ultra</code> command will flattened your design by default. You can turn off flattening by using the <code>-no_autoungroup</code> option with the <code>compile_ultra</code> command. <code>compile_ultra</code> also has the option <code>-gate_clock</code> which automatically performs clock gating on your design, which can save quite a bit of power. Once you finish this tutorial, feel free to go back and experiment with this command.</p> <pre><code>dc_shell&gt; compile_ultra -no_autoungroup -gate_clock`\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#34-outputs","title":"3.4. Outputs","text":"<p>Now that we have synthesized the design, we output the resulting gate-level netlist in two different file formats: <code>.ddc</code> (which we will use with Synopsys DesignVision) and Verilog. We also output an <code>.sdc</code> file which contains the constraint information we gave Synopsys DC. We will pass this same constraint information to Cadence Innovus during the place and route portion of the flow.</p> <pre><code>dc_shell&gt; write -format ddc     -hierarchy -output post-synth.ddc\ndc_shell&gt; write -format verilog -hierarchy -output post-synth.v\ndc_shell&gt; write_sdc post-synth.sdc\n</code></pre> <p>We can use various commands to generate reports about timing and area. The <code>report_timing</code> command will show the critical path through the design. Part of the report is displayed below.</p> <pre><code>dc_shell&gt; report_timing -nets\n Point                                      Fanout Incr  Path\n ---------------------------------------------------------------\n clock ideal_clock1 (rise edge)                    0.00  0.00\n clock network delay (ideal)                       0.00  0.00\n v/elm1_S0S1/q_reg[1]/CK (DFF_X1)                  0.00  0.00 r\n v/elm1_S0S1/q_reg[1]/Q (DFF_X1)                   0.08  0.08 f\n v/elm1_S0S1/q[1] (net)                     2      0.00  0.08 f\n v/elm1_S0S1/q[1] (vc_Reg_p_nbits8_11)             0.00  0.08 f\n v/elm1_S1[1] (net)                                0.00  0.08 f\n v/mmuA_S1/in1[1] (MinMaxUnit)                     0.00  0.08 f\n v/mmuA_S1/in1[1] (net)                            0.00  0.08 f\n v/mmuA_S1/U10/ZN (INV_X1)                         0.04  0.12 r\n v/mmuA_S1/n22 (net)                        3      0.00  0.12 r\n v/mmuA_S1/U45/ZN (AOI21_X1)                       0.03  0.15 f\n v/mmuA_S1/n8 (net)                         1      0.00  0.15 f\n v/mmuA_S1/U46/ZN (AOI222_X1)                      0.09  0.24 r\n v/mmuA_S1/n9 (net)                         1      0.00  0.24 r\n v/mmuA_S1/U9/ZN (NOR3_X1)                         0.03  0.27 f\n v/mmuA_S1/n10 (net)                        1      0.00  0.27 f\n v/mmuA_S1/U6/ZN (NOR3_X1)                         0.06  0.33 r\n v/mmuA_S1/n11 (net)                        1      0.00  0.33 r\n v/mmuA_S1/U3/ZN (NOR3_X1)                         0.03  0.36 f\n v/mmuA_S1/n12 (net)                        1      0.00  0.36 f\n v/mmuA_S1/U47/ZN (AOI221_X1)                      0.08  0.44 r\n v/mmuA_S1/n13 (net)                        1      0.00  0.44 r\n v/mmuA_S1/U48/ZN (OAI22_X1)                       0.05  0.49 f\n v/mmuA_S1/n15 (net)                        2      0.00  0.49 f\n v/mmuA_S1/U27/ZN (OAI21_X1)                       0.04  0.53 r\n v/mmuA_S1/N1 (net)                         1      0.00  0.53 r\n v/mmuA_S1/U49/ZN (INV_X2)                         0.06  0.59 f\n v/mmuA_S1/n23 (net)                        6      0.00  0.59 f\n v/mmuA_S1/U43/ZN (OAI22_X1)                       0.06  0.65 r\n v/mmuA_S1/out_max[7] (net)                 1      0.00  0.65 r\n v/mmuA_S1/out_max[7] (MinMaxUnit)                 0.00  0.65 r\n v/mmuA_out_max_S1[7] (net)                        0.00  0.65 r\n v/elm1_S1S2/d[7] (vc_Reg_p_nbits8_7)              0.00  0.65 r\n v/elm1_S1S2/d[7] (net)                            0.00  0.65 r\n v/elm1_S1S2/q_reg[7]/D (DFF_X1)                   0.01  0.66 r\n data arrival time                                       0.66\n\n clock ideal_clock1 (rise edge)                    0.70  0.70\n clock network delay (ideal)                       0.00  0.70\n v/elm1_S1S2/q_reg[7]/CK (DFF_X1)                  0.00  0.70 r\n library setup time                               -0.04  0.66\n data required time                                      0.66\n ---------------------------------------------------------------\n data required time                                      0.66\n data arrival time                                       0.66\n ---------------------------------------------------------------\n slack (MET)                                             0.00\n</code></pre> <p>This timing report uses static timing analysis to find the critical path. Static timing analysis checks the timing across all paths in the design (regardless of whether these paths can actually be used in practice) and finds the longest path. For more information about static timing analysis, consult Chapter 1 of the Synopsys Timing Constraints and Optimization User Guide. The report clearly shows that the critical path starts at bit 1 of a pipeline register in between the S0 and S1 stages (<code>elm1_S0S1</code>), goes into an input of a <code>MinMaxUnit</code>, comes out the <code>out_max</code> port of the <code>MinMaxUnit</code>, and ends at the pipeline register between the S1 and S2 stages (`elm1_S1S21). The report shows the delay through each logic gate (e.g., the clk-to-q delay of the initial DFF is 80ps, the propagation delay of a AOI21_X1 gate is 150ps) and the total delay for the critical path which in this case is 0.66ns.</p> <p>The difference between the required arrival time and the actual arrival time is called the slack. In the above report we just meet timing with zero slack. Positive slack means the path arrived before it needed to while negative slack means the path arrived after it needed to. If you end up with negative slack, then you need to rerun the tools with a longer target clock period until you can meet timing with no negative slack. The process of tuning a design to ensure it meets timing is called \"timing closure\". In this course, we are primarily interested in design-space exploration as opposed to meeting some externally defined target timing specification. So you will need to sweep a range of target clock periods. Your goal is to choose the shortest possible clock period which still meets timing without any negative slack! This will result in a well-optimized design and help identify the \"fundamental\" performance of the design. Alternatively, if you are comparing multiple designs, sometimes the best situation is to tune the baseline so it meets timing and then ensure the alternative designs have similar cycle times. This will enable a fair comparison since all designs will be running at the same cycle time.</p> <p>The <code>report_area</code> command will show how much area is required to implement each module in the design.</p> <pre><code>                    Global cell area          Local cell area\n                    ------------------  ---------------------------\nHierarchical cell   Absolute   Percent  Combi-    Noncombi-  Black-\n                    Total      Total    national  national   boxes   Design\n------------------  ---------  -------  --------  ---------  ------  -----------------------------------------\nSortUnitStruct       745.0660    100.0    0.0000     0.0000  0.0\n  SortUnitStruct\nv                    745.0660    100.0   35.9100     0.0000  0.0000  tut3_verilog_sort_SortUnitStruct_p_nbits8\nv/elm0_S0S1           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_0\nv/elm0_S1S2           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_8\nv/elm0_S2S3           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_4\nv/elm1_S0S1           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_11\nv/elm1_S1S2           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_7\nv/elm1_S2S3           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_3\nv/elm2_S0S1           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_10\nv/elm2_S1S2           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_6\nv/elm2_S2S3           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_2\nv/elm3_S0S1           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_9\nv/elm3_S1S2           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_5\nv/elm3_S2S3           36.1760      4.9    0.0000    36.1760  0.0000  vc_Reg_p_nbits8_1\nv/mmuA_S1             50.0080      6.7   50.0080     0.0000  0.0000  tut3_verilog_sort_MinMaxUnit_p_nbits8_0\nv/mmuA_S2             50.0080      6.7   50.0080     0.0000  0.0000  tut3_verilog_sort_MinMaxUnit_p_nbits8_3\nv/mmuA_S3             57.1900      7.7   57.1900     0.0000  0.0000  tut3_verilog_sort_MinMaxUnit_p_nbits8_1\nv/mmuB_S1             50.2740      6.7   50.2740     0.0000  0.0000  tut3_verilog_sort_MinMaxUnit_p_nbits8_4\nv/mmuB_S2             50.0080      6.7   50.0080     0.0000  0.0000  tut3_verilog_sort_MinMaxUnit_p_nbits8_2\nv/val_S0S1             5.8520      0.8    1.3300     4.5220  0.0000  vc_ResetReg_p_nbits1_0\nv/val_S1S2             5.8520      0.8    1.3300     4.5220  0.0000  vc_ResetReg_p_nbits1_2\nv/val_S2S3             5.8520      0.8    1.3300     4.5220  0.0000  vc_ResetReg_p_nbits1_1\n------------------  ---------  -------  --------  ---------  ------  -----------------------------------------\nTotal                                   297.3880   447.6780  0.0000\n</code></pre> <p>The design requires 745um^2. Each pipeline register requires about 5% of the total area and each min/max unit requires about 7% of the total area. The area required for all 12 pipeline registers is about 60% of the total area, and the area required for all five of the min/max units is about 35% of the total area.</p> <p>Finally, we go ahead and exit Synopsys DC.</p> <pre><code>dc_shell&gt; exit\n</code></pre> <p>Take a few minutes to examine the resulting Verilog gate-level netlist. Notice that the module hierarchy is preserved and also notice that the <code>MinMaxUnit</code> synthesizes into a large number of basic logic gates.</p> <pre><code>% cd $TOPDIR/asic/build-sort/02-synopsys-dc-synth\n% more post-synth.v\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#35-synopsys-design-vision","title":"3.5. Synopsys Design Vision","text":"<p>We can use the Synopsys Design Vision (DV) tool for browsing the resulting gate-level netlist, plotting critical path histograms, and generally analyzing our design. Start Synopsys DV and setup the <code>target_library</code> and <code>link_library</code> variables as before.</p> <pre><code>% cd $TOPDIR/asic/build-sort/02-synopsys-dc-synth\n% design_vision-xg\ndesign_vision&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\ndesign_vision&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>You can use the following steps to open the <code>.ddc</code> file generated during synthesis.</p> <ul> <li>Choose File &gt; Read from the menu</li> <li>Open the <code>post-synth.dcc</code> file</li> </ul> <p>You can then use the following steps to browse the gate-level schematic. First select a module in the Logical Hierarchy panel. Then choose Schematic &gt; New Schematic View. You can double click on modules to expand them. You might also want to try this approach to see the entire design at once:</p> <ul> <li>Select the <code>SortUnitStruct__p_nbits_8</code> module in the Logical Hierarchy panel</li> <li>Choose Select &gt; Cells &gt; Leaf Cells of Selected Cells from the menu</li> <li>Choose Schematic &gt; New Schematic View from the menu</li> <li>Choose Select &gt; Clear from the menu</li> </ul> <p>You can use the following steps to view a histogram of path slack, and also to open a gave-level schematic of just the critical path.</p> <ul> <li>Choose Timing &gt; Path Slack from the menu</li> <li>Click OK in the pop-up window</li> <li>Select the left-most bar in the histogram to see list of most critical paths</li> <li>Select one of the paths in the path list to highlight the path in the schematic view</li> </ul> <p>Or you can right click on a path and choose Path Schematic to see just the gates that lie on the critical path. Notice that there eight levels of logic (including the register at the start) on the critical path. The number of levels of logic on the critical path can provide some very rough first-order intuition on whether or not we might want to explore a more aggressive clock constraint and/or adding more pipeline stages. If there are just a few levels of logic on the critical path then our design is probably very simple (as in this case!), while if there are more than 50 levels of logic then there is potentially room for signficant improvement. The following screen capture illutrates using Synopsys Design Vision to explore the post-synthesis results. While this can be interesting, in this course, we almost always prefer exploring the post-place-and-route results, so we will not really use Synopsys DV that often.</p> <p></p>"},{"location":"ece6745-tut06-asic-front-end/#36-automating-synthesis","title":"3.6. Automating Synthesis","text":"<p>You can automate the above steps by putting a sequence of commands in a <code>.tcl</code> file and run Synopsys DC using those commands in one step like this:</p> <pre><code>% cd $TOPDIR/asic/build-sort/02-synopsys-dc-synth\n% dc_shell-xg-t -f run.tcl\n</code></pre> <p>To further simplify rerunning this step, we can put the above command line in its own shell script. We have created such run scripts for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./02-synopsys-dc-synth/run\n% cat ./02-synopsys-dc-synth/run.tcl\n</code></pre> <p>You can rerun synthesis as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./02-synopsys-dc-synth/run\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#4-synopsys-vcs-for-fast-functional-gate-level-simulation","title":"4. Synopsys VCS for Fast-Functional Gate-Level Simulation","text":"<p>Before synthesis, we used Synopsys VCS to do a 4-state simulation. This time, we'll be using VCS to perform a gate-level simulation, since we now have a gate-level netlist available to us. Gate-level simulation provides an advantage over RTL simulation because it more precisely represents the specification of the true hardware generated by the tools. This sort of simulation could propogate X's into the design that were not found by the 4-state RTL simulation, and it also verifies that the tools did not optimize anything away during synthesis. We will use Synopsys VCS to run our gate-level simulation on the <code>sort-rtl-struct-random</code> simulator testbench:</p> <pre><code>% cd $TOPDIR/asic/build-sort/03-synopsys-vcs-ffglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n   +delay_mode_zero \\\n   +vcs+dumpvars+waves.vcd \\\n   +incdir+$TOPDIR/sim/build \\\n   ${ECE6745_STDCELLS}/stdcells.v \\\n   ${TOPDIR}/sim/build/SortUnitStruct_random_tb.v \\\n   ../02-synopsys-dc-synth/post-synth.v\n% ./simv\n</code></pre> <p>Notice there are some differences in the Synopsys VCS command we ran here, and the one we ran for 4-state RTL simulation. In this version, we use the gate-level netlist <code>post-synth.v</code> instead of the pickled file. We also include the option <code>+delay_mode_zero</code> which tells Synopsys VCS to run a fast-functional simulation in which no delays are considered. This is similar to RTL simulation, and you should notice that all signals will change on the clock edge. We also include the macros <code>CYCLE_TIME</code>, <code>VTB_INPUT_DELAY</code> , <code>VTB_OUTPUT_ASSERT_DELAY</code>. These values control how long after the rising edge we change the inputs and how long after the rising edge we check the outputs.</p> <p>To simplify rerunning a simulation, we can put the above command lines in a shell script. We have created such a run script for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>You can rerun fast-functional gate-level simulation as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./03-synopsys-vcs-ffglsim/run\n</code></pre>"},{"location":"ece6745-tut06-asic-front-end/#5-to-do-on-your-own","title":"5. To-Do On Your Own","text":"<p>Now we can use what you have learned so far to push the GCD unit through the ASIC front-end flow. First, run a simulation of the GCD unit.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/gcd/gcd-sim --short-mname --impl rtl --input random --stats \\\n                              --translate --dump-vtb\n% less GcdUnit__pickled.v\n</code></pre> <p>Now create a new ASIC build directory and copy the scripts we used to push the sort unit through the ASIC front-end flow.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-gcd/01-synopsys-vcs-rtlsim\n% mkdir -p $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% mkdir -p $TOPDIR/asic/build-gcd/03-synopsys-vcs-ffglsim\n\n% cp $TOPDIR/asic/build-sort/01-synopsys-vcs-rtlsim/run   $TOPDIR/asic/build-gcd/01-synopsys-vcs-rtlsim\n% cp $TOPDIR/asic/build-sort/02-synopsys-dc-synth/run.tcl $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% cp $TOPDIR/asic/build-sort/02-synopsys-dc-synth/run     $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% cp $TOPDIR/asic/build-sort/03-synopsys-vcs-ffglsim/run  $TOPDIR/asic/build-gcd/03-synopsys-vcs-ffglsim\n</code></pre> <p>Now open up each of these files and modify so they push the GCD unit instead of the sort unit through the flow. You will need to update the name of the Verilog source files and the top module name as follows:</p> <ul> <li>Verilog source file name: <code>GcdUnit__pickled.v</code></li> <li>Verilog test source file name: <code>GcdUnit_random_tb.v</code></li> <li>Top module name for synthesis: <code>GcdUnit</code></li> </ul> <p>Basically, you just need to change <code>SortUnitStruct</code> to <code>GcdUnit</code> in all of the run scripts. You can use <code>sed</code> to do this:</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% find . -type f -exec sed -i.bak 's/SortUnitStruct/GcdUnit/' {} \\;\n</code></pre> <p>Keep the cycle time constraint as 700ps and the other constraints as before. Once you have updated the scripts you can then push the GCD unit through the flow like this:</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>Carefully look at the post-synthesis timing report to ensure your design meetings timing:</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% cat 02-synopsys-dc-synth/timing.rpt\n</code></pre> <p>If your design does not meet timing, increase the cycle time constraint and try again until it does meet timing. Spend time looking at the post-synthesis gate-level netlist in <code>post-synth.v</code> and load the design into Synopsys Design Vision to examine the critical path. Carefully look and the results from running the fast-functional gate-level simulation to verify that the design is passing the test. Convince yourself that the GCD unit was successfully pushed through the ASIC front-end flow.</p>"},{"location":"ece6745-tut07-asic-back-end/","title":"ECE 6745 Tutorial 6: ASIC Back-End Flow","text":"<p>The tutorial will discuss the key tools used for ASIC back-end flow which includes place-and-route, back-annotated gate-level simulation, and power analysis. This tutorial requires entering commands manually for each of the tools to enable students to gain a better understanding of the detailed steps involved in this process. A later tutorial will illustrate how this process can be automated to facilitate rapid design-space exploration. This tutorial assumes you have already completed the tutorials on Linux, Git, and Verilog.</p> <p>The following diagram illustrates the five primary tools we will be using in ECE 6745 along with a few smaller secondary tools. The tools that make-up the ASIC back-end flow are highlighted in red. Notice that the ASIC tools all require various views from the standard-cell library. Before starting this tutorial, you must complete the ASIC standard-cell tutorial so you can understand all of these views and you must complete the ASIC front-end flow tutorial.</p> <p></p> <ol> <li> <p>We write our RTL models in Verilog, and we use the PyMTL framework to     test, verify, and evaluate the execution time (in cycles) of our     design. This part of the flow is very similar to the flow used in     ECE 4750. Once we are sure our design is working correctly, we can     then start to push the design through the flow.</p> </li> <li> <p>We use Synopsys VCS to compile and run both 4-state RTL and     gate-level simulations. These simulations help us to build confidence     in our design as we push our designs through different stages of the     flow. From these simulations, we also generate waveforms in <code>.vcd</code>     (Verilog Change Dump) format, and per-net average activity factors     stored in <code>.saif</code> format. These activity factors will be used for     power analysis. Gate-level simulation is an valuable tool for     ensuring the tools did not optimize something away which impacts the     correctness of the design, and also provides an avenue for obtaining     a more accurate power analysis than RTL simulation. While static     timing analysis (STA) analyzes all paths, GL simulation can also     serve as a backup to check for hold and setup time violations (chip     designers must be paranoid!)</p> </li> <li> <p>We use Synopsys Design Compiler (DC) to synthesize our design,     which means to transform the Verilog RTL model into a Verilog     gate-level netlist where all of the gates are selected from the     standard-cell library. We need to provide Synopsys DC with abstract     logical and timing views of the standard-cell library in <code>.db</code>     format. In addition to the Verilog gate-level netlist, Synopsys DC     can also generate a <code>.ddc</code> file which contains information about the     gate-level netlist and timing, and this <code>.ddc</code> file can be inspected     using Synopsys Design Vision (DV). We will also use Synopsys DC to     generate a <code>.sdc</code> which captures timing constraints which can then be     used as input to the place-and-route tool.</p> </li> <li> <p>We use Cadence Innovus to place-and-route our design, which means     to place all of the gates in the gate-level netlist into rows on the     chip and then to generate the metal wires that connect all of the     gates together. We need to provide Cadence Innovus with the same     abstract logical and timing views used in Synopsys DC, but we also     need to provide Cadence Innovus with technology information in     <code>.lef</code>, and <code>.captable</code> format and abstract physical views of the     standard-cell library also in <code>.lef</code> format. Cadence Innovus will     generate an updated Verilog gate-level netlist, a <code>.spef</code> file which     contains parasitic resistance/capacitance information about all nets     in the design, and a <code>.gds</code> file which contains the final layout. The     <code>.gds</code> file can be inspected using the open-source Klayout GDS     viewer. Cadence Innovus also generates reports which can be used to     accurately characterize area and timing.</p> </li> <li> <p>We use Synopsys PrimeTime (PT) to perform power analysis of our     design. We need to provide Synopsys PT with the same abstract     logical, timing, and power views used in Synopsys DC and Cadence     Innovus, but in addition we need to provide switching activity     information for every net in the design (which comes from the <code>.saif</code>     file), and capacitance information for every net in the design (which     comes from the <code>.spef</code> file). Synopsys PT puts the switching     activity, capacitance, clock frequency, and voltage together to     estimate the power consumption of every net and thus every module in     the design, and these estimates are captured in various reports.</p> </li> </ol> <p>Extensive documentation is provided by Synopsys and Cadence for these ASIC tools. We have organized this documentation and made it available to you on the public course webpage:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into a specific <code>ecelinux</code> server and then use Microsoft Remote Desktop to log into the same server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut07-asic-back-end tut07\n% cd tut07\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#1-revisiting-the-asic-flow-front-end","title":"1. Revisiting the ASIC Flow Front-End","text":"<p>Our goal in this tutorial is to generate layout for the sort unit from the Verilog tutorial using the ASIC tools. As a reminder, the sort unit takes as input four integers and a valid bit and outputs those same four integers in increasing order with the valid bit. The sort unit is implemented using a three-stage pipelined, bitonic sorting network and the datapath is shown below.</p> <p></p> <p>Before we can place and route a gate-level netlist, we need to synthesize that netlist. This is what we learned about in the last section. Here are the steps to test and then synthesize the design using Synopsys DC.</p>"},{"location":"ece6745-tut07-asic-back-end/#11-test-simulate-translate","title":"1.1. Test, Simulate, Translate","text":"<p>Always run the tests before pushing anything through the ASIC flow. There is no sense in running the flow if the design is incorrect!</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort\n</code></pre> <p>The tests are for verification. When we push a design through the flow we want to use a simulator which is focused on evaluation. You can run the simulator for our sort unit like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/sort/sort-sim --short-mname --impl rtl-struct --stats \\\n                                --translate --dump-vtb\nnum_cycles          = 106\nnum_cycles_per_sort = 1.06\n</code></pre> <p>You should now have the Verilog that we want to push through the ASIC flow.</p>"},{"location":"ece6745-tut07-asic-back-end/#12-simulate-synthesize-simulate","title":"1.2. Simulate, Synthesize, Simulate","text":"<p>Let's take a look at each script to confirm it matches the manual commands we used in the previous discussion section. Here is the run script for four-start RTL simulation.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./01-synopsys-vcs-rtlsim/run\n</code></pre> <p>Here is the run script for synthesis.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./02-synopsys-dc-synth/run\n</code></pre> <p>Notice that this script simply executes <code>dc_shell-xg-t</code> with a TCL script which contains the commands to: configure the standard cell library, analyze and elaborate the design; setup timing constraints; synthesize the design; write outputs; and write final outputs (i.e., Verilog and DDC) and reports (i.e., timing report and area report).</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./02-synopsys-dc-synth/run.tcl\n</code></pre> <p>Finally, here is the run script for fast-functional gate-level simulation. The key difference from four-state RTL simulation is that this simulation takes as input the Verilog for the standard-cell library and the Verilog for the post-synthesis gate-level netlist.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>You can run these steps as follows:</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n</code></pre> <p>Verify that your design passes four-state RTL simulation and fast-functional gate-level simulation. Then take a look at the synthesis reports.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% less ./02-synopsys-dc-synth/timing.rpt\n% less ./02-synopsys-dc-synth/area.rpt\n</code></pre> <p>Finally, take a few minutes to examine the resulting Verilog gate-level netlist. Notice that the module hierarchy is preserved.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% less ./02-synopsys-dc-synth/post-synth.v\n</code></pre> <p>This is the gate-level netlist that we now want to push through the ASIC back-end flow.</p>"},{"location":"ece6745-tut07-asic-back-end/#2-cadence-innovus-for-place-and-route","title":"2. Cadence Innovus for Place-and-Route","text":"<p>We use Cadence Innovus for placing standard cells in rows and then automatically routing all of the nets between these standard cells. We also use Cadence Innovus to route the power and ground rails in a grid and connect this grid to the power and ground pins of each standard cell, and to automatically generate a clock tree to distribute the clock to all sequential state elements with hopefully low skew.</p> <p>We will be running Cadence Innovus in a separate directory to keep the files separate from the other tools.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sort/04-cadence-innovus-pnr\n% cd $TOPDIR/asic/build-sort/04-cadence-innovus-pnr\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#21-timing-analysis-setup-file","title":"2.1. Timing Analysis Setup File","text":"<p>Before starting Cadence Innovus, we need to create a file to setup the timing analysis. This file specifies what \"corner\" to use for our timing analysis. A corner is a characterization of the standard cell library and technology with specific assumptions about the process, temperature, and voltage (PVT). So we might have a \"fast\" corner which assumes best-case process variability, low temperature, and high voltage, or we might have a \"slow\" corner which assumes worst-case variability, high temperature, and low voltage. To ensure our design will work across a range of operating conditions, we need to evaluate our design across a range of corners. In this course, we will keep things simple by only considering a \"typical\" corner (i.e., average PVT). Use VS Code to create a file named <code>setup-timing.tcl</code>.</p> <pre><code>% cd $TOPDIR/asic/04-cadence-innovus-pnr\n% code setup-timing.tcl\n</code></pre> <p>The file should have the following content:</p> <pre><code>create_rc_corner -name typical \\\n   -cap_table \"$env(ECE6745_STDCELLS)/rtk-typical.captable\" \\\n   -T 25\n\ncreate_library_set -name libs_typical \\\n   -timing [list \"$env(ECE6745_STDCELLS)/stdcells.lib\"]\n\ncreate_delay_corner -name delay_default \\\n   -library_set libs_typical \\\n   -rc_corner typical\n\ncreate_constraint_mode -name constraints_default \\\n   -sdc_files [list ../02-synopsys-dc-synth/post-synth.sdc]\n\ncreate_analysis_view -name analysis_default \\\n   -constraint_mode constraints_default \\\n   -delay_corner delay_default\n\nset_analysis_view -setup analysis_default -hold analysis_default\n</code></pre> <p>The <code>create_rc_corner</code> command loads in the <code>.captable</code> file that we examined earlier. This file includes information about the resistance and capacitance of every metal layer. Notice that we are loading in the \"typical\" captable and we are specifying an \"average\" operating temperature of 25 degC. The <code>create_library_set</code> command loads in the <code>.lib</code> file that we examined earlier. This file includes information about the input/output capacitance of each pin in each standard cell along with the delay from every input to every output in the standard cell. The <code>create_delay_corner</code> specifies a specific corner that we would like to use for our timing analysis by putting together a <code>.captable</code> and a <code>.lib</code> file. In this specific example, we are creating a typical corner by putting together the typical <code>.captable</code> and typical <code>.lib</code> we just loaded. The <code>create_constraint_mode</code> command loads in the post-synthesis <code>.sdc</code> file which captures all of the timing constraints after synthesis. The <code>create_analysis_view</code> command puts together constraints with a specific corner, and the <code>set_analysis_view</code> command tells Cadence Innovus that we would like to use this specific analysis view for both setup and hold time analysis.</p>"},{"location":"ece6745-tut07-asic-back-end/#22-initial-setup","title":"2.2. Initial Setup","text":"<p>Now that we have created our <code>setup-timing.tcl</code> file we can start Cadence Innovus:</p> <pre><code>% cd $TOPDIR/asic/04-cadence-innovus-pnr\n% innovus\n</code></pre> <p>As we enter commands we will be able use the GUI to see incremental progress towards a fully placed-and-routed design. We need to set various variables before starting to work in Cadence Innovus. These variables tell Cadence Innovus the location of the MMMC file, the location of the Verilog gate-level netlist, the name of the top-level module in our design, the location of the <code>.lef</code> files, and finally the names of the power and ground nets.</p> <pre><code>innovus&gt; set init_mmmc_file \"setup-timing.tcl\"\ninnovus&gt; set init_verilog   \"../02-synopsys-dc-synth/post-synth.v\"\ninnovus&gt; set init_top_cell  \"SortUnitStruct\"\ninnovus&gt; set init_lef_file  \"$env(ECE6745_STDCELLS)/rtk-tech.lef $env(ECE6745_STDCELLS)/stdcells.lef\"\ninnovus&gt; set init_gnd_net   \"VSS\"\ninnovus&gt; set init_pwr_net   \"VDD\"\n</code></pre> <p>We are now ready to use the <code>init_design</code> command to read in the verilog, set the design name, setup the timing analysis views, read the technology <code>.lef</code> for layer information, and read the standard cell <code>.lef</code> for physical information about each cell used in the design.</p> <pre><code>innovus&gt; init_design\n</code></pre> <p>We also need to tell Cadence Innovus the process node are using so it can roughly estimate specific technology parameters.</p> <pre><code>innovus&gt; setDesignMode -process 45\n</code></pre> <p>Cadence Innovus includes many advanced timing-driven optimizations by default. Two examples include signal integrity analysis (e.g., capacitive coupling across signal wires) and useful clock skew (e.g., purposefully introducing clock skew to give more time for critical paths at the expense of other paths). To simply our timing analysis we will turn these optimizations off as follows.</p> <pre><code>innovus&gt; setDelayCalMode -SIAware false\ninnovus&gt; setOptMode -usefulSkew false\n</code></pre> <p>Cadence Innovus can fix hold-time violations by inserting extra buffers to delay certain paths. We add an extra hold-time target slack so that Cadence Innovus will work extra hard to meet the hold-time, and we need to tell Cadence Innovus which standard cells to use when fixing hold-time violations as follows.</p> <pre><code>innovus&gt; setOptMode -holdTargetSlack 0.010\ninnovus&gt; setOptMode -holdFixingCells {\n  BUF_X1 BUF_X1 BUF_X2 BUF_X4 BUF_X8 BUF_X16 BUF_X32\n}\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#23-floorplanning","title":"2.3. Floorplanning","text":"<p>The next substep is floorplaning. This is where we broadly organize the chip in terms of its overall dimensions and the placement of any previously designed blocks. For now we just do some very simple floorplanning using the <code>floorPlan</code> command.</p> <pre><code>innovus&gt; floorPlan -r 1.0 0.70 4.0 4.0 4.0 4.0\n</code></pre> <p>In this example, we have chosen the aspect ratio to be 1.0 and a target cell utilization to be 70%. The cell utilization is the percentage of the final chip that will actually contain useful standard cells as opposed to just \"filler\" cells (i.e., empty cells). Ideally, we would like the cell utilization to be 100% but this is simply not reasonable. If the cell utilization is too high, Cadence Innovus will spend way too much time trying to optimize the design and will eventually simply give up. A target cell utilization of 70% makes it more likely that Cadence Innovus can successfuly place and route the design. We have also added 4.0um of margin around the top, bottom, left, and right of the chip to give us room for the power ring which will go around the entire chip.</p> <p>The following screen capture illustrates what you should see: a square floorplan with rows where the standard cells will eventually be placed. You can use the View &gt; Fit menu option to see the entire chip.</p> <p></p>"},{"location":"ece6745-tut07-asic-back-end/#24-placement","title":"2.4. Placement","text":"<p>The next substep is cell placement. We can do the placement and initial routing of the standard cells using the <code>place_opt_design</code> command:</p> <pre><code>innovus&gt; place_opt_design\n</code></pre> <p>The following screen capture illustrates what you should see: the gates have been placed underneath a sea of wiring on the various metal layers.</p> <p></p> <p>Note that Cadence Innovus has only done a very preliminary routing, primarily to help improve placement. You can use the Amobea workspace to help visualize how modules are mapped across the chip. Choose Windows &gt; Workspaces &gt; Amoeba from the menu. However, we recommend using the design browser to help visualize how modules are mapped across the chip. Here are the steps:</p> <ul> <li>Choose Windows &gt; Workspaces &gt; Design Browser + Physical from the menu</li> <li>Hide all of the metal layers by pressing the number keys</li> <li>Browse the design hierarchy using the panel on the left</li> <li>Right click on a module, click Highlight, select a color</li> </ul> <p>In this way you can view where various modules are located on the chip. The following screen capture illustrates the location of the five min/max units.</p> <p></p> <p>Notice how Cadence Innovus has grouped each module together. The placement algorithm tries to keep connected standard cells close together to minimize wiring.</p> <p>If our design has any constant values, then we need to insert special standard cells to \"tie\" those constant values to either VDD or ground using the <code>addTieHiLo</code> command.</p> <pre><code>innovus&gt; addTieHiLo -cell \"LOGIC1_X1 LOGIC0_X1\"\n</code></pre> <p>After placement and tie cell insertion, we can assign IO pin locations for our block-level design. Since this is not a full chip with IO pads, or a hierarchical block, we don't really care exactly where all of the pins line up, so we'll let the tool assign the location for all of the pins.</p> <pre><code>innovus&gt; assignIoPins -pin *\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#25-power-routing","title":"2.5. Power Routing","text":"<p>The next substep is power routing. Recall that each standard cell has internal M1 power and ground rails which will connect via abutment when the cells are placed into rows. If we were just to supply power to cells using these rails we would likely have large IR drop and the cells in the middle of the chip would effectively be operating at a much lower voltage. During power routing, we create a grid of power and ground wires on the top metal layers and then connect this grid down to the M1 power rails in each row. We also create a power ring around the entire floorplan. Before doing the power routing, we need to use the <code>globalNetCommand</code> command to tell Cadence Innovus which nets are power and which nets are ground (there are many possible names for power and ground!).</p> <pre><code>innovus&gt; globalNetConnect VDD -type pgpin -pin VDD -all -verbose\ninnovus&gt; globalNetConnect VSS -type pgpin -pin VSS -all -verbose\ninnovus&gt; globalNetConnect VDD -type tiehi -pin VDD -all -verbose\ninnovus&gt; globalNetConnect VSS -type tielo -pin VSS -all -verbose\n</code></pre> <p>We can now draw M1 \"rails\" for the power and ground rails that go along each row of standard cells.</p> <pre><code>innovus&gt; sroute -nets {VDD VSS}\n</code></pre> <p>We now create a power ring around our chip using the <code>addRing</code> command. A power ring ensures we can easily get power and ground to all standard cells. The command takes parameters specifying the width of each wire in the ring, the spacing between the two rings, and what metal layers to use for the ring. We will put the power ring on M7 and M8; we often put the power routing on the top metal layers since these are fundamentally global routes and these top layers have low resistance which helps us minimize static IR drop and di/dt noise. These top layers have high capacitance but this is not an issue since the power and ground rails are not switching (and indeed this extra capacitance can serve as a very modest amount of decoupling capacitance to smooth out time variations in the power supply).</p> <pre><code>innovus&gt; addRing \\\n  -nets {VDD VSS} -width 0.8 -spacing 0.8 \\\n  -layer [list top 9 bottom 9 left 8 right 8]\n</code></pre> <p>We have power and ground rails along each row of standard cells and a power ring, so now we need to hook these up. We can use the <code>addStripe</code> command to draw wires and automatically insert vias whenever wires cross. First, we draw the horizontal \"stripes\".</p> <pre><code>innovus&gt; addStripe \\\n  -nets {VSS VDD} -layer 9 -direction horizontal \\\n  -width 0.8 -spacing 4.8 \\\n  -set_to_set_distance 11.2 -start_offset 2.4\n</code></pre> <p>And then we draw the vertical \"stripes\".</p> <pre><code>innovus&gt; addStripe \\\n  -nets {VSS VDD} -layer 8 -direction vertical \\\n  -width 0.8 -spacing 4.8 \\\n  -set_to_set_distance 11.2 -start_offset 2.4\n</code></pre> <p>The following screen capture illustrates what you should see: a power ring and grid on M7 and M8 connected to the horizontal power and ground rails on M1.</p> <p></p> <p>You can toggle the visibility of metal layers by using the panel on the right. Click the checkbox in the V column to toggle the visibility of the corresponding layer. You can also simply use the number keys on your keyboard. Pressing the 7 key will toggle M7 and pressing the 8 key will toggle M8. Zoom in on a via and toggle the visibility of the metal layers to see how Cadence Innovus has automatically inserted a via stack that goes from M1 all the way up to M7 or M8.</p>"},{"location":"ece6745-tut07-asic-back-end/#26-clock-tree-synthesis","title":"2.6. Clock-Tree Synthesis","text":"<p>The next substep is clock-tree synthesis. First, let's display the preliminary clock tree created in the previous step so we can clearly see the impact of optimized clock tree routing. In the right panel click on Net and then deselect the checkbox in the V column next to Signal, Special Net, Power, and Ground so that only Clock is selected. You should be able to see the clock snaking around the chip connecting the clock port of all of the registers. Now use the <code>ccopt_design</code> command to optimize the clock tree routing.</p> <pre><code>innovus&gt; create_ccopt_clock_tree_spec\ninnovus&gt; set_ccopt_property update_io_latency false\ninnovus&gt; clock_opt_design\n</code></pre> <p>By default, Cadence Innovus can optimize the clock tree by adding a \"clock source insertion latency\". Essentially this means that Cadence Innovus might decide that the top-level chip should adjust the delay between the input pins and the clock. Unfortunately, this makes it more difficult for us to perform block-level back-annotated gate-level simulation so for now we will disable this optimization.</p> <p>If you watch closely you should see a significant difference in the clock tree routing before and after optimization. The following screen capture illustrates the optimized clock tree routing.</p> <p></p> <p>The routes are straighter, shorter, and well balanced. This will result in much lower clock skew.</p> <p>We should now use the <code>optDesign</code> command to try and fix both setup time violations (e.g., by choosing different standard cells to reduce the delay of the critical path) and hold time violations (e.g., by inserting buffers to increase the delay of certain fast paths).</p> <pre><code>innovus&gt; optDesign -postCTS -setup\ninnovus&gt; optDesign -postCTS -hold\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#27-routing","title":"2.7. Routing","text":"<p>The next substep is routing. Although we already did a preliminary routing during the placement substep, we now want to optimize this signal routing. Display just the signals but not the power and ground routing by clicking on the checkbox in the V column next to Signal in the left panel. Then use the <code>routeDesign</code> command to optimize the signal routing. We follow this with another iteration of <code>optDesign</code> to fix any violating paths that were created during <code>routeDesign</code>.</p> <pre><code>innovus&gt; routeDesign\n</code></pre> <p>If you watch closely you should see a significant difference in the signal routing before and after optimization. The following screen capture illustrates the optimized signal routing.</p> <p></p> <p>Again the routes are straighter and shorter. This will reduce the interconnect resistance and capacitance and thus improve the delay and energy of our design.</p> <p>Once again, we can now use the <code>optDesign</code> command to try and fix both setup time violations (e.g., by choosing different standard cells to reduce the delay of the critical path) and hold time violations (e.g., by inserting buffers to increase the delay of certain fast paths).</p> <pre><code>innovus&gt; optDesign -postRoute -setup\ninnovus&gt; optDesign -postRoute -hold\n</code></pre> <p>Now that our design is fully placed and routed, we can extract the parasitic resistance and capacitances to enable more accurate timing and power analysis.</p> <pre><code>innovus&gt; extractRC\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#28-finishing","title":"2.8. Finishing","text":"<p>One final step is to insert \"filler\" cells. Filler cells are essentially empty standard cells whose sole purpose is to connect the wells across each standard cell row.</p> <pre><code>innovus&gt; setFillerMode -core {FILLCELL_X4 FILLCELL_X2 FILLCELL_X1}\ninnovus&gt; addFiller\n</code></pre> <p>Zoom in to see some of the detailed routing and take a moment to appreciate how much effort the tools have done for us automatically to synthesize, place, and route this design. The following screen capture shows some of this detailed routing.</p> <p></p> <p>Notice how each metal layer always goes in the same direction. So M2 is always vertical, M3 is always horizontal, M4 is always vertical, etc. This helps reduce capacitive coupling across layers and also simplifies the routing algorithm. Actually, if you look closely in the above screen shot you can see situations on M2 (red) and M3 (green) where the router has generated a little \"jog\" meaning that on a single layer the wire goes both vertically and horizontally. This is an example of the sophisticated algorithms used in these tools.</p> <p>Another final step do is verify that the gate-level netlist matches what is really in the final layout. We can do this using the <code>verifyConnectivity</code> command. We can also do a preliminary \"design rule check\" to make sure that the generated metal interconnect does not violate any design rules with the <code>verify_drc</code> command.</p> <pre><code>innovus&gt; verifyConnectivity\ninnovus&gt; verify_drc\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#29-outputs-and-reports","title":"2.9. Outputs and Reports","text":"<p>Now we can generate various output files and reports. We start by saving the design so we can reload the design into Cadence Innovus for later analysis using the GUI.</p> <pre><code>innovus&gt; saveDesign post-pnr.enc\n</code></pre> <p>We also need to save the final gate-level netlist to enable back-annotated gate-level simulation, since Cadence Innovus will often insert new cells or change cells during its optimization passes.</p> <pre><code>innovus&gt; saveNetlist post-pnr.v\n</code></pre> <p>We can write parasitic information to a special <code>.spef</code> file. This file can be used for later power analysis.</p> <pre><code>innovus&gt; rcOut -rc_corner typical -spef post-pnr.spef\n</code></pre> <p>You may get an error regarding open nets. This is actually more of a warning message, and for the purposes of RC extraction we can ignore this.</p> <p>We also need to extract delay information and write this to an <code>.sdf</code> (Standard Delay Format) file, which we'll use for our back-annotated gate-level simulations.</p> <pre><code>innovus&gt; write_sdf post-pnr.sdf\n</code></pre> <p>Finally, we of course need to generate the real layout as a <code>.gds</code> file. This is what we will send to the foundry when we are ready to tapeout the chip.</p> <pre><code>innovus&gt; streamOut post-pnr.gds \\\n  -merge \"$env(ECE6745_STDCELLS)/stdcells.gds\" \\\n  -mapFile \"$env(ECE6745_STDCELLS)/rtk-stream-out.map\"\n</code></pre> <p>We can also use Cadence Innovus to do timing, area, and power analysis similar to what we did with Synopsys DC. These post-pnr results will be much more accurate than the preliminary post-synthesis results. Let's start with a basic setup timing report.</p> <pre><code>innovus&gt; report_timing -late -path_type full_clock -net\n...\nOther End Arrival Time          0.000\n- External Delay                0.050\n+ Phase Shift                   0.700\n= Required Time                 0.650\n- Arrival Time                  0.607\n= Slack Time                    0.043\n     Clock Rise Edge                      0.000\n     + Drive Adjustment                   0.008\n     = Beginpoint Arrival Time            0.008\n     +---------------------------------------------------------------------------------------------------------------------+\n     |               Pin               | Edge |             Net              |      Cell      | Delay | Arrival | Required |\n     |                                 |      |                              |                |       |  Time   |   Time   |\n     |---------------------------------+------+------------------------------+----------------+-------+---------+----------|\n     | clk[0]                          |  ^   | clk[0]                       |                |       |   0.008 |    0.052 |\n     | v/CTS_ccl_a_buf_00001/A         |  ^   | clk[0]                       | CLKBUF_X3      | 0.000 |   0.008 |    0.052 |\n     | v/CTS_ccl_a_buf_00001/Z         |  ^   | v/CTS_1                      | CLKBUF_X3      | 0.059 |   0.068 |    0.111 |\n     | v/elm2_S2S3/q_reg[1]/CK         |  ^   | v/CTS_1                      | DFF_X1         | 0.002 |   0.069 |    0.113 |\n     | v/elm2_S2S3/q_reg[1]/Q          |  ^   | v/elm2_S3[1]                 | DFF_X1         | 0.101 |   0.170 |    0.213 |\n     | v/mmuA_S3/FE_DBTC2_elm2_S3_1/A  |  ^   | v/elm2_S3[1]                 | INV_X1         | 0.000 |   0.170 |    0.213 |\n     | v/mmuA_S3/FE_DBTC2_elm2_S3_1/ZN |  v   | v/mmuA_S3/FE_DBTN2_elm2_S3_1 | INV_X1         | 0.014 |   0.184 |    0.227 |\n     | v/mmuA_S3/U62/B2                |  v   | v/mmuA_S3/FE_DBTN2_elm2_S3_1 | AOI21_X1       | 0.000 |   0.184 |    0.227 |\n     | v/mmuA_S3/U62/ZN                |  ^   | v/mmuA_S3/n22                | AOI21_X1       | 0.030 |   0.214 |    0.257 |\n     | v/mmuA_S3/U17/A1                |  ^   | v/mmuA_S3/n22                | NAND2_X1       | 0.000 |   0.214 |    0.257 |\n     | v/mmuA_S3/U17/ZN                |  v   | v/mmuA_S3/n13                | NAND2_X1       | 0.017 |   0.231 |    0.274 |\n     | v/mmuA_S3/U8/A2                 |  v   | v/mmuA_S3/n13                | NAND3_X1       | 0.000 |   0.231 |    0.274 |\n     | v/mmuA_S3/U8/ZN                 |  ^   | v/mmuA_S3/n5                 | NAND3_X1       | 0.019 |   0.250 |    0.293 |\n     | v/mmuA_S3/U6/A1                 |  ^   | v/mmuA_S3/n5                 | NAND3_X1       | 0.000 |   0.250 |    0.293 |\n     | v/mmuA_S3/U6/ZN                 |  v   | v/mmuA_S3/n4                 | NAND3_X1       | 0.017 |   0.267 |    0.310 |\n     | v/mmuA_S3/U3/A3                 |  v   | v/mmuA_S3/n4                 | AND3_X1        | 0.000 |   0.267 |    0.310 |\n     | v/mmuA_S3/U3/ZN                 |  v   | v/mmuA_S3/n23                | AND3_X1        | 0.035 |   0.302 |    0.345 |\n     | v/mmuA_S3/U2/A1                 |  v   | v/mmuA_S3/n23                | NOR2_X1        | 0.000 |   0.302 |    0.345 |\n     | v/mmuA_S3/U2/ZN                 |  ^   | v/mmuA_S3/n24                | NOR2_X1        | 0.025 |   0.326 |    0.370 |\n     | v/mmuA_S3/U36/A1                |  ^   | v/mmuA_S3/n24                | NOR3_X1        | 0.000 |   0.326 |    0.370 |\n     | v/mmuA_S3/U36/ZN                |  v   | v/mmuA_S3/n25                | NOR3_X1        | 0.011 |   0.337 |    0.381 |\n     | v/mmuA_S3/U32/A1                |  v   | v/mmuA_S3/n25                | OAI22_X1       | 0.000 |   0.337 |    0.381 |\n     | v/mmuA_S3/U32/ZN                |  ^   | v/mmuA_S3/n27                | OAI22_X1       | 0.037 |   0.374 |    0.418 |\n     | v/mmuA_S3/U13/A                 |  ^   | v/mmuA_S3/n27                | OAI21_X1       | 0.000 |   0.374 |    0.418 |\n     | v/mmuA_S3/U13/ZN                |  v   | v/mmuA_S3/n16                | OAI21_X1       | 0.023 |   0.397 |    0.441 |\n     | v/mmuA_S3/FE_OFC1_n16/A         |  v   | v/mmuA_S3/n16                | CLKBUF_X1      | 0.000 |   0.397 |    0.441 |\n     | v/mmuA_S3/FE_OFC1_n16/Z         |  v   | v/mmuA_S3/FE_OFN5_n16        | CLKBUF_X1      | 0.095 |   0.492 |    0.535 |\n     | v/mmuA_S3/U57/B1                |  v   | v/mmuA_S3/FE_OFN5_n16        | OAI22_X1       | 0.001 |   0.493 |    0.537 |\n     | v/mmuA_S3/U57/ZN                |  ^   | v/mmuA_out_max_S3[2]         | OAI22_X1       | 0.059 |   0.553 |    0.596 |\n     | v/U11/A1                        |  ^   | v/mmuA_out_max_S3[2]         | AND2_X1        | 0.000 |   0.553 |    0.596 |\n     | v/U11/ZN                        |  ^   | out2[2]                      | AND2_X1        | 0.054 |   0.606 |    0.650 |\n     | out2[2]                         |  ^   | out2[2]                      | SortUnitStruct | 0.000 |   0.607 |    0.650 |\n     +---------------------------------------------------------------------------------------------------------------------+\n</code></pre> <p>Note that for these results we used a target clock period of 700ps. From the above report we can see that our design is still meeting timing even after place-and-route. This critical path is from the last pipeline register to the <code>out2[2]</code> output pin. Recall the setup time for all output ports was set to be 50ps in our timing constraints. So this path must be less than 700ps - 50ps = 650ps to meet the setup time constraint. The actual arrive time is 607ps and includes 69ps from the input clock pin to the CK pin of the DFF, 101ps for the clock-to-q delay, 383ps to get through the min/max unit, and 54ps to go through a final AND gate before reaching the <code>out2[2]</code> output pin for a total delay of 607ps. The total delay (607ps) is less than the required time (650ps) by 43ps of positive slack.</p> <p>Note that it is very likely that the critical path identified by Synsopsys DC after synthesis will not be the same critical path identified by Cadence Innovus after place-and-route. This is because Synopsys DC can only guess the final placement of the cells and interconnect during static timing analysis, while Cadence Innovus can use the real placement of the cells and interconnect during static timing analysis. For the same reason, there is no guarantee that if your design meets timing after synthesis that it will still meet timing after place-and-route! It is very possible that your design will meet timing after synthesis and then will not meet timing after place-and-route. If your design does not meet timing after place-and-route you must go back and use a longer target clock period for synthesis!</p> <p>You can use the following steps in Cadence Innovus to display where the critical path is on the actual chip.</p> <ul> <li>Choose Timing &gt; Debug Timing from the menu</li> <li>Click OK in the pop-up window</li> <li>Right click on first path in the Path List</li> <li>Choose Highlight &gt; Only This Path &gt; Color</li> </ul> <p>You can also use the Design Browser to highlight specific modules to visualize how the critical path is routed across the chip between these modules. The following screen capture illustrates the critical path in our three-stage sort unit. From the above timing report we know the critical path basically goes through the <code>mmuA_S3</code> module, so we have highlighted that module in red using the Design Browser. Cadence Innovus has worked hard in both placement and routing to keep the critical path short. If your critical path stretches across the entire chip you may need to take extra steps such as explicit floorplanning or hierarchical design to help the tools produce a better quality of result.</p> <p></p> <p>In addition to checking to see if we met our setup time constraints, we also must check to see if we have met our hold time constraints.</p> <pre><code>innovus&gt; report_timing -early -path_type full_clock -net\nOther End Arrival Time          0.070\n+ Hold                          0.015\n+ Phase Shift                   0.000\n= Required Time                 0.085\n  Arrival Time                  0.085\n  Slack Time                    0.000\n     Clock Rise Edge                      0.000\n     + Input Delay                        0.000\n     + Drive Adjustment                   0.004\n     = Beginpoint Arrival Time            0.004\n     Timing Path:\n     +--------------------------------------------------------------------------------------------------------+\n     |             Pin              | Edge |            Net             |  Cell  | Delay | Arrival | Required |\n     |                              |      |                            |        |       |  Time   |   Time   |\n     |------------------------------+------+----------------------------+--------+-------+---------+----------|\n     | in3[6]                       |  ^   | in3[6]                     |        |       |   0.004 |    0.004 |\n     | FE_PHC106_in3_6/A            |  ^   | in3[6]                     | BUF_X1 | 0.000 |   0.004 |    0.004 |\n     | FE_PHC106_in3_6/Z            |  ^   | FE_PHN106_in3_6            | BUF_X1 | 0.020 |   0.024 |    0.024 |\n     | FE_PHC81_in3_6/A             |  ^   | FE_PHN106_in3_6            | BUF_X1 | 0.000 |   0.024 |    0.024 |\n     | FE_PHC81_in3_6/Z             |  ^   | FE_PHN81_in3_6             | BUF_X1 | 0.021 |   0.045 |    0.045 |\n     | FE_PHC46_in3_6/A             |  ^   | FE_PHN81_in3_6             | BUF_X1 | 0.000 |   0.045 |    0.045 |\n     | FE_PHC46_in3_6/Z             |  ^   | FE_PHN46_in3_6             | BUF_X1 | 0.020 |   0.065 |    0.065 |\n     | v/elm3_S0S1/FE_PHC28_in3_6/A |  ^   | FE_PHN46_in3_6             | BUF_X1 | 0.000 |   0.065 |    0.065 |\n     | v/elm3_S0S1/FE_PHC28_in3_6/Z |  ^   | v/elm3_S0S1/FE_PHN28_in3_6 | BUF_X1 | 0.020 |   0.085 |    0.085 |\n     | v/elm3_S0S1/q_reg[6]/D       |  ^   | v/elm3_S0S1/FE_PHN28_in3_6 | DFF_X1 | 0.000 |   0.085 |    0.085 |\n     +--------------------------------------------------------------------------------------------------------+\n     Clock Rise Edge                      0.000\n     + Drive Adjustment                   0.008\n     = Beginpoint Arrival Time            0.008\n     Other End Path:\n     +-----------------------------------------------------------------------------------+\n     |           Pin           | Edge |   Net   |   Cell    | Delay | Arrival | Required |\n     |                         |      |         |           |       |  Time   |   Time   |\n     |-------------------------+------+---------+-----------+-------+---------+----------|\n     | clk[0]                  |  ^   | clk[0]  |           |       |   0.008 |    0.009 |\n     | v/CTS_ccl_a_buf_00002/A |  ^   | clk[0]  | CLKBUF_X3 | 0.000 |   0.008 |    0.009 |\n     | v/CTS_ccl_a_buf_00002/Z |  ^   | v/CTS_2 | CLKBUF_X3 | 0.061 |   0.069 |    0.069 |\n     | v/elm3_S0S1/q_reg[6]/CK |  ^   | v/CTS_2 | DFF_X1    | 0.001 |   0.070 |    0.070 |\n     +-----------------------------------------------------------------------------------+\n</code></pre> <p>In our original design, there was basically no logic on the path from the input pin <code>in2[3]</code> and the <code>D</code> input of the DFF in the <code>elm2_S0S1</code> pipeline register. This makes this path a \"fast path\" which might cause a hold time violation. Indeed, in the above timing report, we can see that Cadence Innovus has inserted buffers (i.e., with the <code>FE_PHC</code> prefix) to delay the data to meet the hold time constraint. The timing report shows that the delay from the block's clock pin to the CK pin of the DFF (i.e., clock tree insertion delay) is 70ps and the contamination delay from the block's <code>in2[3]</code> pin to the D pin of the DFF is 85ps. Since 85ps - 75ps is 15ps which is greater than or equal to the hold time of 15ps this path now meets the hold time constraint.</p> <p>As in Synopsys DC, the <code>report_area</code> command can show the area each module uses and can enable detailed area breakdown analysis. These area results will be far more accurate than the post-synthesis results.</p> <pre><code>innovus&gt; report_area\n    Hinst Name   Module Name                         Inst Count Tot Area\n------------------------------------------------------------------------\nSortUnitStruct                                              520  841.890\n  v              tut3_verilog_sort_SortUnitStruct_p_nbits8  424  765.282\n    v/elm0_S0S1  vc_Reg_p_nbits8_0                           16   42.560\n    v/elm0_S1S2  vc_Reg_p_nbits8_8                            8   36.176\n    v/elm0_S2S3  vc_Reg_p_nbits8_4                            8   36.176\n    v/elm1_S0S1  vc_Reg_p_nbits8_11                          16   42.560\n    v/elm1_S1S2  vc_Reg_p_nbits8_7                            8   36.176\n    v/elm1_S2S3  vc_Reg_p_nbits8_3                            8   36.176\n    v/elm2_S0S1  vc_Reg_p_nbits8_10                          16   42.560\n    v/elm2_S1S2  vc_Reg_p_nbits8_6                            8   36.176\n    v/elm2_S2S3  vc_Reg_p_nbits8_2                            8   36.176\n    v/elm3_S0S1  vc_Reg_p_nbits8_9                           16   42.560\n    v/elm3_S1S2  vc_Reg_p_nbits8_5                            8   36.176\n    v/elm3_S2S3  vc_Reg_p_nbits8_1                            8   36.176\n    v/mmuA_S1    tut3_verilog_sort_MinMaxUnit_p_nbits8_0     48   48.678\n    v/mmuA_S2    tut3_verilog_sort_MinMaxUnit_p_nbits8_3     48   48.678\n    v/mmuA_S3    tut3_verilog_sort_MinMaxUnit_p_nbits8_1     57   53.466\n    v/mmuB_S1    tut3_verilog_sort_MinMaxUnit_p_nbits8_4     47   47.082\n    v/mmuB_S2    tut3_verilog_sort_MinMaxUnit_p_nbits8_2     49   49.742\n    v/val_S0S1   vc_ResetReg_p_nbits1_0                       6    8.246\n    v/val_S1S2   vc_ResetReg_p_nbits1_2                       3    5.852\n    v/val_S2S3   vc_ResetReg_p_nbits1_1                       3    5.852\n</code></pre> <p>The <code>Inst Count</code> column indicates the number of non-filler cells in that module. There are a total of 520 standard cells in the design. Each register should have eight standard cells; eight flip-flops since it is an eight-bit register. However, notice that some of the pipeline registers have 16 standard cells. You can look in the post-pnr gate-level netlist to see why. This is because these pipeline registers have inserted extra buffers to fix hold-time violations. The min/max units have a different number of cells since they have been optimized differently. The min/max units consume about ~47% of the area.</p> <p>Finally, we go ahead and exit Cadence Innovus.</p> <pre><code>innovus&gt; exit\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#210-final-layout","title":"2.10. Final Layout","text":"<p>We can now look at the actual <code>.gds</code> file for our design to see the final layout including all of the cells and the interconnect using the open-source Klayout GDS viewer. Choose Display &gt; Full Hierarchy from the menu to display the entire design. Zoom in and out to see the individual transistors as well as the entire chip.</p> <pre><code>% cd $TOPDIR/asic/build-sort/04-cadence-innovus-pnr\n% klayout -l ${ECE6745_STDCELLS}/klayout.lyp post-pnr.gds\n</code></pre> <p>The following screen capture illutrates using Klayout to view the layout for the entire sort unit.</p> <p></p> <p>The following figure shows a zoomed portion of the layout. You can clearly see the active layer inside the standard cells along with the signal routing on the lower metal layers. The power routing on the upper metal layers has been hiddent for clarity.</p> <p></p>"},{"location":"ece6745-tut07-asic-back-end/#211-automating-place-and-route","title":"2.11. Automating Place and Route","text":"<p>You can automate the above steps by putting a sequence of commands in a <code>.tcl</code> file and run Cadence Innovus using those commands in one step like this:</p> <pre><code>% cd $TOPDIR/asic/build-sort/04-cadence-innovus-pnr\n% innovus -no_gui -files run.tcl\n</code></pre> <p>To further simplify rerunning this step, we can put the above command line in its own a shell script. We have created such run scripts for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./04-cadence-innovus-pnr/run\n% cat ./04-cadence-innovus-pnr/run.tcl\n</code></pre> <p>You can rerun synthesis as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./04-cadence-innovus-pnr/run\n</code></pre> <p>And you can then open up the Cadence Innovus design in the GUI as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort/04-cadence-innovus-pnr\n% innovus\ninnovus&gt; source post-pnr.enc\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#3-using-synopsys-vcs-for-back-annotated-gate-level-simulation","title":"3. Using Synopsys VCS for Back-Annotated Gate-Level Simulation","text":"<p>In the previous tutorial, we used Synopsys VCS to do 4-state simulation and gate-level simulation. This time, we'll be using VCS to perform back-annotated gate-level simulation. The key difference between fast-functional and back-annotated gate-level simulation, is that we can now use an <code>.sdf</code> file to annotate delays in the gate-level simulation. In previous simulations, we only see signals change on the clock edge; however, with a back-annotated simulation, we'll know more precisely when signals are arriving by using the delay information provided by the <code>.sdf</code>. This means that running a back-annotated simulation with a cycle time that is too fast can potentially cause setup time violations or fast paths can potentially cause hold time violations. Back-annotated gate-level simulation is the primary way we will verify that our final design is functionally correct.</p> <p>We will be running Synopsys VCS in a separate directory to keep the files separate from the other tools.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sort/05-synopsys-vcs-baglsim\n% cd $TOPDIR/asic/build-sort/05-synopsys-vcs-baglsim\n</code></pre> <p>Given the more realistic timing implications of a back-annotated simulation, we need to be more careful about the cycle time, input delays, and output delays that we provide to Synopsys VCS. Notice the differences between the following command and the fast-functional gate-level simulation command from the previous tutorial.</p> <pre><code>% cd $TOPDIR/asic/build-sort/05-synopsys-vcs-baglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +neg_tchk +sdfverbose \\\n    -sdf max:Top.DUT:../04-cadence-innovus-pnr/post-pnr.sdf \\\n    +define+CYCLE_TIME=0.400 \\\n    +define+VTB_INPUT_DELAY=0.025 \\\n    +define+VTB_OUTPUT_DELAY=0.025 \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../04-cadence-innovus-pnr/post-pnr.v \\\n    ${TOPDIR}/sim/build/SortUnitStruct_random_tb.v\n% ./simv\n</code></pre> <p>This time, we add the flag <code>+neg_tchk</code>, which enables negative values in timing checks. Negative values in timing checks are important for cells which have negative hold times, for example. We also include the <code>+sdfverbose</code> flag which reads in the <code>post-pnr.sdf</code>. Note that we also assign non-zero values for <code>+define+VTB_INPUT_DELAY</code> and <code>+define+VTB_OUTPUT_DELAY</code>. These values are based on the input and output delay timing constraints during the Synopsys DC synthesis step. All inputs from the test bench will be set 25ps after the rising edge; recall that we used an input min delay of 0ps and max delay of 50ps so changing the inputs 25ps after the rising edge should meet hold and setup time constraints. All outputs will be checked 25ps before the next rising edge; recall that we used an output max delay of 50ps which corresponds to the setup time of the output pin so the output data should be stable by 25ps before the rising edge.</p> <p>The above command uses a cycle time of 400ps but recall that we used a cycle time constraint of 700ps. You should see a failing timing check and testbench failure similar to below.</p> <pre><code>\"/classes/ece6745/install/adks/freepdk-45nm/stdview/stdcells.v\", 2122:\n  Timing violation in Top.DUT.v.elm0_S1S2.\\q_reg[4]\n  $setuphold( posedge CK:2265, posedge D:2271, limits: (32,23) );\n\n...\n\nThe test bench received a value containing X/Z's! Please note\nthat the VTB is pessmistic about X's and you should make sure\nall output ports of your DUT does not produce X's after reset.\n- Timestamp      : 3 (default unit: ns)\n- Cycle number   : 5 (variable: cycle_count)\n- line number    : line 4 in SortUnitStruct_random_tb.v.cases\n- port name      : out[1] (out1 in Verilog)\n- expected value : 0x77\n- actual value   : 0xxX\n</code></pre> <p>The timing check is failing because the clock is rising at 2265ps and the data input is changing at 2271ps for the <code>elm0_S1S2.q_reg[4]</code> DFF; this means the data is changing 6ps after the rising edge but the hold time for this specific flip-flop is 23ps. If you open up the resulting waveforms and look at these signals at 2265ps you should be able to see this exact scenario.</p> <p>Let's rerun the simulation with our actual target cycle time of 700ps and verify back-annotated gate-level simulation passes the simulation.</p> <pre><code>% cd $TOPDIR/asic/build-sort/05-synopsys-vcs-baglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +neg_tchk +sdfverbose \\\n    -sdf max:Top.DUT:../04-cadence-innovus-pnr/post-pnr.sdf \\\n    +define+CYCLE_TIME=0.700 \\\n    +define+VTB_INPUT_DELAY=0.025 \\\n    +define+VTB_OUTPUT_DELAY=0.025 \\\n    +define+VTB_DUMP_SAIF=waves.saif \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../04-cadence-innovus-pnr/post-pnr.v \\\n    ${TOPDIR}/sim/build/SortUnitStruct_random_tb.v\n% ./simv\n</code></pre> <p>The <code>.vcd</code> file contains information about the state of every net in the design on every cycle. This can make these <code>.vcd</code> files very large and thus slow to analyze. For average power analysis, we only need to know the activity factor on each net, so we also dump out an <code>.saif</code> file that only contains a single average activity factor for every net.</p> <p>Take a look at the vcd file from this simulation. Here we can see some subcycle delays that shows us how long it takes for data to stabilize before the following cycle. This is showing the first stage of the sort unit pipeline. It shows the input and output of one of the stage 0 min/max units.</p> <p></p> <p>To simplify rerunning a simulation, we can put the above command lines in a shell script. We have created such a run script for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./05-synopsys-vcs-baglsim/run\n</code></pre> <p>You can rerun back-annotated gate-level simulation as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./05-synopsys-vcs-baglsim/run\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#4-synopsys-primetime-for-power-analysis","title":"4. Synopsys PrimeTime for Power Analysis","text":"<p>Synopsys PrimeTime (PT) is primarily used for very accurate \"sign-off\" static timing analysis (more accurate than the analysis performed by Synopsys DC and Cadence Innovus), but in this course, we will only use Synopsys PT for power analysis. There are many ways to perform power analysis. We can use Synopsys DC and Cadence Innovus for statistical power analysis where we simply assume some toggle probability on each net. For more accurate power analysis we need to find out the actual activity for every net for a given experiment, which is exactly what the <code>.saif</code> file from the previous section provides.</p> <p>We will be running Synopsys PT in a separate directory to keep the files separate from the other tools.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-sort/06-synopsys-pt-pwr\n% cd $TOPDIR/asic/build-sort/06-synopsys-pt-pwr\n% pt_shell\n</code></pre> <p>To make it easier to copy-and-paste commands from this document, we tell Synopsys PT to ignore the prefix <code>pt_shell&gt;</code> using the following:</p> <pre><code>pt_shell&gt; alias \"pt_shell&gt;\" \"\"\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#41-initial-setup","title":"4.1. Initial Setup","text":"<p>We begin by setting the <code>target_library</code> and <code>link_library</code> variables as before.</p> <pre><code>pt_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\npt_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>Since Synopsys PT is primarily used for static timing analysis, we need to explicitly tell Synopsys PT that we want to use it for power analysis.</p> <pre><code>pt_shell&gt; set_app_var power_enable_analysis true\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#42-inputs","title":"4.2. Inputs","text":"<p>We need to read in the gate-level netlist, tell Synopsys PT we want to do power analysis for the top-level module, and link the design (i.e., recursively resolve all of the module references starting from the top-level module).</p> <pre><code>pt_shell&gt; read_verilog ../04-cadence-innovus-pnr/post-pnr.v\npt_shell&gt; current_design SortUnitStruct\npt_shell&gt; link_design\n</code></pre> <p>We need to read in the actual activity factors which will be used for power analysis. The <code>.saif</code> file comes from a <code>.vcd</code> file which in turn came from running a simulation with a test harness. We need to strip off part of the instance names in the <code>.saif</code> file since the gate-level netlist does not have this test harness.</p> <pre><code>pt_shell&gt; read_saif ../05-synopsys-vcs-baglsim/waves.saif -strip_path Top/DUT\n</code></pre> <p>The <code>.db</code> file includes parasitic capacitance estimates for every pin of every standard cell, but to improve the accuracy of power analysis, we also need to include parasitic capacitances from the interconnect. Recall that we used Cadence Innovus to generate exactly this information in a <code>.spef</code> file. So we now read in these additional parasitic capacitance values for every net in the gate-level netlist.</p> <pre><code>pt_shell&gt; read_parasitics -format spef ../04-cadence-innovus-pnr/post-pnr.spef\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#43-timing-constraints","title":"4.3. Timing Constraints","text":"<p>In order to do power analysis, Synopsys PT needs to know the clock period. Here we will set the clock frequency to be the same as the initial clock constraint, but note that this is only valid if our design actually met timing. If our design has negative slack, then this means we cannot actually run the design at the target clock frequency and we will need to iterate to meet timing.</p> <pre><code>pt_shell&gt; create_clock clk -name ideal_clock1 -period 0.7\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#44-power-analysis","title":"4.4. Power Analysis","text":"<p>We now have everything we need to perform the power analysis: (1) the activity factor of a subset set of the nets, (2) the capacitance of every net/port, (3) the supply voltage, and (4) the clock frequency. We use the <code>update_power</code> command to propagate activity factors to unannotated nest and to estimate the power of our design.</p> <pre><code>pt_shell&gt; update_power\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#45-outputs","title":"4.5. Outputs","text":"<p>We can use the <code>report_power</code> command to show a high-level overview of how much power the sort unit consumes.</p> <pre><code>pt_shell&gt; report_power\n ...\n                Internal  Switching  Leakage    Total\n Power Group    Power     Power      Power      Power   (     %)  Attrs\n -----------------------------------------------------------------------\n clock_network  5.871e-04 2.163e-04 9.175e-08 8.035e-04 (29.22%)  i\n register       6.058e-04 1.292e-04 7.822e-06 7.428e-04 (27.01%)\n combinational  6.564e-04 5.365e-04 1.092e-05 1.204e-03 (43.77%)\n sequential        0.0000    0.0000    0.0000    0.0000 ( 0.00%)\n memory            0.0000    0.0000    0.0000    0.0000 ( 0.00%)\n io_pad            0.0000    0.0000    0.0000    0.0000 ( 0.00%)\n black_box         0.0000    0.0000    0.0000    0.0000 ( 0.00%)\n\n  Net Switching Power  = 8.819e-04   (32.07%)\n  Cell Internal Power  = 1.849e-03   (67.25%)\n  Cell Leakage Power   = 1.884e-05   ( 0.68%)\n                         ---------\nTotal Power            = 2.750e-03  (100.00%)\n</code></pre> <p>These numbers are in Watts. We can see that the sort unit consumes ~2.75mW of power when processing random input data. Power is the rate change of energy (i.e., energy divided by execution time), so the total energy is just the product of the total power, the number of cycles, and the cycle time. When we ran the sort unit simulator at the beginning of the tutorial, we saw that the simulation required 106 cycles. Assuming our sort unit runs as 0.7ns, this means the total energy is 2.5mW * 106 * 0.7ns = 185pJ. Since we are doing 100 sorts, this corresponds to about 1.8pJ per sort.</p> <p>The power is broken down into internal, switching, and leakage power. Internal and switching power are both forms of dynamic power, while leakage power is a form of static power. Notice that in this case, the dynamic power is much more significant than the static power. Internal power was described earlier in this tutorial, so you may want to revisit that section. Note that internal power includes short circuit power, but it can also include the local clock power internal to the cell. In this overview, the power is also broken down by the power consumed in the global clock network, registers, and combinational logic. Switching power is the power dissipated by the charging and discharging of the load capacitance at the output of each cell. Leakage power is the constant power due to subthreshold leakage. Sometimes we might want to factor out the static leakage power and focus more on the dynamic energy since including leakage power would mix energy and performance (i.e., using more cycles requires more leakage power even if we are not doing any more work during those cycles).</p> <p>Although the above breakdown is somewhat useful, it is even more useful to use the <code>report_power</code> command to show how much power each module consumes in the design.</p> <pre><code>pt_shell&gt; report_power -hierarchy\n ...\n                                      Int      Switch   Leak     Total\nHierarchy                             Power    Power    Power    Power    %\n----------------------------------------------------------------------------------\nSortUnitStruct                        1.85e-03 8.82e-04 1.88e-05 2.75e-03 100.0\n  v (SortUnitStruct_p_nbits8)         1.68e-03 8.12e-04 1.62e-05 2.51e-03  91.2\n    mmuA_S1 (MinMaxUnit_p_nbits8_0)   7.75e-05 8.51e-05 1.21e-06 1.64e-04   6.0\n    mmuA_S2 (MinMaxUnit_p_nbits8_3)   7.83e-05 9.41e-05 1.26e-06 1.74e-04   6.3\n    elm3_S2S3 (vc_Reg_p_nbits8_1)     9.39e-05 3.49e-06 6.31e-07 9.80e-05   3.6\n    elm2_S2S3 (vc_Reg_p_nbits8_2)     9.37e-05 1.25e-05 6.33e-07 1.07e-04   3.9\n    mmuA_S3 (MinMaxUnit_p_nbits8_1)   7.77e-05 8.44e-05 1.31e-06 1.63e-04   5.9\n    elm1_S2S3 (vc_Reg_p_nbits8_3)     9.71e-05 1.17e-05 6.31e-07 1.09e-04   4.0\n    elm3_S0S1 (vc_Reg_p_nbits8_9)     1.01e-04 1.63e-05 8.07e-07 1.18e-04   4.3\n    elm0_S2S3 (vc_Reg_p_nbits8_4)     9.42e-05 3.24e-06 6.30e-07 9.81e-05   3.6\n    elm2_S0S1 (vc_Reg_p_nbits8_10)    1.04e-04 1.57e-05 8.04e-07 1.20e-04   4.4\n    elm1_S0S1 (vc_Reg_p_nbits8_11)    1.01e-04 1.64e-05 8.04e-07 1.18e-04   4.3\n    val_S2S3 (vc_ResetReg_p_nbits1_1) 9.19e-06 7.25e-07 1.17e-07 1.00e-05   0.4\n    elm0_S0S1 (vc_Reg_p_nbits8_0)     1.01e-04 1.34e-05 8.04e-07 1.15e-04   4.2\n    val_S0S1 (vc_ResetReg_p_nbits1_0) 1.02e-05 3.57e-07 4.51e-07 1.10e-05   0.4\n    elm3_S1S2 (vc_Reg_p_nbits8_5)     9.34e-05 1.62e-05 6.32e-07 1.10e-04   4.0\n    elm2_S1S2 (vc_Reg_p_nbits8_6)     9.46e-05 1.25e-05 6.32e-07 1.08e-04   3.9\n    elm1_S1S2 (vc_Reg_p_nbits8_7)     9.67e-05 1.24e-05 6.31e-07 1.10e-04   4.0\n    mmuB_S1 (MinMaxUnit_p_nbits8_4)   7.48e-05 8.74e-05 1.19e-06 1.63e-04   5.9\n    mmuB_S2 (MinMaxUnit_p_nbits8_2)   7.12e-05 8.76e-05 1.27e-06 1.60e-04   5.8\n    elm0_S1S2 (vc_Reg_p_nbits8_8)     9.50e-05 1.19e-05 6.32e-07 1.08e-04   3.9\n    val_S1S2 (vc_ResetReg_p_nbits1_2) 9.18e-06 7.81e-08 1.17e-07 9.38e-06   0.3\n</code></pre> <p>From this breakdown, you can see that each min/max unit consumes about 6% of the total power and each register consumes about 4% of the total power. There are five min/max units so overall they consume about 30% of the total power and there are 12 registers so overall they consume 48% of the total power. So while each min/max unit consumes more energy than each register, there are more registers than min/max units such that overall more energy is consumed in the registers than the min/max units.</p> <p>Finally, we go ahead and exit Synopsys PT.</p>"},{"location":"ece6745-tut07-asic-back-end/#46-automating-power-analysis","title":"4.6. Automating Power Analysis","text":"<pre><code>pt_shell&gt; exit\n</code></pre> <p>You can automate the above steps by putting a sequence of commands in a <code>.tcl</code> file and run Synopsys PT using those commands in one step like this:</p> <pre><code>% cd $TOPDIR/asic/build-sort/06-synopsys-pt-pwr\n% pt_shell -f run.tcl\n</code></pre> <p>To further simplify rerunning this step, we can put the above command line in its own shell script. We have created such run scripts for you. Let's take a look to confirm these scripts match the manual commands we used above.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% cat ./06-synopsys-pt-pwr/run\n% cat ./06-synopsys-pt-pwr/run.tcl\n</code></pre> <p>You can rerun power analysis as follows.</p> <pre><code>% cd $TOPDIR/asic/build-sort\n% ./06-synopsys-pt-pwr/run\n</code></pre>"},{"location":"ece6745-tut07-asic-back-end/#5-to-do-on-your-own","title":"5. To-Do On Your Own","text":"<p>Now we can use what you have learned so far to push the GCD unit through the ASIC front-end and back-end flow. First, run a simulation of the GCD unit.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut3_verilog/gcd/gcd-sim --short-mname --impl rtl --input random --stats \\\n                              --translate --dump-vtb\n% less GcdUnit__pickled.v\n</code></pre> <p>Now create a new ASIC build directory and copy the scripts we used to push the sort unit through the ASIC front-end flow.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-gcd/01-synopsys-vcs-rtlsim\n% mkdir -p $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% mkdir -p $TOPDIR/asic/build-gcd/03-synopsys-vcs-ffglsim\n% mkdir -p $TOPDIR/asic/build-gcd/04-cadence-innovus-pnr\n% mkdir -p $TOPDIR/asic/build-gcd/05-synopsys-vcs-baglsim\n% mkdir -p $TOPDIR/asic/build-gcd/06-synopsys-pt-pwr\n\n% cp $TOPDIR/asic/build-sort/01-synopsys-vcs-rtlsim/run              $TOPDIR/asic/build-gcd/01-synopsys-vcs-rtlsim\n% cp $TOPDIR/asic/build-sort/02-synopsys-dc-synth/run.tcl            $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% cp $TOPDIR/asic/build-sort/02-synopsys-dc-synth/run                $TOPDIR/asic/build-gcd/02-synopsys-dc-synth\n% cp $TOPDIR/asic/build-sort/03-synopsys-vcs-ffglsim/run             $TOPDIR/asic/build-gcd/03-synopsys-vcs-ffglsim\n% cp $TOPDIR/asic/build-sort/04-cadence-innovus-pnr/setup-timing.tcl $TOPDIR/asic/build-gcd/04-cadence-innovus-pnr/setup-timing.tcl\n% cp $TOPDIR/asic/build-sort/04-cadence-innovus-pnr/run              $TOPDIR/asic/build-gcd/04-cadence-innovus-pnr/run\n% cp $TOPDIR/asic/build-sort/04-cadence-innovus-pnr/run.tcl          $TOPDIR/asic/build-gcd/04-cadence-innovus-pnr/run.tcl\n% cp $TOPDIR/asic/build-sort/05-synopsys-vcs-baglsim/run             $TOPDIR/asic/build-gcd/05-synopsys-vcs-baglsim/run\n% cp $TOPDIR/asic/build-sort/06-synopsys-pt-pwr/run                  $TOPDIR/asic/build-gcd/06-synopsys-pt-pwr/run\n% cp $TOPDIR/asic/build-sort/06-synopsys-pt-pwr/run.tcl              $TOPDIR/asic/build-gcd/06-synopsys-pt-pwr/run.tcl\n</code></pre> <p>Now open up each of these files and modify so they push the GCD unit instead of the sort unit through the flow. You will need to update the name of the Verilog source files and the top module name as follows:</p> <ul> <li>Verilog source file name: <code>GcdUnit__pickled.v</code></li> <li>Verilog test source file name: <code>GcdUnit_random_tb.v</code></li> <li>Top module name for synthesis: <code>GcdUnit</code></li> </ul> <p>Basically, you just need to change <code>SortUnitStruct</code> to <code>GcdUnit</code> in all of the run scripts. You can use <code>sed</code> to do this:</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% find . -type f -exec sed -i.bak 's/SortUnitStruct/GcdUnit/' {} \\;\n</code></pre> <p>Keep the cycle time constraint as 700ps and the other constraints as before. Once you have updated the scripts you can then push the GCD unit through the flow like this:</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n</code></pre> <p>Carefully look at the post-synthesis and post-pnr timing reports to ensure your design meetings timing.</p> <pre><code>% cd $TOPDIR/asic/build-gcd\n% cat 02-synopsys-dc-synth/timing.rpt\n% cat 04-cadence-innovus-pnr/timing-setup.rpt\n% cat 04-cadence-innovus-pnr/timing-hold.rpt\n</code></pre> <p>If your design does not meet timing post-pnr, increase the cycle time constraint and try again until it does meet timing. If your design does not meet timing post-synthesis but does meet timing post-pnr this is means your overall design does meet timing. It just means the timing analysis used by Synopsys DC was overly conservative and/or Cadence Innovus was able to further optimize your design to meet timing. Carefully look and the results from running the four-state RTL simulation, fast-functional gate-level simulation, and back-annotated gate-level simulation to verify that the design is passing the simulations. Spend time looking at the post-synthesis gate-level netlist in <code>post-pnr.v</code> and load the design into Cadence Innovus to examine the placement. Convince yourself that the GCD unit was successfully pushed through the entire ASIC flow.</p>"},{"location":"ece6745-tut08-asic-auto/","title":"ECE 6745 Tutorial 8: ASIC Automated Flow","text":"<p>The previous tutorials demonstrated how to take a design from RTL to layout by both manually entering commands for each tool and also writing flow scripts. Flow scripts can help automate the process but copying and modifying these flow scripts for every design is tedious and error prone. An agile hardware design flow demands automation to simplify rapidly exploring the area, energy, timing design space of one or more designs. In this tutorial we will introduce a simple tool called pyhflow which takes as input a step templates and a design YAML and generates appropriate flow scripts. This tutorial assumes you have already completed the tutorials on Linux, Git, and Verilog.</p> <p>The following diagram illustrates the five primary tools we will be using in ECE 6745 along with a few smaller secondary tools. Notice that the ASIC tools all require various views from the standard-cell library. Before starting this tutorial, you must complete the ASIC standard-cell tutorial, the ASIC front-end flow tutorial, and the ASIC back-end flow tutorial.</p> <p></p> <ol> <li> <p>We write our RTL models in Verilog, and we use the PyMTL framework to     test, verify, and evaluate the execution time (in cycles) of our     design. This part of the flow is very similar to the flow used in     ECE 4750. Once we are sure our design is working correctly, we can     then start to push the design through the flow.</p> </li> <li> <p>We use Synopsys VCS to compile and run both 4-state RTL and     gate-level simulations. These simulations help us to build confidence     in our design as we push our designs through different stages of the     flow. From these simulations, we also generate waveforms in <code>.vcd</code>     (Verilog Change Dump) format, and per-net average activity factors     stored in <code>.saif</code> format. These activity factors will be used for     power analysis. Gate-level simulation is an valuable tool for     ensuring the tools did not optimize something away which impacts the     correctness of the design, and also provides an avenue for obtaining     a more accurate power analysis than RTL simulation. While static     timing analysis (STA) analyzes all paths, GL simulation can also     serve as a backup to check for hold and setup time violations (chip     designers must be paranoid!)</p> </li> <li> <p>We use Synopsys Design Compiler (DC) to synthesize our design,     which means to transform the Verilog RTL model into a Verilog     gate-level netlist where all of the gates are selected from the     standard-cell library. We need to provide Synopsys DC with abstract     logical and timing views of the standard-cell library in <code>.db</code>     format. In addition to the Verilog gate-level netlist, Synopsys DC     can also generate a <code>.ddc</code> file which contains information about the     gate-level netlist and timing, and this <code>.ddc</code> file can be inspected     using Synopsys Design Vision (DV). We will also use Synopsys DC to     generate a <code>.sdc</code> which captures timing constraints which can then be     used as input to the place-and-route tool.</p> </li> <li> <p>We use Cadence Innovus to place-and-route our design, which means     to place all of the gates in the gate-level netlist into rows on the     chip and then to generate the metal wires that connect all of the     gates together. We need to provide Cadence Innovus with the same     abstract logical and timing views used in Synopsys DC, but we also     need to provide Cadence Innovus with technology information in     <code>.lef</code>, and <code>.captable</code> format and abstract physical views of the     standard-cell library also in <code>.lef</code> format. Cadence Innovus will     generate an updated Verilog gate-level netlist, a <code>.spef</code> file which     contains parasitic resistance/capacitance information about all nets     in the design, and a <code>.gds</code> file which contains the final layout. The     <code>.gds</code> file can be inspected using the open-source Klayout GDS     viewer. Cadence Innovus also generates reports which can be used to     accurately characterize area and timing.</p> </li> <li> <p>We use Synopsys PrimeTime (PT) to perform power analysis of our     design. We need to provide Synopsys PT with the same abstract     logical, timing, and power views used in Synopsys DC and Cadence     Innovus, but in addition we need to provide switching activity     information for every net in the design (which comes from the <code>.saif</code>     file), and capacitance information for every net in the design (which     comes from the <code>.spef</code> file). Synopsys PT puts the switching     activity, capacitance, clock frequency, and voltage together to     estimate the power consumption of every net and thus every module in     the design, and these estimates are captured in various reports.</p> </li> </ol> <p>Extensive documentation is provided by Synopsys and Cadence for these ASIC tools. We have organized this documentation and made it available to you on the public course webpage:</p> <ul> <li>https://www.csl.cornell.edu/courses/ece6745/asicdocs</li> </ul> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into the same specific <code>ecelinux</code> server and then use Microsoft Remote Desktop to log into the same server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut08-asic-auto tut08\n% cd tut08\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut08-asic-auto/#1-testing-simulation-and-translation","title":"1. Testing, Simulation, and Translation","text":"<p>As in the previous tutorial, our goal is to characterize the area, energy, and timing for the sort unit from the Verilog tutorial using the ASIC tools. As a reminder, the sort unit takes as input four integers and a valid bit and outputs those same four integers in increasing order with the valid bit. The sort unit is implemented using a three-stage pipelined, bitonic sorting network and the datapath is shown below.</p> <p></p> <p>Before using the ASIC tools we need to verify that our design passes all of our tests and use an interactive simulator to drive our design-space exploration.</p>"},{"location":"ece6745-tut08-asic-auto/#11-testing-the-sort-unit","title":"1.1. Testing the Sort Unit","text":"<p>As always, we can use our Python-based testing framework combined with the Verilator two-state RTL simulator to verify our design's functionality. We need to use the <code>--test-verilog</code> and <code>--dump-vtb</code> command line options to generate Verilog test benches which can then be used for four-state RTL simulation, fast-functional gate-level simulation, and back-annotated gate-level simulation.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort --test-verilog --dump-vtb\n</code></pre> <p>Verify the test benches have been generated.</p> <pre><code>% cd $TOPDIR/sim/build\n% ls SortUnitStruct*tb.v\n</code></pre>"},{"location":"ece6745-tut08-asic-auto/#12-evaluating-the-sort-unit","title":"1.2. Evaluating the Sort Unit","text":"<p>We can use the provided interactive simulator to run two experiments each with a different dataset.</p> <pre><code>% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input random --stats --translate --dump-vtb\n% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input zeros  --stats --translate --dump-vtb\n</code></pre> <p>Verify the Verilog RTL and test benches have been generated.</p> <pre><code>% cd $TOPDIR/sim/build\n% ls SortUnitStruct__p_nbits_8__pickled.v\n% ls SortUnitStruct__p_nbits_8_sort-sim-rtl-struct-random_tb.v\n% SortUnitStruct__p_nbits_8_sort-sim-rtl-struct-zeros_tb.v\n</code></pre>"},{"location":"ece6745-tut08-asic-auto/#2-pyhflow-for-generating-flows","title":"2. pyhflow For Generating Flows","text":"<p>pyflow is based on the idea of step templates which are located in the <code>asic/steps</code> directory.</p> <pre><code>% cd $TOPDIR/asic/steps\n% tree\n.\n\u251c\u2500\u2500 01-synopsys-vcs-rtlsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 02-synopsys-dc-synth\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u2514\u2500\u2500 run.tcl\n\u251c\u2500\u2500 03-synopsys-vcs-ffglsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 04-cadence-innovus-pnr\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u251c\u2500\u2500 run.tcl\n\u2502   \u2514\u2500\u2500 setup-timing.tcl\n\u251c\u2500\u2500 05-synopsys-vcs-baglsim\n\u2502   \u2514\u2500\u2500 run\n\u251c\u2500\u2500 06-synopsys-pt-pwr\n\u2502   \u251c\u2500\u2500 run\n\u2502   \u2514\u2500\u2500 run.tcl\n\u2514\u2500\u2500 07-summarize-results\n    \u251c\u2500\u2500 run\n    \u2514\u2500\u2500 summarize-results\n</code></pre> <p>Each step is a directory with a run script and possibly other scripts. The key difference from the scripts we used in the previous tutorials, is that these scripts are templated using the Jinja2 templating system:</p> <ul> <li>https://jinja.palletsprojects.com</li> </ul> <p>So for example, the Synopsys DC run.tcl script is templated based on the design name and the target clock period as follows</p> <pre><code>analyze -format sverilog $env(TOPDIR)/sim/build/{{design_name}}__pickled.v\nelaborate {{design_name}}\n\ncreate_clock clk -name ideal_clock1 -period {{clock_period}}\n</code></pre> <p>The <code>{{ }}</code> directive is the standard syntax for template variable substitution using Jinja2. As another example, the RTL, FFGL, and BAGL simulation scripts are all templated by the list of tests and evaluations.</p> <pre><code>{% for item in tests_and_evals -%}\nrun_sim {{item}}\n{% endfor %}\n</code></pre> <p>The <code>{% %}</code> directive is the standard syntax for more complex templating using Jinja2.</p> <p>The pyhflow program takes as input a design YAML file which specifies:</p> <ul> <li>what steps make up the flow</li> <li>key/value pairs for variables to substitute into scripts</li> <li>list of tests</li> <li>list of evals</li> </ul> <p>Take a look at the provided design YAML file for the sort unit.</p> <pre><code>% cd $TOPDIR/asic/designs\n% cat tut08-sort.yml\n\nsteps:\n - 01-synopsys-vcs-rtlsim\n - 02-synopsys-dc-synth\n - 03-synopsys-vcs-ffglsim\n - 04-cadence-innovus-pnr\n - 05-synopsys-vcs-baglsim\n - 06-synopsys-pt-pwr\n - 07-summarize-results\n\nsrc_dir      : ../../../sim/build\ndesign_name  : SortUnitStruct__p_nbits_8\nclock_period : 0.7\ndump_vcd     : true\n\ntests:\n - SortUnitStruct__p_nbits_8_test_basic\n - SortUnitStruct__p_nbits_8_test_stream\n - SortUnitStruct__p_nbits_8_test_dups\n - SortUnitStruct__p_nbits_8_test_sorted\n - SortUnitStruct__p_nbits_8_test_random_8\n\nevals:\n - SortUnitStruct__p_nbits_8_sort-sim-rtl-struct-random\n</code></pre> <p>This design YAML file specifies the generated flow should use all seven steps. Currently the only parameters are the source directory, design name, and the clock period. We run RTL sim, FFGL sim, and BAGL sim on all tests and evals, but we only do energy analysis on the evals. The evals usually come from running an interactive simulator like <code>sort-sim</code>. All pyhflow does is use the YAML file to figure out what to substitute into the templated steps and then copy the run scripts into the current working directory. You can also override parameters on pyhflow command line.</p>"},{"location":"ece6745-tut08-asic-auto/#21-running-asic-flow-with-one-test","title":"2.1. Running ASIC Flow with One Test","text":"<p>Let's go ahead and use pyhflow to generate the flow scripts for the sort unit.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut08-sort\n% cd $TOPDIR/asic/build-tut08-sort\n% pyhflow --one-test ../designs/tut08-sort.yml\n</code></pre> <p>The <code>--one-test</code> command line option tells pyhflow to only include the first test and no evals in the flow scripts. This is a useful way to get started with a single test and reduces the overall runtime of the flow. Once we know that everything works with one test we can circle back and regenerate the flow scripts with all of the tests and evals.</p> <p>Let's see how the step template has been filled in for the Verilog RTL simulation step.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% cat 01-synopsys-vcs-rtlsim/run\n...\nrun_sim SortUnitStruct__p_nbits_8_test_basic\n</code></pre> <p>Notice how the name of the first test has been filled in. Let's also see how the step template has been filled in for the Synopsys DC synthesis step.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% cat 02-synopsys-dc-synth/run.tcl\n...\nanalyze -format sverilog $env(TOPDIR)/sim/build/SortUnitStruct__p_nbits_8__pickled.v\nelaborate SortUnitStruct__p_nbits_8\ncreate_clock clk -name ideal_clock1 -period 0.7\n</code></pre> <p>Notice how the name of the source Verilog RTL File, the top-level modulename, and the clock period have all been filled in.</p> <p>After generating a flow, we always recommend explicitly running at least the first two steps to ensure there are no errors. You can run the four-state RTL simulation as follows.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% ./01-synopsys-vcs-rtlsim/run\n</code></pre> <p>Make sure the step can find the source files and passes the test. Then run synthesis as follows.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% ./02-synopsys-dc-synth/run\n</code></pre> <p>Carefully look at the output from the synthesis step (also stored in the <code>run.log</code> file). Look for the output after <code>Running PRESTO HDLC</code> for any warnings to ensure that all of your Verilog RTL is indeed synthesizable. Scan through the rest of the logs to ensure there are no worrying warnings or errors.</p> <p>Once you have explicitly run the first two steps to ensure there are no errors, you can run the remaning steps.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% 03-synopsys-vcs-ffglsim\n% 04-cadence-innovus-pnr\n% 05-synopsys-vcs-baglsim\n% 06-synopsys-pt-pwr\n% 07-summarize-results\n</code></pre>"},{"location":"ece6745-tut08-asic-auto/#22-running-asic-flow-with-all-tests-and-evals","title":"2.2. Running ASIC Flow with All Tests and Evals","text":"<p>If all looks good, then you can regenerate the with all of the tests and evals. pyhflow will also create a <code>run-flow</code> script which will run all of the steps in sequence for you, but only use this if you are confident there are no errors!</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% pyhflow ../designs/tut08-sort.yml\n% ./run-flow\n\n timestamp          = 2025-02-19 22:14:30\n design_name        = SortUnitStruct__p_nbits_8\n clock_period       = 0.7\n rtlsim             = 7/7 passed\n synth_setup_slack  = 0.0089 ns\n synth_num_stdcells = 461\n synth_area         = 785.498 um^2\n ffglsim            = 7/7 passed\n pnr_setup_slack    = 0.0683 ns\n pnr_hold_slack     = 0.0102 ns\n pnr_num_stdcells   = 609\n pnr_area           = 930.202 um^2\n baglsim            = 7/7 passed\n\n SortUnitStruct__p_nbits_8_sort-sim-rtl-struct-random\n  - exec_time = 106 cycles\n  - exec_time = 74.5750 ns\n  - power     = 2.9100 mW\n  - energy    = 0.2170 nJ\n</code></pre> <p>The final step summarizes the results and includes the following information.</p> <ul> <li>Timestamp</li> <li>Design name</li> <li>Clock period in ns</li> <li>Four-state RTL simulation results</li> <li>Synthesis setup slack in ns</li> <li>Synthesis num stdcells</li> <li>Synthesis area in um^2</li> <li>Fast-functional gate-level simulation results</li> <li>Place-and-route setup slack in ns</li> <li>Place-and-route hold slack in ns</li> <li>Place-and-route num stdcells</li> <li>Place-and-route area in um^2</li> <li>Back-annotated gate-level simulation results</li> <li>For each evaluation<ul> <li>Execution time in cycles</li> <li>Execution time in ns</li> <li>Power in mW</li> <li>Energy in nJ</li> </ul> </li> </ul> <p>For the results to be valid, the following must be true:</p> <ul> <li>all four-state RTL simulations pass</li> <li>all fast-functional gate-level simulations pass</li> <li>all back-annotated gate-level simulations pass</li> <li>place-and-route setup slack is positive</li> <li>place-and-route hold slack is positive</li> </ul> <p>If your design does not meet timing after synthesis but does meet timing after place-and-route then these are still valid results. It just means Synopsys DC was conservative and/or Cadence Innovus did a good job further optimizing the design.</p>"},{"location":"ece6745-tut08-asic-auto/#23-debugging-issues","title":"2.3. Debugging Issues","text":"<p>Every step logs its output to a <code>run.log</code> file. The four-state RTL simulation, fast-functional gate-level simulation, and back-annotated gate-level simulation save the output of each simulation in a separate log file and also save a VCD file.</p> <p>If you pass two-state RTL simulation but fail four-state RTL simulation then the likely cause is either Verilog syntax that Synopsys VCS does not like (e.g., using signals before they are declared), mishandling register initialization, not handling inputs which are X correctly, and/or not forcing the outputs to always be known values (i.e., you cannot produces Xs on the outputs of your block after reset). Use Surfer and start from the observable error and work backwards through your design in both space and time. If you are seeing Xs in the output work backwards to try and figure out where these Xs are coming from.</p> <p>If you pass two-state RTL simulation and four-state RTL simulation but fail fast-functional gate-level simulation then the likely cause is some kind of synthesis issue such as inferred latches, parts of your design are being optimized away incorrectly, or the Synopsys DC TCL script has an issue. While you can look at waveforms for gate-level simulation it is not fun; it might be best to carefully look through the <code>run.log</code> file for the synthesis step first.</p> <p>If you pass two-state RTL simulation, four-state RTL simulation, fast-functional gate-level simulation, and your design has positive setup and hold slack after place-and-route then the likely cause is the Cadence Innovus TCL script has an issue. While you can look at waveforms for gate-level simulation it is not fun; it might be best to carefully look through the <code>run.log</code> file for the place-and-route step first.</p>"},{"location":"ece6745-tut08-asic-auto/#24-interactive-debugging","title":"2.4. Interactive Debugging","text":"<p>You can use Synopsys DV to look at the synthesis results as follows.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% design_vision-xg\ndesign_vision&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db\"\ndesign_vision&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db\"\n</code></pre> <p>You can use the following steps to open the <code>.ddc</code> file generated during synthesis.</p> <ul> <li>Choose File &gt; Read from the menu</li> <li>Open the <code>02-synopsys-dc-synth/post-synth.dcc</code> file</li> </ul> <p>However, we don't usually find using Synopsys DV to be that helpful.</p> <p>It is far more helpful to use Cadence Innovus to debug your physical design including highlighting modules and paths to see where they are located in the block. You can reload the design into Cadence Innovus as follows.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% innovus\ninnovus&gt; source 04-cadence-innovus-pnr/post-pnr.enc\n</code></pre> <p>You can use the Amobea workspace to help visualize how modules are mapped across the chip. Choose Windows &gt; Workspaces &gt; Amoeba from the menu. However, we recommend using the design browser to help visualize how modules are mapped across the chip. Here are the steps:</p> <ul> <li>Choose Windows &gt; Workspaces &gt; Design Browser + Physical from the menu</li> <li>Hide all of the metal layers by pressing the number keys</li> <li>Browse the design hierarchy using the panel on the left</li> <li>Right click on a module, click Highlight, select a color</li> </ul> <p>You can use the following steps in Cadence Innovus to display where the critical path is on the actual chip.</p> <ul> <li>Choose Timing &gt; Debug Timing from the menu</li> <li>Click OK in the pop-up window</li> <li>Right click on first path in the Path List</li> <li>Choose Highlight &gt; Only This Path &gt; Color</li> </ul> <p>Finally, you can use Klayout to capture a screen shot demonstrating that you have successfully taken a design from RTL to layout.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% klayout -l $ECE6745_STDCELLS/klayout.lyp 04-cadence-innovus-pnr/post-pnr.gds\n</code></pre>"},{"location":"ece6745-tut08-asic-auto/#25-key-reports","title":"2.5. Key Reports","text":"<p>Here is a list of key reports.</p> <ul> <li>02-synopsys-dc-synth/timing.rpt</li> <li>02-synopsys-dc-synth/area.rpt</li> <li>02-synopsys-dc-synth/resources.rpt</li> <li>04-cadence-innovus-pnr/timing-setup.rpt</li> <li>04-cadence-innovus-pnr/timing-hold.rpt</li> <li>04-cadence-innovus-pnr/area.rpt</li> <li>06-synopsys-pt-pwr/*-summary.rpt</li> <li>06-synopsys-pt-pwr/*-detailed.rpt</li> </ul> <p>You can use the synthesis resources report to determine if Synospys DC has used DesignWare components to optimize parts of your design. You can learn more about all of the DesignWare components here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_datasheets</li> </ul> <p>You can use the place-and-route timing setup report to determine the critical path in your design and the delay of every component along this critical path. You can use the place-and-route area reprot to determine the area of every module in your design. You can use the detailed power reports to determine the power consumption of every module in your design.</p>"},{"location":"ece6745-tut08-asic-auto/#3-to-do-on-your-own","title":"3. To Do On Your Own","text":"<p>Now we can use what you have learned so far to push the GCD unit through the ASIC automted flow. First, run all of the tests for theGCD unit.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/gcd/test --test-verilog --dump-vtb\n</code></pre> <p>Then run three interactive simulations for our evaluation.</p> <pre><code>% ../tut3_verilog/gcd/gcd-sim --impl rtl --input random --stats --translate --dump-vtb\n% ../tut3_verilog/gcd/gcd-sim --impl rtl --input small  --stats --translate --dump-vtb\n% ../tut3_verilog/gcd/gcd-sim --impl rtl --input zeros  --stats --translate --dump-vtb\n</code></pre> <p>Then you can use pyhflow to push the GCD unit through the flow.</p> <pre><code>% mkdir -p ${TOPDIR}/asic/build-tut08-gcd\n% cd ${TOPDIR}/asic/build-tut08-gcd\n% pyhflow ../designs/tut08-gcd.yml\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>Or use the <code>run-flow</code> script to run the entire flow with a single command.</p> <pre><code>% mkdir -p ${TOPDIR}/asic/build-tut08-gcd\n% cd ${TOPDIR}/asic/build-tut08-gcd\n% pyhflow ../designs/tut08-gcd.yml\n% ./run-flow\n</code></pre> <p>Compare the energy of the three evaluations. Look at the following reports to understand the critical path and area breakdown.</p> <pre><code>% cd ${TOPDIR}/asic/build-tut08-gcd\n% cat 04-cadence-innovus-pnr/timing-setup.rpt\n% cat 04-cadence-innovus-pnr/area.rpt\n</code></pre> <p>Use the Cadence Innovus GUI to highlight the datapath vs control modules. Use klayout to look at the final layout. Then try to push the clock period lower to see if the block can operate at a higher clock frequency while still meeting timing and passing all of the tests.</p>"},{"location":"ece6745-tut09-xcel-rtl/","title":"ECE 6745 Tutorial 9: TinyRV2 Accelerator RTL Design","text":"<p>The infrastructure for the ECE 6745 lab assignments and projects has support for implementing medium-grain accelerators. Fine-grain accelerators are tightly integrated within the processor pipeline (e.g., a specialized functional unit for bit-reversed addressing useful in implementing an FFT), while coarse-grain accelerators are loosely integrated with a processor through the memory hierarchy (e.g., a graphics rendering accelerator sharing the last-level cache with a general-purpose processor). Medium-grain accelerators are often integrated as co-processors: the processor can directly send/receive messages to/from the accelerator with special instructions, but the co-processor is relatively decoupled from the main processor pipeline and can also independently interact with memory.</p> <p>This tutorial will use the vector-vector-add (vvadd) microbenchmark as an example. We will explore the area and timing of a baseline TinyRV2 pipelined processor and the energy and performance when this processor is used to execute a pure-software version of the vvadd microbenchmark. We will then implement a vvadd accelerator, integrate it with the TinyRV2 pipelined processor, and determine the potential benefit of hardware acceleration for this simple microbenchmark. This tutorial assumes you have already completed the tutorials on Linux, Git, Verilog, ASIC front-end flow, ASIC back-end flow, and ASIC automated ASIC flow.</p> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into the same specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut09-xcel-rtl tut09\n% cd tut09\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut09-xcel-rtl/#1-baseline-tinyrv2-processor-fl-and-rtl-models","title":"1. Baseline TinyRV2 Processor FL and RTL Models","text":"<p>The following figure illustrates the overall system we will be using with our TinyRV2 processors. The processor includes eight latency insensitive val/rdy interfaces. The mngr2proc/proc2mngr interfaces are used for the test harness to send data to the processor and for the processor to send data back to the test harness. The imem master/minion interface is used for instruction fetch, and the dmem master/minion interface is used for implementing load/store instructions. The system includes both instruction and data caches. The xcel master/minion interface is used for the processor to send messages to the accelerator. The mngr2proc/proc2mngr and memreq/memresp interfaces were all introduced in ECE 4750. For now we will largely ignore the accelerator, and we will defer discussion of the xcel master/minion interfaces to later in this tutorial. The cache is not ported to work with the ASIC flow so it is not currently included!</p> <p></p> <p>We provide two implementations of the TinyRV2 processor. The FL model in <code>sim/proc/ProcFL.py</code> is essentially an instruction-set-architecture (ISA) simulator; it simulates only the instruction semantics and makes no attempt to model any timing behavior. As a reminder, the TinyRV2 instruction set is defined here:</p> <ul> <li>http://www.csl.cornell.edu/courses/ece6745/handouts/ece6745-tinyrv-isa.txt</li> </ul> <p>The RTL model in <code>sim/proc/ProcPRTL.py</code> is similar to the alternative design for lab 2 in ECE 4750. It is a five-stage pipelined processor that implements the TinyRV2 instruction set and includes full bypassing/forwarding to resolve data hazards. There are two important differences from the alternative design for lab 2 of ECE 4750. First, the new processor design uses a single-cycle integer multiplier. We can push the design through the flow and verify that the single-cycle integer multiplier does not adversely impact the overall processor cycle time. Second, the new processor design includes the ability to handle new CSRs for interacting with medium-grain accelerators. The datapath diagram for the processor is shown below.</p> <p></p> <p>We should run all of the unit tests on both the FL and RTL processor models to verify that we are starting with a working processor.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../proc\n</code></pre> <p>See the handout for lab 2 from ECE 4750 for more information about how we use <code>pytest</code> and the mngr2proc/proc2mngr interfaces to test the TinyRV2 processor.</p>"},{"location":"ece6745-tut09-xcel-rtl/#2-testing-and-evaluating-tinyrv2-microbenchmarks","title":"2. Testing and Evaluating TinyRV2 Microbenchmarks","text":"<p>We will write our microbenchmarks in C. Take a closer look at the vvadd microbenchmark which is located in <code>app/ubmark/ubmark-vvadd.c</code>:</p> <pre><code>__attribute__ ((noinline))\nvoid vvadd_scalar( int *dest, int *src0, int *src1, int size )\n{\n  for ( int i = 0; i &lt; size; i++ )\n    dest[i] = src0[i] + src1[i];\n}\n</code></pre> <p>We will a use microbenchmark test to verify the functionality of our microbenchmark and a microbenchmark eval to evaluate the performance of our microbenchmark. We will run both the microbenchmark test and eval on both FL and RTL TinyRV2 processor models.</p>"},{"location":"ece6745-tut09-xcel-rtl/#21-tinyrv2-vvadd-test","title":"2.1. TinyRV2 VVADD Test","text":"<p>Let's go ahead and take a look at the microbenchmark test provided for the vvadd microbenchmark.</p> <pre><code>% cd $TOPDIR/app/ubmark\n% less ubmark-vvadd-test.c\n</code></pre> <p>Here is a snippet from the microbenchmark test.</p> <pre><code>#include \"ece6745.h\"\n#include \"ubmark-vvadd.h\"\n#include \"ubmark-vvadd.dat\"\n\nvoid test_case_1_pos()\n{\n  ECE6745_CHECK( L\"test_case_1_pos\" );\n\n  int src0[] = {  1,  2,  3,  4 };\n  int src1[] = {  5,  6,  7,  8 };\n  int dest[] = {  0,  0,  0,  0 };\n  int ref[]  = {  6,  8, 10, 12 };\n\n  ubmark_vvadd( dest, src0, src1, 4 );\n\n  for ( int i = 0; i &lt; 4; i++ )\n    ECE6745_CHECK_INT_EQ( dest[i], ref[i] );\n}\n\n...\n\nint main( int argc, char** argv )\n{\n  __n = ( argc == 1 ) ? 0 : ece6745_atoi( argv[1] );\n\n  if ( (__n &lt;= 0) || (__n == 1) ) test_case_1_pos();\n  ...\n\n  ece6745_wprintf( L\"\\n\\n\" );\n  return ece6745_check_status;\n}\n</code></pre> <p>The test harness includes several test case functions and then we call these test case functions in <code>main</code>. We wave a build system that can compile C code natively for x86 and can also cross-compile these microbenchmarks for TinyRV2 so they can be executed on our simulators. When developing and testing C code, we should always try to compile the code natively to ensure the code is functionally correct before we attempt to cross-compile the code for TinyRV2. Debugging code natively is much easier compared to debugging code on our simulators. Here is how we compile and execute the tests for the vvadd microbenchmark natively:</p> <pre><code>% cd $TOPDIR/app\n% mkdir build-native\n% cd build-native\n% ../configure\n% make ubmark-vvadd-test\n% ./ubmark-vvadd-test\n</code></pre> <p>You can run a single test case like this:</p> <pre><code>% cd $TOPDIR/app/build-native\n% ./ubmark-vvadd-test 1\n</code></pre> <p>Once we are confident the microbenchmark test passes on natively, we can cross-compile the microbenchmark test and run it on both FL and RTL TinyRV2 processor models. Let's start by cross-compiling the microbenchmark test.</p> <pre><code>% mkdir -p $TOPDIR/app/build\n% cd $TOPDIR/app/build\n% ../configure --host=riscv32-unknown-elf\n% make ubmark-vvadd-test\n</code></pre> <p>This will create a <code>ubmark-vvadd-test</code> binary which contains TinyRV2 instructions and data. You can disassemble a TinyRV2 binary (i.e., turn a compiled binary back into an assembly text representation) with the <code>riscv32-objdump</code> command like this:</p> <pre><code>% cd $TOPDIR/app/build\n% riscv32-objdump ubmark-vvadd-test | less -p \"&lt;ubmark_vvadd&gt;:\"\n00000fac &lt;ubmark_vvadd&gt;:\n    fac: bge    x0,  x13, fd8\n    fb0: slli   x13, x13, 0x2\n    fb4: add    x13, x11, x13\n    fb8: lw     x15, 0(x11)   # &lt;-.\n    fbc: lw     x14, 0(x12)   #   |\n    fc0: addi   x11, x11, 4   #   |\n    fc4: addi   x12, x12, 4   #   |\n    fc8: add    x15, x15, x14 #   |\n    fcc: sw     x15, 0(x10)   #   |\n    fd0: addi   x10, x10, 4   #   |\n    fd4: bne    x11, x13, fb8 # --'\n    fd8: jalr   x0,  x1,  0\n</code></pre> <p>You can also redirect the output from <code>riscv32-objdump</code> to a text file for viewing with VS Code. The disassembly shows the address and assembly text for each instruction in the binary.</p> <p>The assembly code for the <code>ubmark_vvadd</code> function is similar to what we saw in ECE 4750 although with some additional optimizations. I have added some comments to show the backwards branch for the vvadd loop. The loop has eight instructions. Four instructions do useful work (i.e., two LW instructions, the actual ADDU instruction, one SW instruction) and three ADDI instructions generate the array addresses by bumping the array pointers. Notice that there is no explicit loop counter. The compiler has instead calculated the address of one past the last element in the first source array, and placed this value in <code>x13</code>. Each iteration, the BNE instruction compares the current pointer to see if we have reached the end of the array.</p> <p>We have provided you with a simulator that composes a processor, cache, memory, and accelerator and is capable of executing TinyRV2 binaries. The simulator enables flexibly choosing the processor implementation (FL vs. RTL), the cache implementation (no cache vs. RTL), and the type and implementation of the accelerator. By default, the simulator uses the processor FL model, no cache model, and a null accelerator which we will discuss later. So let's execute the vvadd TinyRV2 binary on the instruction-set simulator:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim ./ubmark-vvadd-test\n</code></pre> <p>The simulator should display the same test output that we saw when executing the microbenchmark test natively. You can run a single test case like this:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim ./ubmark-vvadd-test 1\n</code></pre> <p>The <code>--trace</code> command line option will display each instruction as it is executed on the ISA simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --trace \\\n    ./ubmark-vvadd-test 1 &gt; ubmark-vvadd-test-fl.trace\n</code></pre> <p>When dumping out large line traces, it is usually much faster to save them to a file and then open the file in VS Code. Here is what the beginning of the line trace looks like.</p> <pre><code>cycle PC       instruction                                          FL memory\n----------------------------------------------------------------------------------\n  1r  #                                |              ()                 |     |\n  2r  #                                |              ()                 |     |\n  3:  #                                |              ()            rd&gt;  |     |\n  4:  #                                |              ()              &gt;rd|     |\n  5:  00000200 auipc  x03, 0x00003     |              ()                 |     |\n  6:  #                                |              ()            rd&gt;  |     |\n  7:  #                                |              ()              &gt;rd|     |\n  8:  00000204 addi   x03, x03, 0x9f0  |              ()                 |     |\n  9:  #                                |              ()            rd&gt;  |     |\n 10:  #                                |              ()              &gt;rd|     |\n 11:  00000208 addi   x01, x00, 0x000  |              ()                 |     |\n 12:  #                                |              ()            rd&gt;  |     |\n 13:  #                                |              ()              &gt;rd|     |\n 14:  0000020c addi   x02, x00, 0x000  |              ()                 |     |\n 15:  #                                |              ()            rd&gt;  |     |\n 16:  #                                |              ()              &gt;rd|     |\n 17:  00000210 addi   x04, x00, 0x000  |              ()                 |     |\n 18:  #                                |              ()            rd&gt;  |     |\n 19:  #                                |              ()              &gt;rd|     |\n</code></pre> <p>You can see the beginning of the program is initializing the registers to zero. Since this is an ISA simulator, instructions can functionally execute in a single cycle, although technically they take multiple \"cycles\" to interact with the memory system. These cycles are not really modeling any kind of realistic timing, but can instead be thought of as the \"steps\" required for functional simulation.</p> <p>Now that we have verified the microbenchmark test works correctly on the ISA simulator, we can run the microbenchmark test on the baseline TinyRV2 pipelined processor RTL model:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl ./ubmark-vvadd-test\n</code></pre> <p>Again the simulator should display the same test output that we saw when executing the microbenchmark test natively and on the FL simulator. You can run a single test case like this:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl ./ubmark-vvadd-test 1\n</code></pre> <p>Let's use the <code>--trace</code> command line option to dump out the trace.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --trace \\\n    ./ubmark-vvadd-test 1 &gt; ubmark-vvadd-test-rtl.trace\n</code></pre> <p>Here is what the first few cycles of the simulation look like.</p> <pre><code>cycle F        D                       X    M    W     imem  dmem\n-------------------------------------------------------------------\n  1r          |                       |    |    |    |      |     |\n  2r          |                       |    |    |    |      |     |\n  3:          |                       |    |    |    | rd&gt;  |     |\n  4:  00000200|                       |    |    |    | rd&gt;rd|     |\n  5:  00000204|auipc  x03, 0x00003    |    |    |    | rd&gt;rd|     |\n  6:  00000208|addi   x03, x03, 0x9f0 |auiP|    |    | rd&gt;rd|     |\n  7:  0000020c|addi   x01, x00, 0x000 |addi|auiP|    | rd&gt;rd|     |\n  8:  00000210|addi   x02, x00, 0x000 |addi|addi|auiP| rd&gt;rd|     |\n  9:  00000214|addi   x04, x00, 0x000 |addi|addi|addi| rd&gt;rd|     |\n 10:  00000218|addi   x05, x00, 0x000 |addi|addi|addi| rd&gt;rd|     |\n 11:  0000021c|addi   x06, x00, 0x000 |addi|addi|addi| rd&gt;rd|     |\n</code></pre> <p>We can see the five stages of the processor pipeline. The PC is displayed in the F stage, the full instruction is displayed in the D stage, and a shorter version of the instruction is displayed in the X, M, and W stages. We are using a single-cycle magic memory, so we can see instruction memory requests being sent and the responses being returned the next cycle. Again you can see the beginning of the program is initializing the registers to zero.</p>"},{"location":"ece6745-tut09-xcel-rtl/#22-tinyrv2-vvadd-eval","title":"2.2. TinyRV2 VVADD Eval","text":"<p>Once we are sure the microbenchmark test is working natively, on the FL simulator, and the RTL simulator, we can then turn our focus to the microbenchmark eval.</p> <pre><code>% cd $TOPDIR/app/ubmark\n% less ubmark-vvadd-eval.c\n</code></pre> <p>Here is the microbenchmark eval.</p> <pre><code>#include \"ece6745.h\"\n#include \"ubmark-vvadd.h\"\n#include \"ubmark-vvadd.dat\"\n\nint main( void )\n{\n  // Allocate destination array for results\n\n  int* dest = ece6745_malloc( eval_size * (int)sizeof(int) );\n\n  // Run the evaluation\n\n  ece6745_stats_on();\n  ubmark_vvadd( dest, eval_src0, eval_src1, eval_size );\n  ece6745_stats_off();\n\n  // Verify the results\n\n  for ( int i = 0; i &lt; eval_size; i++ ) {\n    if ( dest[i] != eval_ref[i] ) {\n      ece6745_wprintf( L\"\\n FAILED: dest[%d] != eval_ref[%d] (%d != %d)\\n\\n\",\n                       i, i, dest[i], eval_ref[i] );\n      ece6745_exit(1);\n    }\n  }\n\n  // Free destination array\n\n  ece6745_free(dest);\n\n  // Check for no memory leaks\n\n  if ( ece6745_get_heap_usage() != 0 ) {\n    ece6745_wprintf( L\"\\n FAILED: memory leak of %d bytes!\\n\\n\",\n                     ece6745_get_heap_usage() );\n    ece6745_exit(1);\n  }\n\n  // Otherwise we passed\n\n  ece6745_wprintf( L\"\\n **PASSED** \\n\\n\" );\n\n  return 0;\n}\n</code></pre> <p>The <code>eval_src0</code>, <code>eval_src1</code>, and <code>eval_ref</code> arrays are all defined in the <code>app/ubmark/ubmark-vvadd.dat</code> file. The microbenchmark first allocates the destination array on the heap, turns stats on, does the actual vvadd computation, turns stats off, verifies that the results are as expected, and makes sure there are no memory leaks. We need the <code>ece6745_stats_on()</code> and <code>ece6745_stats_off()</code> functions to make sure we can keep track of various statistics (e.g., the number of cycles) only during the important part of the microbenchmark. We do not want to count time spent in initialization or verification when comparing the performance of our various microbenchmarks. The <code>ece6745_stats_on</code> function is defined in <code>app/ece6745/ece6745-misc.h</code> as follows:</p> <pre><code>#ifdef _RISCV\n\ninline\nvoid ece6745_stats_on()\n{\n  int status = 1;\n  __asm__ ( \"csrw 0x7c1, %0\" :: \"r\"(status) );\n}\n\n#else\n\ninline\nvoid ece6745_stats_on()\n{ }\n\n#endif\n</code></pre> <p>Notice that if <code>_RISCV</code> is not defined (i.e., we are compiling the microbenchmark eval natively on x86) this function is empty. If <code>_RISCV</code> is defined (i.e., we are cross-compilng the microbenchmark eval for TinyRV2) then this function uses GCC inline assembly to insert a CSRW instruction into the program. You can find out more about inline assembly syntax here:</p> <ul> <li>https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html</li> </ul> <p>At a high level, <code>%0</code> acts as a place holder for whatever register specifier the compiler ends up allocating for the <code>status</code> variable. The TinyRV2 instruction set defines CSR number 0x7c1 as the <code>stats_en</code> control/status register, which is why we use <code>0x7c1</code> in the inline assembly. Refer to the TinyRV2 instruction set for a list of the CSRs.</p> <ul> <li>http://www.csl.cornell.edu/courses/ece6745/handouts/ece6745-tinyrv-isa.txt</li> </ul> <p>The idea is that the microarchitecture and/or simulator can monitor for writes to the <code>stats_en</code> register to determine when to start and stop keeping statistics. For more on writing microbenchmarks, please review the handout for lab 5 from ECE 4750.</p> <p>Here is how we compile and execute the evaluation for the vvadd microbenchmark natively:</p> <pre><code>% cd $TOPDIR/app/build-native\n% make ubmark-vvadd-eval\n% ./ubmark-vvadd-eval\n</code></pre> <p>The microbenchmark eval should display <code>passed</code>. Once you are sure your microbenchmark eval is working correctly natively, you can cross-compile the microbenchmark eval for TinyRV2 and look at the main function.</p> <pre><code>% cd $TOPDIR/app/build\n% make ubmark-vvadd-eval\n% riscv32-objdump ./ubmark-vvadd-eval | less -p \"&lt;main&gt;:\"\n</code></pre> <p>If you look in the disassembly for the main function you should be able to see the two CSRW instructions used to turn stats on and off.</p> <pre><code> 6f8:   addi    x15,x0,1              # \\\n 6fc:   csrw    0x7c1,x15             # / turn stats on\n 700:   lui     x12,0x1               # \\\n 704:   lw      x13,-2048(x3)         # | setup arguments\n 708:   addi    x9,x12,-1072          # |\n 70c:   addi    x11,x9,400            # |\n 710:   addi    x12,x12,-1072         # /\n 714:   jal     x1,2fc &lt;ubmark_vvadd&gt; # call the ubmark_vvadd function\n 718:   addi    x15,x0,0              # \\\n 71c:   csrw    0x7c1,x15             # / turn stats off\n</code></pre> <p>Now let's run the microbenchmark eval on the FL simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim ./ubmark-vvadd-eval\n</code></pre> <p>The microbenchmark eval should display <code>passed</code>. Once you are sure your microbenchmark eval is working correctly natively and on the FL simulator you are finally ready to run it on the actual RTL simulator to do a real performance evaluation.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --stats ./ubmark-vvadd-eval\n **PASSED**\n\n num_cycles        = 1013\n num_inst          = 812\n CPI               = 1.25\n</code></pre> <p>Now let's look in more detail at the trace.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --trace ./ubmark-vvadd-eval &gt; ubmark-vvadd-eval-rtl.trace\n</code></pre> <p>Open up the trace in VS code and search for 0fbc which is the address of the first instruction in the loop.</p> <pre><code>cycle F        D                       X    M    W     imem  dmem\n-------------------------------------------------------------------\n841:  00000fbc|lw     x15, 0x000(x11) |add |slli|bge | rd&gt;rd|     |\n842:  00000fc0|lw     x14, 0x000(x12) |lw  |add |slli| rd&gt;rd|rd&gt;  |\n843:  00000fc4|addi   x11, x11, 0x004 |lw  |lw  |add | rd&gt;rd|rd&gt;rd|\n844:  00000fc8|addi   x12, x12, 0x004 |addi|lw  |lw  | rd&gt;rd|  &gt;rd|\n845:  00000fcc|add    x15, x15, x14   |addi|addi|lw  | rd&gt;rd|     |\n846:  00000fd0|sw     x15, 0x000(x10) |add |addi|addi| rd&gt;rd|     |\n847:  00000fd4|addi   x10, x10, 0x004 |sw  |add |addi| rd&gt;rd|wr&gt;  |\n848:  00000fd8|bne    x11, x13, 0x1fe4|addi|sw  |add | rd&gt;rd|  &gt;wr|\n849:  /       |/                      |bne |addi|sw  | rd&gt;rd|     |\n850:  00000fb8|                       |    |bne |addi| rd&gt;rd|     |\n851:  00000fbc|lw     x15, 0x000(x11) |    |    |bne | rd&gt;rd|     |\n852:  00000fc0|lw     x14, 0x000(x12) |lw  |    |    | rd&gt;rd|rd&gt;  |\n853:  00000fc4|addi   x11, x11, 0x004 |lw  |lw  |    | rd&gt;rd|rd&gt;rd|\n854:  00000fc8|addi   x12, x12, 0x004 |addi|lw  |lw  | rd&gt;rd|  &gt;rd|\n</code></pre> <p>We can see the eight instructions in the loop going through the five stages of the pipeline. We can see the memory requests for the two loads and store going to the data memory and the responses coming back on the next cycle. We can also see the branch misprediction squashing two instructions. The <code>eval_size</code> is 100 so there are 100 iterations of the loop and 800 instructions, which should take a total of 1000 cycles resulting in a CPI of 1.25.</p> <p>When we used <code>--stats</code> the instruction count and number of cycles was slightly higher due to the extra instructions required to setup the arguments before calling <code>ubmark_vvadd</code> and the extra instructions within <code>ubmark_vvadd</code> before we start the loop.</p>"},{"location":"ece6745-tut09-xcel-rtl/#3-testing-and-evaluating-accelerators-in-isolation","title":"3. Testing and Evaluating Accelerators in Isolation","text":"<p>We will take an incremental approach when designing, implementing, testing, and evaluating accelerators. We can use test sources, sinks, and memories to create a test harness that will enable us to explore the accelerator cycle-level performance and the ASIC area, energy, and timing in isolation. Only after we are sure that we have a reasonable design-point should we consider integrating the accelerator with the processor.</p> <p>All accelerators have an xcel minion interface along with a standard mem master interface. The messages sent over the xcel minion interface allows the test harness or processor to read and write accelerator registers. These accelerator registers can be real registers that hold configuration information and/or results, or these accelerator registers can just be used to trigger certain actions. The messages sent over the xcel.req interface from the test harness or processor to the accelerator have the following format:</p> <pre><code>   1b     5b      32b\n +------+-------+-----------+\n | type | raddr | data      |\n +------+-------+-----------+\n</code></pre> <p>The 1-bit <code>type</code> field indicates if this messages if for reading (0) or writing (1) an accelerator register, the 5-bit <code>raddr</code> field specifies which accelerator register to read or write, and the 32-bit <code>data</code> field is the data to be written. For every accelerator request, the accelerator must send back a corresponding accelerator response over the xcel.resp interface. These response messages have the following format:</p> <pre><code>   1b     32b\n +------+-----------+\n | type | data      |\n +------+-----------+\n</code></pre> <p>The 1-bit <code>type</code> field gain indicates if this response is from if for reading (0) or writing (1) an accelerator register, and the 32-bit <code>data</code> field is the data read from the corresponding accelerator register. Every accelerator is free to design its own accelerator protocol by defining the meaning of reading/writing the 32 accelerator registers.</p> <p>We have implemented a null accelerator which we can use when we don't want to integrate a \"real\" accelerator, but this null accelerator is also useful in illustrating the basic accelerator interface. The null accelerator has a single accelerator register (xr0) which can be read and written. Take a closer look at this null accelerator in <code>sim/proc/NullXcel.v</code>.</p> <pre><code>  always_comb begin\n\n    // Mux to force xcelresp data to zero on a write\n    // Enable xr0 only upon write requests and both val/rdy on resp side\n\n    if ( xcelreq_deq_msg.type_ == `VC_XCEL_REQ_MSG_TYPE_WRITE ) begin\n      xr0_en = xcel_respstream_val &amp;&amp; xcel_respstream_rdy;\n      xcel_respstream_msg.data = '0;\n    end\n    else begin\n      xr0_en = 0;\n      xcel_respstream_msg.data = xr0;\n    end\n\n  end\n</code></pre> <p>The null accelerator simply waits for a xcel.req message to arrive. If that message is a read, then it reads the <code>xr0</code> register into the xcelresp message. If that message is a write, then it sets the enable of the <code>xr0</code> register so that the new value is flopped in at the end of the cycle. Here is a unit test which writes a value to the null accelerator's xr0 register and then reads it back:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../proc/test/NullXcel_test.py -k basic -s\n\n  1r                &gt;               |.           &gt; .\n  2r                &gt;               |.           &gt; .\n  3:                &gt;               |.           &gt; .\n  4:                &gt;               |.           &gt; .\n  5:                &gt;               |.           &gt; .\n  6:                &gt;               |.           &gt; .\n  7: wr:00:0000000a &gt; wr:00:0000000a|            &gt;\n  8: rd:00:         &gt; rd:00:        |wr:         &gt; wr:\n  9:                &gt;               |rd:0000000a &gt; rd:0000000a\n 10:                &gt;               |            &gt;\n</code></pre> <p>From the line trace, you can see the write request message (with write data 0x0a) going into the accelerator, and then the write response being returned on the next cycle. You can also see the read request message going into the accelerator, and then the read response being returned (with read data 0x0a) again on the next cycle.</p> <p>The vvadd accelerator is obviously more sophisticated. Accelerator protocols are usually defined as a comment at the top of the FL model, so take a closer look at the vvadd accelerator FL model in <code>sim/tut9_xcel/VvaddXcelFL.py</code>. The vvadd accelerator protocol defines the accelerator registers as follows:</p> <ul> <li>xr0 : go/done</li> <li>xr1 : base address of the array src0</li> <li>xr2 : base address of the array src1</li> <li>xr3 : base address of the array dest</li> <li>xr4 : size of the array</li> </ul> <p>The actual protocol involves the following steps:</p> <ol> <li>Write the base address of src0 to xr1</li> <li>Write the base address of src1 to xr2</li> <li>Write the base address of dest to xr3</li> <li>Write the number of elements in the array to xr4</li> <li>Tell accelerator to go by writing xr0</li> <li>Wait for accelerator to finish by reading xr0, result will be 1</li> </ol> <p>A close look at the vvadd accelerator FL model shows that most of the work is really in managing this accelerator protocol. The accelerator waits for accelerator requests, updates its internal state registers, and when it receives a write to xr0 it starts doing the actual vvadd computation. The FL model makes use of method-based interfaces to simplify interacting with the memory system. Let's run the unit tests on the FL model first:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut9_xcel/test/VvaddXcelFL_test.py -v\n</code></pre> <p>The vvadd accelerator CL model is actually very close to the RTL implementation largely due to the need to carefully interact with the latency insensitive memory interface. CL modeling may or may not be useful in this context. The vvadd accelerator RTL model is in <code>sim/tut9_xcel/VvaddXcelPRTL.py</code> and (roughly) implements the following FSM:</p> <p></p> <p>While the accelerator is in the XCFG state, it will update its internal registers when it receives accelerator requests. When the accelerator receives a write to xr0 it moves into the M_RD state. While in the M_RD state, the accelerator will send out two memory read requests to read the current element from each source array. In the ADD state, the accelerator will do the actual addition, and in the M_WR state, the accelerator will send out the memory write request to write the result to the destination array. The accelerator will wait in the final WAIT state until it receives the memory write response, and then will either move back into the M_RD state if there is another element to be processed, or move into the XCFG state if we have processed all elements in the array.</p> <p>The accelerator is not implemented with a control/datapath split because the accelerator is almost entirely control logic; it was just simpler to implement the accelerator as a single model. When a model is almost all control logic or almost all datapath logic, then a control/datapath split may be more trouble than its worth.</p> <p>Let's run the unit tests for all of the vvadd accelerator models:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut9_xcel\n% pytest ../tut9_xcel --test-verilog\n</code></pre> <p>We have also included a simulator for just the vvadd accelerator in isolation which can be used to evaluate its performance.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut9_xcel/vvadd-xcel-sim --impl rtl --input multiple --stats\n  num_cycles = 1058\n</code></pre> <p>We could use the simulator to help evaluate the cycle-level performance of the accelerator on various different datasets as we try out various optimizations.</p>"},{"location":"ece6745-tut09-xcel-rtl/#4-testing-and-evaluating-tinyrv2-microbenchmarks-with-accelerators","title":"4. Testing and Evaluating TinyRV2 Microbenchmarks with Accelerators","text":"<p>Now that we have unit tested and evaluated both the baseline TinyRV2 pipelined processor and the vvadd accelerator in isolation, we are finally ready to compose them. We will start by looking at a basic null accelerator to understand how we will integrate processors and accelerators before looking at the vvadd accelerator in the next section.</p>"},{"location":"ece6745-tut09-xcel-rtl/#41-integrating-the-tinyrv2-processor-and-a-null-accelerator","title":"4.1. Integrating the TinyRV2 Processor and a Null Accelerator","text":"<p>The key way the processor interacts with an accelerator is by sending messages that read and write 32 special accelerator registers using the standard CSRW and CSRR instructions. These 32 special CSRs are as follows:</p> <pre><code>  0x7e0 : accelerator register  0 (xr0)\n  0x7e1 : accelerator register  1 (xr1)\n  0x7e2 : accelerator register  2 (xr2)\n  ...\n  0x7ff : accelerator register 31 (xr31)\n</code></pre> <p>When the processor uses a CSRW instruction to write an accelerator register, it first reads the general-purpose register file to get the source value, creates a new accelerator request message, then sends this message to the accelerator through the xcel.req interface in the X stage. The processor waits for the response message to be returned through the xcel.resp interface in the M stage. The processor uses a CSRR instruction to read an accelerator register in a similar way, except that when the response message is returned in the M stage, the data from the accelerator is sent down the pipeline and written into the general-purpose register file in the W stage.</p> <p>Here is a simple assembly sequence which will write the value <code>1</code> to the null accelerator's only accelerator register, read that value back from the accelerator register, and write the value to general-purpose register <code>x2</code>.</p> <pre><code>  addi x1, x0, 1\n  csrw 0x7e0, x1\n  csrr x2, 0x7e0\n</code></pre> <p>You can run a simple test of using the CSRW/CSRR instructions to write/read an accelerator register like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../proc/test/ProcFL_xcel_test.py\n% pytest ../proc/test/Proc_xcel_test.py\n% pytest ../proc/test/Proc_xcel_test.py -k [bypass -s\n\n     src        F-stage   D-stage                 X    M    W    xcelreq         xcelresp    sink\n ------------------------------------------------------------------------------------------------------\n  1r .        &gt;          |                       |    |    |    |              ().           &gt;\n  2r .        &gt;          |                       |    |    |    |              ().           &gt;\n  3: .        &gt;          |                       |    |    |    |              ().           &gt;\n  4: #        &gt;  00000200|                       |    |    |    |              ().           &gt;\n  5: deadbeef &gt;  00000204|csrr   x02, mngr2proc  |    |    |    |              ().           &gt;\n  6: #        &gt;  00000208|nop                    |csrr|    |    |              ().           &gt;\n  7: #        &gt;  0000020c|nop                    |nop |csrr|    |              ().           &gt;\n  8: #        &gt;  00000210|nop                    |nop |nop |csrr|              ().           &gt;\n  9: #        &gt;  00000214|csrw   0x7e0, x02      |nop |nop |nop |              ().           &gt;\n 10: #        &gt;  00000218|csrr   x03,     0x7e0  |csrw|nop |nop |wr:00:deadbeef().           &gt;\n 11: #        &gt;  0000021c|nop                    |csrr|csrw|nop |rd:00:        ()wr:         &gt;\n 12: #        &gt;  00000220|nop                    |nop |csrr|csrw|              ()rd:deadbeef &gt;\n 13: #        &gt;  00000224|nop                    |nop |nop |csrr|              ().           &gt;\n 14: #        &gt;  00000228|csrw   proc2mngr, x03  |nop |nop |nop |              ().           &gt;\n 15: deadbe00 &gt;  0000022c|csrr   x02, mngr2proc  |csrw|nop |nop |              ().           &gt;\n 16: #        &gt;  00000230|nop                    |csrr|csrw|nop |              ().           &gt;\n 17: #        &gt;  00000234|nop                    |nop |csrr|csrw|              ().           &gt; deadbeef\n 18: #        &gt;  00000238|csrw   0x7e0, x02      |nop |nop |csrr|              ().           &gt;\n 19: #        &gt;  0000023c|csrr   x03,     0x7e0  |csrw|nop |nop |wr:00:deadbe00().           &gt;\n 20: #        &gt;  00000240|nop                    |csrr|csrw|nop |rd:00:        ()wr:         &gt;\n 21: #        &gt;  00000244|nop                    |nop |csrr|csrw|              ()rd:deadbe00 &gt;\n 22: #        &gt;  00000248|csrw   proc2mngr, x03  |nop |nop |csrr|              ().           &gt;\n 23: 00adbe00 &gt;  0000024c|csrr   x02, mngr2proc  |csrw|nop |nop |              ().           &gt;\n 24: #        &gt;  00000250|nop                    |csrr|csrw|nop |              ().           &gt;\n 25: #        &gt;  00000254|csrw   0x7e0, x02      |nop |csrr|csrw|              ().           &gt; deadbe00\n 26: #        &gt;  00000258|csrr   x03,     0x7e0  |csrw|nop |csrr|wr:00:00adbe00().           &gt;\n 27: #        &gt;  0000025c|nop                    |csrr|csrw|nop |rd:00:        ()wr:         &gt;\n 28: #        &gt;  00000260|csrw   proc2mngr, x03  |nop |csrr|csrw|              ()rd:00adbe00 &gt;\n 29: dea00eef &gt;  00000264|csrr   x02, mngr2proc  |csrw|nop |csrr|              ().           &gt;\n 30: .        &gt;  00000268|csrw   0x7e0, x02      |csrr|csrw|nop |              ().           &gt;\n 31: .        &gt;  0000026c|csrr   x03,     0x7e0  |csrw|csrr|csrw|wr:00:dea00eef().           &gt; 00adbe00\n 32: .        &gt;  #       |#                      |csrr|csrw|csrr|rd:00:        ()wr:         &gt;\n 33: .        &gt;  00000270|csrw   proc2mngr, x03  |    |csrr|csrw|              ()rd:dea00eef &gt;\n 34: .        &gt;  #       |#                      |csrw|    |csrr|              ().           &gt;\n 35: .        &gt;  #       |#                      |    |csrw|    |              ().           &gt;\n 36: .        &gt;  #       |#                      |    |    |csrw|              ().           &gt; dea00eef\n 37: .        &gt;  #       |#                      |    |    |    |              ().           &gt;\n</code></pre> <p>I have cleaned up the line trace a bit to annotate the columns and make it more compact. You can see the processor executing CSRW/CSRR instructions to 0x7e0 which is accelerator register 0. This results in the processor sending accelerator requests to the null accelerator, and then the accelerator sending the corresponding accelerator responses back to the processor.</p> <p>Also notice the need for the processor to add new RAW dependency stall logic. CSRR instructions which read from accelerator registers send out the xcel.req in the X stage and receive the xcelresp in the M stage. This means we cannot bypass data from a CSRR instruction if it is in the X stage since the data has not returned from the accelerator yet. In cycle 32, the CSRW instruction in the decode stage needs to stall to wait for the CSRR instruction in the X stage to move into the M stage.</p> <p>To use an accelerator from a C microbenchmark, we can use the same GCC inline assembly extensions we used to write the <code>stats_en</code> CSR earlier in the tutorial. Take a closer look at the <code>app/ubmark/ubmark-null-xcel-test.c</code> example:</p> <pre><code> __attribute__ ((noinline))\n int ubmark_null_xcel( int in )\n {\n   int result;\n   __asm__ (\n     \"csrw 0x7E0,     %[in];\\n\"\n     \"csrr %[result], 0x7E0;\\n\"\n\n     // Outputs from the inline assembly block\n\n     : [result] \"=r\"(result)\n\n     // Inputs to the inline assembly block\n\n     : [in] \"r\"(in)\n\n   );\n   return result;\n }\n</code></pre> <p>We are inserting a CSRW instruction to copy the value passed to this function through the <code>in</code> argument, and then we are using an CSRR instruction to retrieve the same value from the null accelerator. Notice that unlike the inline assembly we used when setting the <code>stats_en</code> CSR, here we also need to handle outputs from the assembly block. Again, you can find out more about inline assembly syntax here:</p> <ul> <li>https://gcc.gnu.org/onlinedocs/gcc/Extended-Asm.html</li> </ul> <p>Let's cross-compile this microbenchmark. Note that you cannot natively compile a microbenchmark that makes use of an accelerator, since x86 does not have any accelerators!</p> <pre><code>% cd $TOPDIR/app/build\n% make ubmark-null-xcel-test\n% riscv32-objdump ubmark-null-xcel-test | less -p\"&lt;ubmark_null_xcel&gt;:\"\n000002fc &lt;ubmark_null_xcel&gt;:\n    2fc:  csrw 0x7e0,x10\n    300:  csrr x10,0x7e0\n    304:  jalr x0,x1,0\n</code></pre> <p>Always a good idea to use <code>riscv32-objdump</code> so you can verify your C code is compiling as expected. Here we can see that the <code>null_xcel</code> function compiles into a CSRW, CSRR, and JALR instruction as expected. We should now run this microbenchmark on our ISA simulator to verify it works, and then we can run it on our RTL simulator.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../pmx/pmx-sim ../../app/build/ubmark-null-xcel\n% ../pmx/pmx-sim --proc-impl rtl --cache-impl rtl --xcel-impl null-rtl \\\n     --trace ../../app/build/ubmark-null-xcel\n</code></pre>"},{"location":"ece6745-tut09-xcel-rtl/#42-tinyrv2-vvadd-xcel-test","title":"4.2. TinyRV2 VVADD Xcel Test","text":"<p>Let's turn out attention to our vvadd accelerator. Take a closer look at the accelerated version of the vvadd microbenchmark in <code>app/ubmark/ubmark-vvadd-xcel.c</code>:</p> <pre><code> __attribute__ ((noinline))\n void vvadd_xcel( int *dest, int *src0, int *src1, int size )\n {\n   asm volatile (\n     \"csrw 0x7E1, %[src0];\\n\"\n     \"csrw 0x7E2, %[src1];\\n\"\n     \"csrw 0x7E3, %[dest];\\n\"\n     \"csrw 0x7E4, %[size];\\n\"\n     \"csrw 0x7E0, x0     ;\\n\"\n     \"csrr x0,    0x7E0  ;\\n\"\n\n     // Outputs from the inline assembly block\n\n     :\n\n     // Inputs to the inline assembly block\n\n     : [src0] \"r\"(src0),\n       [src1] \"r\"(src1),\n       [dest] \"r\"(dest),\n       [size] \"r\"(size)\n\n     // Tell the compiler this accelerator read/writes memory\n\n     : \"memory\"\n   );\n }\n</code></pre> <p>Notice that our use of the CSRW/CSRR instructions corresponds exactly to the accelerator protocol described above. We first write the source base pointers, the destination base pointer, and the size before starting the accelerator by writing to <code>xr0</code> and then waiting for the accelerator to finish by reading <code>xr0</code>. We need a final <code>\"memory\"</code> argument in our inline assembly block to tell the compiler that this accelerator reads and writes memory. Let's cross-compile the test for the vvadd microbenchmark:</p> <pre><code>% cd $TOPDIR/app/build\n% make ubmark-vvadd-xcel-test\n% riscv32-objdump ubmark-vvadd-xcel-test | less -p\"&lt;ubmark_vvadd_xcel&gt;:\"\n00000fac &lt;ubmark_vvadd_xcel&gt;:\n    fac:  csrw 0x7e1, x11\n    fb0:  csrw 0x7e2, x12\n    fb4:  csrw 0x7e3, x10\n    fb8:  csrw 0x7e4, x13\n    fbc:  csrw 0x7e0, x0\n    fc0:  csrr x0, 0x7e0\n    fc4:  jalr x0, x1, 0\n</code></pre> <p>Everything looks as expected, so we can now test our accelerated vvadd microbenchmark on the ISA simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --xcel-impl vvadd-fl ./ubmark-vvadd-xcel-test\n</code></pre> <p>Notice that we needed to specify the accelerator implementation as a command line option. If we forgot to include this option, then the simulator would use the null accelerator and clearly the accelerated vvadd microbenchmark does not work with the null accelerator!</p> <p>Finally, we can run the test on the RTL implementation of the processor and accelerator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl vvadd-rtl \\\n    ./ubmark-vvadd-xcel-test\n</code></pre> <p>All of the tests should pass.</p>"},{"location":"ece6745-tut09-xcel-rtl/#43-tinyrv2-vvadd-xcel-eval","title":"4.3. TinyRV2 VVADD Xcel Eval","text":"<p>We are now ready to run the microbenchmark eval. We first make sure it works on the FL simulator.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --xcel-impl vvadd-fl ./ubmark-vvadd-xcel-eval\n</code></pre> <p>Finally, we can run the accelerated vvadd microbenchmark on the RTL implementation of the processor augmented with the RTL implementation of the vvadd accelerator:</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl vvadd-rtl \\\n     --stats ./ubmark-vvadd-xcel-eval\n **PASSED**\n\n num_cycles        = 818\n num_inst          = 15\n CPI               = 54.53\n</code></pre> <p>The CPI is so large because there are only a few CSR instructions. All of the work is done by the vvadd accelerator. Recall that the pure-software vvadd microbenchmark required 1013 cycles. So our accelerator results in a cycle-level speedup of 1.23x. We might ask, where did this speedup come from? Why isn't the speedup larger? Let's look at the line trace.</p> <pre><code>% cd $TOPDIR/app/build\n% ../../sim/pmx/pmx-sim --proc-impl rtl --xcel-impl vvadd-rtl \\\n     --trace ./ubmark-vvadd-xcel-eval &gt; ubmark-vvadd-xcel-eval-rtl.trace\n</code></pre> <p>Here is what the line trace looks like for the initial configuration of the accelerator and the first two iterations of the vvadd loop:</p> <pre><code>cyc   F-stage  D-stage                 X    M    W    xcelreq        ST xcelresp    imem  dmem  xmem\n-----------------------------------------------------------------------------------------------------\n186:  000006ec|csrw   stats_en , x15  |addi|addi|    |              (X ).           rd&gt;rd|     |\n187:  000006f0|lui    x12, 0x00001    |csrw|addi|addi|              (X ).           rd&gt;rd|     |\n188:  000006f4|lw     x13, 0x800(x03) |lui |csrw|addi|              (X ).           rd&gt;rd|     |\n189:  000006f8|addi   x09, x12, 0xbc0 |lw  |lui |csrw|              (X ).           rd&gt;rd|rd&gt;  |\n190: *000006fc|addi   x11, x09, 0x190 |addi|lw  |lui |              (X ).           rd&gt;rd|  &gt;rd|\n191: *00000700|addi   x12, x12, 0xbc0 |addi|addi|lw  |              (X ).           rd&gt;rd|     |\n192: */       |jal    x01, 0x1ffbfc   |addi|addi|addi|              (X ).           rd&gt;rd|     |\n193: *000002fc|                       |jal |addi|addi|              (X ).           rd&gt;rd|     |\n194: *00000300|csrw   0x7e1, x11      |    |jal |addi|              (X ).           rd&gt;rd|     |\n195: *00000304|csrw   0x7e2, x12      |csrw|    |jal |wr:01:00000d50(X ).           rd&gt;rd|     |\n196: *00000308|csrw   0x7e3, x10      |csrw|csrw|    |wr:02:00000bc0(X )wr:         rd&gt;rd|     |\n197: *0000030c|csrw   0x7e4, x13      |csrw|csrw|csrw|wr:03:000010c4(X )wr:         rd&gt;rd|     |\n198: *00000310|csrw   0x7e0, x00      |csrw|csrw|csrw|wr:04:00000064(X )wr:         rd&gt;rd|     |\n199: *00000314|csrr   x00,     0x7e0  |csrw|csrw|csrw|wr:00:00000000(X )wr:         rd&gt;rd|     |\n200: *00000318|jalr   x00, x01, 0x000 |csrr|csrw|csrw|rd:00:        (X )wr:         rd&gt;rd|     |\n201: *#       |#                      |#   |#   |csrw|.             (RD).                |     |rd&gt;\n202: *#       |#                      |#   |#   |    |.             (RD).                |     |rd&gt;rd\n203: *#       |#                      |#   |#   |    |.             (RD).                |     |  &gt;rd\n204: *#       |#                      |#   |#   |    |.             (RD).                |     |\n205: *#       |#                      |#   |#   |    |.             (+ ).                |     |\n206: *#       |#                      |#   |#   |    |.             (WR).                |     |wr&gt;\n207: *#       |#                      |#   |#   |    |.             (W ).                |     |  &gt;wr\n208: *#       |#                      |#   |#   |    |.             (W ).                |     |\n209: *#       |#                      |#   |#   |    |.             (RD).                |     |rd&gt;\n210: *#       |#                      |#   |#   |    |.             (RD).                |     |rd&gt;rd\n211: *#       |#                      |#   |#   |    |.             (RD).                |     |  &gt;rd\n212: *#       |#                      |#   |#   |    |.             (RD).                |     |\n213: *#       |#                      |#   |#   |    |.             (+ ).                |     |\n214: *#       |#                      |#   |#   |    |.             (WR).                |     |wr&gt;\n215: *#       |#                      |#   |#   |    |.             (W ).                |     |  &gt;wr\n216: *#       |#                      |#   |#   |    |.             (W ).                |     |\n217: *#       |#                      |#   |#   |    |.             (RD).                |     |rd&gt;\n218: *#       |#                      |#   |#   |    |.             (RD).                |     |rd&gt;rd\n219: *#       |#                      |#   |#   |    |.             (RD).                |     |  &gt;rd\n220: *#       |#                      |#   |#   |    |.             (RD).                |     |\n</code></pre> <p>I have cleaned up the line trace a bit to annotate the columns and make it more compact. The ST column is the current state of the vvadd accelerator FSM. You can see the processor executing the CSRW instructions to configure the accelerator, and these instructions then turn into messages over the xcel.req interface. The accelerator is in the XCFG state receiving these messages until it receives the write to <code>xr0</code> which causes the accelerator to move into the RD stage. The accelerator sends memory read requests into the memory system, then does the vvadd, then writes the result back to the memory system. We know that every iteration should look like the first iteration (8 cycles). Since there are 100 iterations, this means the total number of cycles should be about 800 cycles, but our simulator reported 818 cycles. Again, the discrepancy is due to the extra cycles required to call and return from the <code>ubmark_vvadd_xcel</code> function. So the accelerator is a little faster than the processor since it requires fewer cycles per iteration.</p> <p>There is certainly room for improvement. We can probably remove some of the bubbles and improve the accelerator performance by a couple more cycles. The accelerator could also potentially use wide accesses to the data cache to retrieve four words at a time and then process all four words in parallel. The accelerator could also potentially achieve better performance by issuing multiple memory requests to a non-blocking cache. Eventually we should be able to optimize such an accelerator so that it is memory bandwidth limited (i.e., we are doing a memory request every cycle).</p>"},{"location":"ece6745-tut10-sram/","title":"ECE 6745 Tutorial 10: SRAM Generators","text":"<p>Small memories can be easily synthesized using flip-flop or latch standard cells, but synthesizing large memories can significantly impact the area, energy, and timing of the overall design. ASIC designers often use SRAM generators to \"generate\" arrays of memory bitcells and the corresponding peripheral circuitry (e.g., address decoders, bitline drivers, sense amps) which are combined into what is called an \"SRAM macro\". These SRAM generators are parameterized to enable generating a wide range of SRAM macros with different numbers of rows, columns, and column muxes, as well as optional support for partial writes, built-in self-test, and error correction. Similar to a standard-cell library, an SRAM generator must generate not just layout but also all of the necessary views to capture logical functionality, timing, geometry, and power usage. These views can then by used by the ASIC tools to produce a complete design which includes a mix of both standard cells and SRAM macros.</p> <p>The tutorial will first describe how to use the open-source OpenRAM memory generator to generate various views of an SRAM macro. You will then see how to use an SRAM in an RTL model, how to generate the corresponding SRAM macro, and then how to push a design which uses an SRAM macro through the manual ASIC flow. Finally, you will see how to use pyhflow to automate this process. This tutorial assumes you have already completed the tutorials on Linux, Git, PyMTL, Verilog, ASIC front-end flow, ASIC back-end flow, and ASIC automated ASIC flow.</p> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into a specific <code>ecelinux</code> server and then use Microsoft Remote Desktop to log into the same server. Once you are at the <code>ecelinux</code> prompt, source the setup script, source the GUI setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% source setup-gui.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut10-sram tut10\n% cd tut10\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut10-sram/#1-openram-memory-generator","title":"1. OpenRAM Memory Generator","text":"<p>Just as with standard-cell libraries, acquiring real SRAM generators is a complex and potentially expensive process. It requires gaining access to a specific fabrication technology, negotiating with a company which makes the SRAM generator, and usually signing multiple non-disclosure agreements. The OpenRAM memory generator is based on the same \"fake\" 45nm technology that we are using for the Nangate standard-cell library. The \"fake\" technology is representative enough to provide reasonable area, energy, and timing estimates for our purposes. In this section, we will take a look at how to use the OpenRAM memory generator to generate various views of an SRAM macro.</p> <p>An SRAM generator takes as input a configuration file which specifies the various parameters for the desired SRAM macro. Let's go ahead and create such a configuration file for a small SRAM. For this section of the tutorial, we will work in the <code>openram</code> subdirectory. The name of the configuration file should be <code>SRAM_32x128_1rw_cfg.py</code>.</p> <pre><code>% mkdir -p $TOPDIR/openram\n% code SRAM_32x128_1rw_cfg.py\n</code></pre> <p>The configuration file should look like this:</p> <pre><code>use_conda       = False\n\nnum_rw_ports    = 1\nnum_r_ports     = 0\nnum_w_ports     = 0\n\nword_size       = 32\nnum_words       = 128\nnum_banks       = 1\nwords_per_row   = 4\nwrite_size      = 8\n\ntech_name       = \"freepdk45\"\nprocess_corners = [\"TT\"]\nsupply_voltages = [1.1]\ntemperatures    = [25]\n\nroute_supplies  = True\ncheck_lvsdrc    = False\n\noutput_path     = \"SRAM_32x128_1rw\"\noutput_name     = \"SRAM_32x128_1rw\"\ninstance_name   = \"SRAM_32x128_1rw\"\n</code></pre> <p>In this example, we are generating a single-ported SRAM which has 128 rows and 32 bits per row for a total capacity of 4096 bits or 512B. This size is probably near the cross-over point where you might transition from using synthesized memories to SRAM macros. OpenRAM will take this configuration file as input and generate many different views of the SRAM macro including: schematics (<code>.sp</code>), layout (<code>.gds</code>), a Verilog behavioral model (<code>.v</code>), abstract logical, timing, power view (<code>.lib</code>), and a physical view (<code>.lef</code>). These views can then be used by the ASIC tools.</p> <p>You can use the following command to run the OpenRAM memory generator.</p> <pre><code>% cd -p $TOPDIR/openram\n% openram -v -v SRAM_32x128_1rw_cfg.py\n</code></pre> <p>It will take about 4-5 minutes to generate the SRAM macro. You can see the resulting views here:</p> <pre><code>% cd $TOPDIR/openram/SRAM_32x128_1rw\n% ls -1\nSRAM_32x128_1rw.v\nSRAM_32x128_1rw.sp\nSRAM_32x128_1rw.gds\nSRAM_32x128_1rw.lef\nSRAM_32x128_1rw_TT_1p1V_25C.lib\nSRAM_32x128_1rw.html\n</code></pre> <p>You can find more information about the OpenRAM memory generator on the project's webpage here:</p> <ul> <li>https://openram.org</li> </ul> <p>Or in this research paper:</p> <ul> <li>M. Guthaus et. al, \"OpenRAM: An Open-Source Memory Compiler\", Int'l    Conf. on Computer-Aided Design (ICCAD), Nov. 2016.    (https://doi.org/10.1145/2966986.2980098)</li> </ul> <p>The following excerpt from the paper illustrates the microarchitecture used in the single-port SRAM macro in the original OpenRAM implementation.</p> <p></p> <p>The functionality of the pins are as follows:</p> <ul> <li><code>clk</code>: clock</li> <li><code>WEb</code>: write enable (active low)</li> <li><code>OEb</code>: output enable (active low)</li> <li><code>CSb</code>: whole SRAM enable (active low)</li> <li><code>ADDR</code>: address</li> <li><code>DATA</code>: read/write data</li> </ul> <p>Notice that there is a single address, and a single read/write data bus. In the new version of OpenRAM that we are currently using, this has been changed to use a separate read data and write data bus. However, this SRAM macro still only supports executing a single transaction at a time. The new version of OpenRAM has also removed the output enable control signal. The diagram shows a bank select which is used when a single SRAM macro is built out of multiple lower-level \"physical banks\" to produce a more efficient layout (by means of reducing the length of bitlines and wordlines, hence improving delay and energy efficiency). To achieve similar results, we instead use a column muxing factor, which allows us to read multiple lines and select the data we want via a MUX, hence also creating a more efficient layout. We will see what the column muxing looks like a little later in the tutorial.</p> <p>The following excerpt from the paper shows the timing diagram for a read and write transaction in the old OpenRAM implementation, which for the most part holds for the most recent version.</p> <p></p> <p>In order to execute any kind of transaction in the SRAM, we need to set the <code>CSb</code> pin low (note that <code>CSb</code> is active low). Let's start by focusing on the read transaction shown on the left. For the read transaction on the left, the <code>WEb</code> pin is set high (note that <code>WEB</code> is active low). The <code>ADDR</code> pins are used to set the row address. Note that this is a row address not a byte address. From the block diagram, we can see that the address first goes into the \"Address MS-Flop\". This is an array of flip-flops which store the address on the rising edge of the clock. After the rising edge, the address is decoded to drive the word lines and enable the desired row. The read data is driven from the bit cell array through the column muxing and into the sense amp array. The <code>OEb</code> pin was used to determine whether the read data should be driven onto the data bus. This can enable multiple SRAM macros to be arranged on a distributed bus with only one SRAM driving that bus on any given cycle. The <code>OEb</code> pin has since been removed in OpenRAM, and its functionality was tied to the <code>CSb</code> pin. Assuming <code>CSb</code> is low, then the read data is driven out the <code>DATA</code> pins. Since we set the address before the edge and the data is valid after the edge, this is a synchronous read SRAM. Compare this to a register file which often provides a combinational read where the address is set and the data is valid sometime later during the same cycle. Most SRAM generators produce synchronous read SRAM macros. For the write transaction on the right, the <code>WEb</code> pin is set low and the <code>DATA</code> pins are driven with the write data.</p> <p>You can look at the behavioral Verilog produced by the OpenRAM memory generator like this:</p> <pre><code>% cd $TOPDIR/openram/SRAM_32x128_1rw\n% less SRAM_32x128_1rw.v\n</code></pre> <p>The Verilog file should look like this:</p> <pre><code>module SRAM_32x128_1rw(\n    clk0,csb0,web0,wmask0,addr0,din0,dout0\n  );\n\n  parameter NUM_WMASKS = 4 ;\n  parameter DATA_WIDTH = 32 ;\n  parameter ADDR_WIDTH = 7 ;\n  parameter RAM_DEPTH = 1 &lt;&lt; ADDR_WIDTH;\n  // FIXME: This delay is arbitrary.\n  parameter DELAY = 3 ;\n  parameter VERBOSE = 0 ; //Set to 0 to only display warnings\n  parameter T_HOLD = 1 ; //Delay to hold dout value after posedge. Value is arbitrary\n\n  input  clk0; // clock\n  input   csb0; // active low chip select\n  input  web0; // active low write control\n  input [ADDR_WIDTH-1:0]  addr0;\n  input [NUM_WMASKS-1:0]   wmask0; // write mask\n  input [DATA_WIDTH-1:0]  din0;\n  output [DATA_WIDTH-1:0] dout0;\n\n  reg [DATA_WIDTH-1:0]    mem [0:RAM_DEPTH-1];\n\n  reg  csb0_reg;\n  reg  web0_reg;\n  reg [NUM_WMASKS-1:0]   wmask0_reg;\n  reg [ADDR_WIDTH-1:0]  addr0_reg;\n  reg [DATA_WIDTH-1:0]  din0_reg;\n  reg [DATA_WIDTH-1:0]  dout0;\n\n  // All inputs are registers\n  always @(posedge clk0)\n  begin\n    csb0_reg &lt;= csb0;\n    web0_reg &lt;= web0;\n    wmask0_reg &lt;= wmask0;\n    addr0_reg &lt;= addr0;\n    din0_reg &lt;= din0;\n    dout0 &lt;= 32'bx;\n    if ( !csb0_reg &amp;&amp; web0_reg &amp;&amp; VERBOSE )\n      $display($time,\" Reading %m addr0=%b dout0=%b\",addr0_reg,mem[addr0_reg]);\n    if ( !csb0_reg &amp;&amp; !web0_reg &amp;&amp; VERBOSE )\n      $display($time,\" Writing %m addr0=%b din0=%b wmask0=%b\",addr0_reg,din0_reg,wmask0_reg);\n  end\n\n  // Memory Write Block Port 0\n  // Write Operation : When web0 = 0, csb0 = 0\n  always @ (negedge clk0)\n  begin : MEM_WRITE0\n    if ( !csb0_reg &amp;&amp; !web0_reg ) begin\n        if (wmask0_reg[0])\n                mem[addr0_reg][7:0] &lt;= din0_reg[7:0];\n        if (wmask0_reg[1])\n                mem[addr0_reg][15:8] &lt;= din0_reg[15:8];\n        if (wmask0_reg[2])\n                mem[addr0_reg][23:16] &lt;= din0_reg[23:16];\n        if (wmask0_reg[3])\n                mem[addr0_reg][31:24] &lt;= din0_reg[31:24];\n    end\n  end\n\n  // Memory Read Block Port 0\n  // Read Operation : When web0 = 1, csb0 = 0\n  always @ (negedge clk0)\n  begin : MEM_READ0\n    if (!csb0_reg &amp;&amp; web0_reg)\n       dout0 &lt;= mem[addr0_reg];\n  end\n\nendmodule\n</code></pre> <p>This is a simple behavior Verilog model which could be used for RTL or gate-level simulation. If you study this behavioral model you should be able to see the timing diagrams it implements, and the slight variations from the original OpenRAM implementation described in the paper. Again, notice that all inputs are registered on the positive edge, and the read operation is modeled using an <code>always @(negedge clk)</code> block to reflect the fact that this SRAM uses a sequential read based on the clock.</p> <p>You can take a look at the generated transistor-level netlist like this:</p> <pre><code>% cd $TOPDIR/openram/SRAM_32x128_1rw\n% less -p \" cell_1rw \" SRAM_32x128_1rw.sp\n</code></pre> <p>The netlist for the bitcell should look like this:</p> <pre><code>.SUBCKT cell_1rw bl br wl vdd gnd\n * Inverter 1\n MM0 Q_bar Q gnd gnd NMOS_VTG W=205.00n L=50n\n MM4 Q_bar Q vdd vdd PMOS_VTG W=90n     L=50n\n\n * Inverter 2\n MM1 Q Q_bar gnd gnd NMOS_VTG W=205.00n L=50n\n MM5 Q Q_bar vdd vdd PMOS_VTG W=90n     L=50n\n\n * Access transistors\n MM3 bl wl Q gnd NMOS_VTG W=135.00n L=50n\n MM2 br wl Q_bar gnd NMOS_VTG W=135.00n L=50n\n.ENDS cell_1rw\n</code></pre> <p>This is showing the netlist for one bitcell in the SRAM. This is a classic 6T SRAM bitcell with two cross-coupled inverters (<code>MM0</code>, <code>MM4</code>, <code>MM1</code>, <code>MM5</code>) and two access transistors (<code>MM2</code>, <code>MM3</code>). Note that the transistors must be carefully sized to ensure correct operation of an SRAM bitcell!</p> <p>Now let's use Klayout look at the actual layout produced by the OpenRAM memory generator.</p> <pre><code>% cd $TOPDIR/openram/SRAM_32x128_1rw\n% klayout -l $ECE6745_STDCELLS/klayout.lyp SRAM_32x128_1rw.gds\n</code></pre> <p>The following figure shows the layout for the SRAM macro. In Klayout, you can show/hide layers by double clicking on them on the right panel. You can show more of the hierarchy by selecting Display &gt; Increment Hierarchy from the menu.</p> <p></p> <p>Use a ruler in Klayout to measure the height and width of the SRAM macro. It should be about 140um wide by 75um tall.</p> <p>On the left we have flops for the row addresses, which are then fed into a decoder. The decoder activates a certain wordline driver, which will then read out the data through the circuitry below (with the column muxing and sense amps shown in more detail in the following image). Also note that in the above image, the circuitry at the bottom are the flops for the read data.</p> <p>Notice how at the bottom of the SRAM, above the data flops, we have circuitry distributed every four rows of the SRAM. This is the column muxing circuitry that we added in our configuration file and mentioned previously. The following figure shows a closer look at this column muxing circuitry and the sense amps.</p> <p></p> <p>The following figure shows the layout for a single SRAM bitcell.</p> <p></p> <p>The word line is routed horizontally on M1 (blue) and the bit lines are routed vertically on M2 (green). It looks like power and ground are routed both vertically and horizontally. See if you can map the layout to the canonical 6T SRAM bitcell transistor-level implementation.</p> <p>Let\u2019s look at snippet of the <code>.lib</code> file for the SRAM macro.</p> <pre><code>% cd $TOPDIR/openram/SRAM_32x128_1rw\n% less SRAM_32x128_1rw_TT_1p1V_25C.lib\n</code></pre> <p>The <code>.lib</code> should look like this:</p> <pre><code> cell (SRAM_32x128_1rw) {\n   ...\n   area : 10711.8116;\n   ...\n   bus (dout0) {\n     bus_type        : data;\n     direction       : output;\n     max_capacitance : 0.0008364000000000001;\n     min_capacitance : 5.2275000000000003e-05;\n     memory_read() {\n       address : addr0;\n     }\n     pin(dout0[31:0]) {\n       timing(){\n         timing_sense : non_unate;\n         related_pin  : \"clk0\";\n         timing_type  : falling_edge;\n         cell_rise(CELL_TABLE) {\n           values(\"0.293, 0.293, 0.294\",\\\n                  \"0.293, 0.293, 0.294\",\\\n                  \"0.293, 0.293, 0.294\");\n         }\n         cell_fall(CELL_TABLE) {\n           values(\"0.293, 0.293, 0.294\",\\\n                  \"0.293, 0.293, 0.294\",\\\n                  \"0.293, 0.293, 0.294\");\n         }\n         rise_transition(CELL_TABLE) {\n           values(\"0.001, 0.001, 0.001\",\\\n                  \"0.001, 0.001, 0.001\",\\\n                  \"0.001, 0.001, 0.001\");\n         }\n         fall_transition(CELL_TABLE) {\n           values(\"0.001, 0.001, 0.001\",\\\n                  \"0.001, 0.001, 0.001\",\\\n                  \"0.001, 0.001, 0.001\");\n         }\n       }\n     }\n   }\n   ...\n }\n</code></pre> <p>As with the standard-cell library, the <code>.lib</code> includes information about the area of the block, the capacitance on all pins, and power of the circuit. By default OpenRAM will use analytical models to estimate this characterization data which is probably why the timing values are not varying too much within a look-up table. OpenRAM can also use SPICE simulations to estimate this characterization data. These simulations will result in the memory compiler taking significantly longer to generate the SRAM macros, but will also result in much more accurate characterization data.</p> <p>The <code>.lef</code> file will mostly contain large rectangular blockages which mean that the ASIC tools should not route any M1, M2, M3 wires over the SRAM (because they would accidentally create short circuits with the M1, M2, M3 wires already in the SRAM macro). The <code>.lef</code> file also identifies where all of the pins are physically located so the ASIC tools can correctly connect to the SRAM macro.</p>"},{"location":"ece6745-tut10-sram/#2-srams-rtl-models","title":"2. SRAMs RTL Models","text":"<p>Now that we understand how an SRAM generator works, let's see how to actually use an SRAM in your RTL models. Our basic SRAMs are located in the <code>sim/sram</code> subdirectory.</p> <pre><code>% cd $TOPDIR/sim/sram\n% ls\n...\nSRAM_generic.v\nSRAM.v\n</code></pre> <p>Take a look the interface of the SRAM in <code>SRAM.v</code>.</p> <pre><code>module sram_SRAM\n#(\n  parameter p_data_nbits  = 32,\n  parameter p_num_entries = 256,\n\n  // Local constants not meant to be set from outside the module\n  parameter c_addr_nbits  = $clog2(p_num_entries),\n  parameter c_data_nbytes = (p_data_nbits+7)/8 // $ceil(p_data_nbits/8)\n)(\n  input  logic                        clk,\n  input  logic                        reset,\n  input  logic                        port0_val,\n  input  logic                        port0_type,\n  input  logic [c_addr_nbits-1:0]     port0_idx,\n  input  logic [(p_data_nbits/8)-1:0] port0_wben,\n  input  logic [p_data_nbits-1:0]     port0_wdata,\n  output logic [p_data_nbits-1:0]     port0_rdata\n);\n</code></pre> <p>The SRAM model is parameterized by the number of words and the bits per word, and has the following pin-level interface:</p> <ul> <li><code>port0_val</code>: port enable</li> <li><code>port0_type</code>: transaction type (0 = read, 1 = write)</li> <li><code>port0_idx</code>: which row to read/write</li> <li><code>port0_wben</code>: write byte enables</li> <li><code>port0_wdata</code>: write data</li> <li><code>port0_rdata</code>: read data</li> </ul> <p>Now look at the implementation of the SRAM. You will see a generate if statement which uses the parameters to either: (1) instantiate an SRAM macro RTL model or (2) instantiate an SRAM generic RTL model. Although you can instantiate an SRAM with any number of words and bits per word, this SRAM will only result in a real SRAM macro if these parameters match one of the existing SRAM macros in the generate statement. If the parameters do not match one of the existing SRAM macros, then the SRAM RTL model will still behave correctly in simulation but will result in synthesizing the memory out of flip-flops. Note that it is critical that the name of any specific SRAM macro matches the exact name generated by OpenRAM.</p>"},{"location":"ece6745-tut10-sram/#21-testing-existing-sram-rtl-models","title":"2.1. Testing Existing SRAM RTL Models","text":"<p>Let's test an SRAM with 256 words and 32 bits per word. You can see the corresponding test case in <code>SRAM_test.py</code>.</p> <pre><code>% cd $TOPDIR/sim/sram/test\n% cat SRAM_test.py\n</code></pre> <p>The test case should look as follows.</p> <pre><code>def test_direct_32x256( cmdline_opts ):\n  run_test_vector_sim( SRAM(32, 256), [ header_str,\n    # val type idx  wben    wdata       rdata\n    [ 1,  1,  0x00, 0b1111, 0x00000000, '?'        ], # write 0x00\n    [ 1,  0,  0x00, 0b1111, 0x00000000, '?'        ], # read  0x00\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0x00000000 ], # check read data\n    [ 1,  1,  0x00, 0b1111, 0xdeadbeef, '?'        ], # write 0x00\n    [ 1,  0,  0x00, 0b1111, 0x00000000, '?'        ], # read  0x00\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0xdeadbeef ], # check read data\n    [ 1,  1,  0x01, 0b1111, 0xcafecafe, '?'        ], # write 0x01\n    [ 1,  0,  0x01, 0b1111, 0x00000000, '?'        ], # read  0x01\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0xcafecafe ], # check read data\n    [ 1,  1,  0x1f, 0b1111, 0x0a0a0a0a, '?'        ], # write 0x1f\n    [ 1,  0,  0x1f, 0b1111, 0x00000000, '?'        ], # read  0x1f\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0x0a0a0a0a ], # check read data\n...\n]```\n\nEach row represents the inputs and expected outputs for that cycle. In\nthe first cycle, we write 0x00000000 to address 0x00. In the second\ncycle, we read address 0x00. In the first cycle, we check to ensure the\nread data is correct. Since the SRAM supports synchronous read, the read\ndata is returned the cycle _after_ we specify the read address! Let's run\nthe tests for this SRAM.\n\n```bash\n% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_direct_32x256 -s\n</code></pre> <p>You can run the random test like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_random[32-256] -s\n</code></pre>"},{"location":"ece6745-tut10-sram/#22-adding-a-new-sram-rtl-model","title":"2.2. Adding a New SRAM RTL Model","text":"<p>As mentioned above, the SRAM module is parameterized to enable initial design space exploration, but just because we choose a specific SRAM configuration does not mean the files we need to create the corresponding SRAM macro exist yet. Once we have finalized the SRAM size, we need to go through a five step process to ensure we can run OpenRAM and generate the corresponding SRAM macro.</p> <p>Step 1: See if SRAM configuration already exists</p> <p>The first step is to see if your desired SRAM configuration already exists. You can do this by looking at the names of the <code>_cfg.py</code> files in the <code>sim/sram</code> subdirectory.</p> <pre><code>% cd $TOPDIR/sim/sram\n% ls *_cfg.py\nSRAM_128x256_1rw-cfg.py\nSRAM_32x256_1rw-cfg.py\n</code></pre> <p>This means there are two SRAM configurations already available. One SRAM has 256 words each with 128 bits and the other SRAM has 256 words each with 32 bits. If the SRAM configuration you need already exists then you are done and can skip the remaining steps.</p> <p>Step 2: Create SRAM configuration file</p> <p>The next step is to create a new SRAM configuration file. You must use a very specific naming scheme. An SRAM with <code>N</code> words and <code>M</code> bits per word must be named <code>SRAM_MxN_1rw_cfg.py</code>. Go ahead and create a new SRAM configuration file named <code>SRAM_32x128_1rw_cfg.py</code>.</p> <pre><code>% cd $TOPDIR/sim/sram\n% code SRAM_32x128_1rw-cfg.py\n</code></pre> <p>The SRAM configuration file should contain the following contents:</p> <pre><code>use_conda       = False\n\nnum_rw_ports    = 1\nnum_r_ports     = 0\nnum_w_ports     = 0\n\nword_size       = 32\nnum_words       = 128\nnum_banks       = 1\nwords_per_row   = 4\nwrite_size      = 8\n\ntech_name       = \"freepdk45\"\nprocess_corners = [\"TT\"]\nsupply_voltages = [1.1]\ntemperatures    = [25]\n\nroute_supplies  = True\ncheck_lvsdrc    = False\n\noutput_path     = \"SRAM_32x128_1rw\"\noutput_name     = \"SRAM_32x128_1rw\"\ninstance_name   = \"SRAM_32x128_1rw\"\n</code></pre> <p>Step 3: Create an SRAM macro RTL model</p> <p>The next step is to create an SRAM macro RTL model. This new RTL model should have the same name as the configuration file except with <code>.v</code> instead of <code>_cfg.py</code>. You can use the SRAM generic RTL model to implement the SRAM macro RTL model. Go ahead and create an SRAM macro RTL model for the 32x128 configuration.</p> <pre><code>% cd $TOPDIR/sim/sram\n% code SRAM_32x128_1rw.v\n</code></pre> <p>The SRAM macro RTL model should contain the following contents.</p> <pre><code>`ifndef SRAM_32x128_1rw\n`define SRAM_32x128_1rw\n\n`include \"sram/SramGenericVRTL.v\"\n\n`ifndef SYNTHESIS\n\nmodule SRAM_32x128_1rw\n(\n  input  logic        clk0,\n  input  logic        web0,\n  input  logic        csb0,\n  input  logic [3:0]  wmask0,\n  input  logic [6:0]  addr0,\n  input  logic [31:0] din0,\n  output logic [31:0] dout0\n);\n\n  sram_SRAM_generic\n  #(\n    .p_data_nbits  (32),\n    .p_num_entries (128)\n  )\n  sram_generic\n  (\n    .clk0   (clk0),\n    .web0   (web0),\n    .csb0   (csb0),\n    .wmask0 (wmask0),\n    .addr0  (addr0),\n    .din0   (din0),\n    .dout0  (dout0)\n  );\n\nendmodule\n\n`endif /* SYNTHESIS */\n\n`endif /* SRAM_32x128_1rw */\n</code></pre> <p>Notice how this is simply a wrapper around <code>sram_SRAM_generic</code> instantiated with the desired number of words and bits per word.</p> <p>Step 4: Use new SRAM macro RTL model in top-level SRAM model</p> <p>The final step is to modify the top-level SRAM model to select the proper SRAM macro RTL model. You will need to modify <code>SRAM.v</code>.</p> <pre><code>% cd $TOPDIR/sim/sram\n% code SRAM.v\n</code></pre> <p>You need to add a new condition to the generate if statement as follows.</p> <pre><code>// Add this at the top of the file\n`include \"sram/SRAM_32x128_1rw.v\"\n\n...\n\n  generate\n    if      ( p_data_nbits == 32  &amp;&amp; p_num_entries == 256 ) SRAM_32x256_1rw  sram (.*);\n    else if ( p_data_nbits == 128 &amp;&amp; p_num_entries == 256 ) SRAM_128x256_1rw sram (.*);\n\n    // Add the following to choose a new SRAM configuration RTL model\n    else if ( p_data_nbits == 32  &amp;&amp; p_num_entries == 128 ) SRAM_32x128_1rw  sram (.*);\n\n    else\n      sram_SRAM_generic#(p_data_nbits,p_num_entries) sram (.*);\n  endgenerate\n</code></pre> <p>One might ask what is the point of going through all of the trouble of creating an SRAM macro RTL model that is for a specific size if we already have a SRAM generic RTL model. The key reason is that the ASIC flow will use the name of the SRAM to figure out where to swap in the SRAM macro. So we need a explicit module name for every different SRAM configuration to enable using SRAM macros in the ASIC flow.</p> <p>Step 5: Test new SRAM configuration</p> <p>The final step is to test the new configuration and verify everything works. We start by adding a simple directed test to the <code>SRAM_test.py</code> test script. Here is an example:</p> <pre><code>def test_direct_32x128( cmdline_opts ):\n  run_test_vector_sim( SRAM(32, 128), [ header_str,\n    # val type idx  wben    wdata       rdata\n    [ 1,  1,  0x00, 0b1111, 0x00000000, '?'        ], # one at a time\n    [ 1,  0,  0x00, 0b1111, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0x00000000 ],\n    [ 1,  1,  0x00, 0b1111, 0xdeadbeef, '?'        ],\n    [ 1,  0,  0x00, 0b1111, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0xdeadbeef ],\n    [ 1,  1,  0x01, 0b1111, 0xcafecafe, '?'        ],\n    [ 1,  0,  0x01, 0b1111, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0xcafecafe ],\n    [ 1,  1,  0x1f, 0b1111, 0x0a0a0a0a, '?'        ],\n    [ 1,  0,  0x1f, 0b1111, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0x0a0a0a0a ],\n\n    [ 1,  1,  0x1e, 0b1111, 0x0b0b0b0b, '?'        ], # streaming reads\n    [ 1,  0,  0x1e, 0b1111, 0x00000000, '?'        ],\n    [ 1,  0,  0x1f, 0b1111, 0x00000000, 0x0b0b0b0b ],\n    [ 1,  0,  0x01, 0b1111, 0x00000000, 0x0a0a0a0a ],\n    [ 1,  0,  0x00, 0b1111, 0x00000000, 0xcafecafe ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0xdeadbeef ],\n\n    [ 1,  1,  0x1d, 0b1111, 0x0c0c0c0c, '?'        ], # streaming writes/reads\n    [ 1,  0,  0x1d, 0b1111, 0x00000000, '?'        ],\n    [ 1,  1,  0x1c, 0b1111, 0x0d0d0d0d, 0x0c0c0c0c ],\n    [ 1,  0,  0x1c, 0b1111, 0x00000000, '?'        ],\n    [ 1,  1,  0x1b, 0b1111, 0x0e0e0e0e, 0x0d0d0d0d ],\n    [ 1,  0,  0x1b, 0b1111, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b1111, 0x00000000, 0x0e0e0e0e ],\n\n    [ 1,  1,  0x00, 0b1111, 0x00000000, '?'        ], # partial writes\n    [ 1,  1,  0x01, 0b1111, 0x00000000, '?'        ],\n    [ 1,  1,  0x0f, 0b1111, 0x00000000, '?'        ],\n    [ 1,  1,  0x00, 0b0001, 0xdeadbeef, '?'        ],\n    [ 1,  0,  0x00, 0b0000, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b0000, 0x00000000, 0x000000ef ],\n    [ 1,  1,  0x01, 0b0100, 0xcafecafe, '?'        ],\n    [ 1,  0,  0x01, 0b0000, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b0000, 0x00000000, 0x00fe0000 ],\n    [ 1,  1,  0x0f, 0b0000, 0x0a0a0a0a, '?'        ],\n    [ 1,  0,  0x0f, 0b0000, 0x00000000, '?'        ],\n    [ 0,  0,  0x00, 0b0000, 0x00000000, 0x00000000 ],\n  ], cmdline_opts )\n</code></pre> <p>This directed test writes a value to a specific word and then reads that word to verify the value was written correctly. We test writing the first word, the last word, and other words. We also test using the write byte enables for partial writes. We can run the directed test like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_direct_32x128\n</code></pre> <p>We have included a helper function that simplifies random testing. All you need to do is add the configuration to the <code>sram_configs</code> variable in the test script like this:</p> <pre><code>sram_configs = [ (16, 32), (32, 256), (128, 256), (32, 128) ]\n</code></pre> <p>Then you can run the random test like this:</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../sram/test/SRAM_test.py -k test_random[32-128]\n</code></pre> <p>And of course we should run all of the tests to ensure we haven't broken anything when adding this new configuration.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../sram\n</code></pre>"},{"location":"ece6745-tut10-sram/#3-sram-minion-wrapper-rtl","title":"3. SRAM Minion Wrapper RTL","text":"<p>SRAMs use a latency sensitive interface meaning a user must carefully manage the timing for correct operation (i.e., set the read address and then exactly one cycle later use the read data). In addition, the SRAM cannot be \"stalled\". To illustrate how to use SRAM macros, we will create a latency insensitive val/rdy wrapper around an SRAM which enables writing and reading the SRAM using our standard memory messages. The following figure illustrates a naive approach to implementing the SRAM val/rdy wrapper.</p> <p></p> <p>Consider what might happen if we use a single-element bypass queue. The following pipeline diagram illustrates what can go wrong.</p> <pre><code> cycle : 0  1  2  3  4  5  6  7  8\n msg a : M0 Mx\n msg b :    M0 Mx\n msg c :       M0 M1 M2 M2 M2       # M2 stalls on cycles 3-5\n msg d :          M0 M1 M1 M1 M2    # but wait, we cannot stall in M1!\n msg e :             M0 M0 M0 M0 Mx\n\n cycle M0 M1 [q] M2\n    0: a\n    1: b  a      a  # a flows through bypass queue\n    2: c  b      b  # b flows through bypass queue\n    3: d  c         # M2 is stalled, c will need to go into bypq\n    4: e  d   c     # q is full at beginning of cycle, enq_rdy = 0\n    5: e  ?   c     # what happens to d? cannot stall in M1!\n</code></pre> <p>Here we are using Mx to indicate when a transaction goes through M1 and M2 in the same cycle because it flows straight through the bypass queue. So on cycle 3, the response interface is stalled and as a consequence message c must be enqueued into the memory response queue. On cycle 4, the response queue is full (<code>enq_rdy</code> = 0) so <code>memreq_rdy</code> = 0 and message e will stall in M0 (i.e., will stall waiting to be accepted by the SRAM wrapper). The critical question is what happens to message d? It cannot stall in M1 because we cannot stall the SRAM. So basically we just drop it. Increasing the amount of the buffering in the bypass queue will not solve the problem. The key issue is that by the time we realize the bypass queue is full we can potentially already have a transaction executing in the SRAM, and this transaction cannot be stalled.</p> <p>This is a classic situation where the need more skid buffering. A correct solution will have two or more elements of buffering in the memory response queue and stall M0 if there are less than two free elements in the queue. Thus in the worst case, if M2 stalls we have room for two messages in the response queue: the message currently in M1 and the message currently in M0. Here is the updated design:</p> <p></p> <p>Here is the updated pipeline diagram.</p> <pre><code> cycle : 0  1  2  3  4  5  6  7  8\n msg a : M0 Mx\n msg b :    M0 Mx\n msg c :       M0 M1 M2 M2 M2\n msg d :          M0 M1 q  q  M2     # msg c is in skid buffer\n msg e :             M0 M0 M0 M0 Mx\n\n cycle M0 M1 [q ] M2\n    0: a\n    1: b  a       a  # a flows through bypass queue\n    2: c  b       b  # b flows through bypass queue\n    3: d  c          # M2 is stalled, c will need to go into bypq\n    4: e  d    c     #\n    5: e      dc     # d skids behind c into the bypq\n    6: e       d  c  # c is dequeued from bypq\n    7: e          d  # d is dequeued from bypq\n    8:    e       e  # e flows through bypass queue\n</code></pre> <p>Note, with a pipe queue you still need two elements of buffering. There could be a message in the response queue when M2 stalls and then you still don't have anywhere to put the message currently in M1.</p> <p>Take a closer look at the SRAM val/rdy wrapper we provide you.</p> <pre><code>% cd $TOPDIR/sim/tut8_sram\n% code SRAMMinion.v\n</code></pre> <p>Notice how we are instantiating the SRAM within the SRAM val/rdy wrapper. We are using an SRAM corresponding to the newly created SRAM macro configuration/RTL from the previous section.</p> <pre><code>`include \"sram/SRAM.v\"\n...\nsram_SRAM#(32,128) sram\n (\n   .clk         (clk),\n   .reset       (reset),\n   .port0_idx   (sram_addr_M0),\n   .port0_type  (sram_wen_M0),\n   .port0_val   (sram_en_M0),\n   .port0_wben  (sram_wben_M0),\n   .port0_wdata (memreq_msg_data_M0),\n   .port0_rdata (sram_read_data_M1)\n );\n</code></pre> <p>To use an SRAM, simply import <code>sram/SRAM.v</code>, instantiate the SRAM, and set the number of words and number of bits per word. We can run a test on the SRAM val/rdy wrapper like this:</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut10_sram/test/SRAMMinion_test.py -k random_0_3 -s\n</code></pre> <p>The trace output should look like this:</p> <pre><code> ...\n  3:                           &gt; (  (). ) &gt; .\n  4: wr:00:00000000:0:55fceed9 &gt; (wr(). ) &gt; .\n  5: wr:01:00000004:0:5bec8a7b &gt; (wr()# ) &gt; #\n  6: #                         &gt; (# ()# ) &gt; #\n  7: #                         &gt; (# ()wr) &gt; wr:00:0:0:\n  8: #                         &gt; (# ()# ) &gt; #\n  9: #                         &gt; (# ()# ) &gt; #\n 10: #                         &gt; (# ()# ) &gt; #\n 11: #                         &gt; (# ()wr) &gt; wr:01:0:0:\n 12: wr:02:00000008:0:b1aa20f1 &gt; (wr(). ) &gt; .\n 13: wr:03:0000000c:0:a5b6b6bb &gt; (wr()# ) &gt; #\n 14: #                         &gt; (# ()# ) &gt; #\n 15: #                         &gt; (# ()wr) &gt; wr:02:0:0:\n 16: #                         &gt; (# ()# ) &gt; #\n 17: #                         &gt; (# ()# ) &gt; #\n 18: #                         &gt; (# ()# ) &gt; #\n 19: #                         &gt; (# ()wr) &gt; wr:03:0:0:\n</code></pre> <p>The first write transaction takes a single cycle to go through the SRAM val/rdy wrapper (and is held up in the SRAM), but the SRAM response interface is not ready on cycles 5-6. The second write transaction is still accepted by the SRAM val/rdy wrapper and will end up in the bypass queue, but the third write transaction is stalled because the request interface is not ready. No transactions are lost.</p> <p>Let's now rerun the tests and run the interactive simulator to create the Verilog test benches which we can use for four-state RTL, fast-functional gate-level, and back-annotated gate-level simulation.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut10_sram/test/SRAMMinion_test.py --test-verilog --dump-vtb\n% ../tut10_sram/sram-sim --impl rtl --input random --translate --dump-vtb\n% ls\n...\nSRAMMinion_noparam__pickled.v\n</code></pre> <p>As you can see, the simulator will generate a Verilog file <code>SRAMMinion_noparam__pickled.v</code> which is what we use with the ASIC tools.</p>"},{"location":"ece6745-tut10-sram/#4-asic-front-end-flow-with-sram-macros","title":"4. ASIC Front-End Flow with SRAM Macros","text":"<p>Now we will push our SRAM minion wrapper through the ASIC front-end flow. In this section, we will go through the steps manually. Later in the tutorial we will use the ASIC automated flow.</p>"},{"location":"ece6745-tut10-sram/#41-sram-generation","title":"4.1. SRAM Generation","text":"<p>The first step is to run the OpenRAM memory generator to generate the SRAM macro corresponding to the desired 32x128 configuration.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram/00-openram-memgen\n% cd $TOPDIR/asic/build-tut10-sram/00-openram-memgen\n% openram -v -v ../../../sim/sram/SRAM_32x128_1rw_cfg.py\n% cd SRAM_32x128_1rw\n% cp SRAM_32x128_1rw_TT_1p1V_25C.lib ../SRAM_32x128_1rw.lib\n% cp *.gds *.lef *.v ..\n</code></pre> <p>We need to convert the <code>.lib</code> file into a <code>.db</code> file using the Synopsys Library Compiler (LC) tool.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/00-openram-memgen\n% lc_shell\nlc_shell&gt; read_lib SRAM_32x128_1rw.lib\nlc_shell&gt; write_lib SRAM_32x128_1rw_TT_1p1V_25C_lib \\\n  -format db -output SRAM_32x128_1rw.db\nlc_shell&gt; exit\n</code></pre> <p>Check that the <code>.db</code> file now exists.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/00-openram-memgen\n% ls\n...\nSRAM_32x128_1rw.db\n</code></pre>"},{"location":"ece6745-tut10-sram/#42-four-state-rtl-simulation","title":"4.2. Four-State RTL Simulation","text":"<p>We now need to use four-state RTL simulation to further verify our design.</p> <pre><code>% mkdir -p ${TOPDIR}/asic/build-tut10-sram/01-synopsys-vcs-rtlsim\n% cd ${TOPDIR}/asic/build-tut10-sram/01-synopsys-vcs-rtlsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${TOPDIR}/sim/build/SRAMMinion_noparam__pickled.v \\\n    ${TOPDIR}/sim/build/SRAMMinion_noparam_sram-rtl-random_tb.v\n% ./simv\n</code></pre>"},{"location":"ece6745-tut10-sram/#43-synthesis","title":"4.3. Synthesis","text":"<p>Now we can use Synopsys DC to synthesize the logic which goes around the SRAM macro.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram/02-synopsys-dc-synth\n% cd $TOPDIR/asic/build-tut10-sram/02-synopsys-dc-synth\n% dc_shell-xg-t\ndc_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\ndc_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\ndc_shell&gt; analyze -format sverilog ../../../sim/build/SRAMMinion_noparam__pickled.v\ndc_shell&gt; elaborate SRAMMinion_noparam\ndc_shell&gt; create_clock clk -name ideal_clock1 -period 2.0\ndc_shell&gt; compile\ndc_shell&gt; write -format ddc     -hierarchy -output post-synth.ddc\ndc_shell&gt; write -format verilog -hierarchy -output post-synth.v\ndc_shell&gt; write_sdc post-synth.sdc\ndc_shell&gt; report_area   -hierarchy\ndc_shell&gt; report_timing -nets\ndc_shell&gt; exit\n</code></pre> <p>We are basically using the same steps we used in the Synopsys/Cadence ASIC tool tutorial. Notice how we must point Synopsys DC to the <code>.db</code> file generated by OpenRAM so Synopsys DC knows the abstract logical, timing, power view of the SRAM.</p> <p>If you look for the SRAM module in the synthesized gate-level netlist, you will see that it is referenced but not declared. This is what we expect since we are not synthesizing the memory but instead using an SRAM macro.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/synopsys-dc\n% less -p SRAM post-synth.v\n</code></pre>"},{"location":"ece6745-tut10-sram/#44-fast-functional-gate-level-simulation","title":"4.4. Fast-Functional Gate-Level Simulation","text":"<p>We can use fast-functional gate-level simulation to simulate the gate-level netlist integrated with the Verilog RTL models for the SRAMs.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/03-synopsys-vcs-ffglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +delay_mode_zero \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../00-openram-memgen/SRAM_32x128_1rw.v \\\n    ../02-synopsys-dc-synth/post-synth.v \\\n    ${TOPDIR}/sim/build/SRAMMinion_noparam_sram-rtl-random_tb.v\n% ./simv\n</code></pre> <p>Notice how we now need to provide the Verilog behavioral model for the SRAM which will be simulated along with the gate-level implementation.</p>"},{"location":"ece6745-tut10-sram/#5-asic-back-end-flow-with-sram-macros","title":"5. ASIC Back-End Flow with SRAM Macros","text":"<p>Now we will push our SRAM minion wrapper through the ASIC back-end flow. In this section, we will go through the steps manually. Later in the tutorial we will use the ASIC automated flow.</p>"},{"location":"ece6745-tut10-sram/#51-place-and-route","title":"5.1. Place and Route","text":"<p>We use Cadence Innovus for placing and routing both the standard cells and the SRAM macros. As in the ASIC back-end flow tutorial, we need to create a file to setup the timing analysis.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram/04-cadence-innovus-pnr\n% cd $TOPDIR/asic/build-tut10-sram/04-cadence-innovus-pnr\n% code setup-timing.tcl\n</code></pre> <p>The file should have the following content:</p> <pre><code>create_rc_corner -name typical \\\n   -cap_table \"$env(ECE6745_STDCELLS)/rtk-typical.captable\" \\\n   -T 25\n\ncreate_library_set -name libs_typical \\\n   -timing [list \"$env(ECE6745_STDCELLS)/stdcells.lib\" \\\n                 \"../openram-mc/SRAM_32x128_1rw.lib\"]\n\ncreate_delay_corner -name delay_default \\\n   -library_set libs_typical \\\n   -rc_corner typical\n\ncreate_constraint_mode -name constraints_default \\\n   -sdc_files [list ../02-synopsys-dc-synth/post-synth.sdc]\n\ncreate_analysis_view -name analysis_default \\\n   -constraint_mode constraints_default \\\n   -delay_corner delay_default\n\nset_analysis_view -setup analysis_default -hold  analysis_default\n</code></pre> <p>This is very similar to the <code>setup-timing.tcl</code> file we used in the ASIC back-end flow tutorial, except that we have to include the <code>.lib</code> file generated by OpenRAM.</p> <p>Now let's start Cadence Innovus, load in the design, and complete the power routing just as in the ASIC back-end tutorial.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/04-cadence-innovus-pnr\n% innovus\n</code></pre> <p>The initial setup is very similar to what we used in the ASIC back-end flow tutorial.</p> <pre><code>innovus&gt; set init_mmmc_file \"setup-timing.tcl\"\ninnovus&gt; set init_verilog   \"../02-synopsys-dc-synth/post-synth.v\"\ninnovus&gt; set init_top_cell  \"SRAMMinion_noparam\"\ninnovus&gt; set init_lef_file  \"$env(ECE6745_STDCELLS)/rtk-tech.lef \\\n                            $env(ECE6745_STDCELLS)/stdcells.lef \\\n                            ../00-openram-memgen/SRAM_32x128_1rw.lef\"\ninnovus&gt; set init_pwr_net   {VDD vdd}\ninnovus&gt; set init_gnd_net   {VSS gnd}\n</code></pre> <p>Two key differences from earlier tutorials are: (1) including the <code>.lef</code> file generated by OpenRAM; and (2) including <code>vdd</code> and <code>gnd</code> which are the names of the power nets used in OpenRAM.</p> <p>We are now ready to use the <code>init_design</code> command to read in the verilog, set the design name, setup the timing analysis views, read the technology <code>.lef</code> for layer information, and read the standard cell <code>.lef</code> for physical information about each cell and the SRAM used in the design.</p> <pre><code>innovus&gt; init_design\n</code></pre> <p>We also need to tell Cadence Innovus some additional setup information just like in the ASIC back-end flow tutorial.</p> <pre><code>innovus&gt; setDesignMode -process 45\ninnovus&gt; setDelayCalMode -SIAware false\ninnovus&gt; setOptMode -usefulSkew false\ninnovus&gt; setOptMode -holdTargetSlack 0.010\ninnovus&gt; setOptMode -holdFixingCells {\n           BUF_X1 BUF_X1 BUF_X2 BUF_X4 BUF_X8 BUF_X16 BUF_X32\n         }\n</code></pre> <p>In the earlier tutorials, we used automatic floorplanning which determines the overall dimensions given a target aspect ratio and placement density. We used a target aspect ratio of 1.0 and a placement density of 70%. Because the SRAM macro has an aspect ratio closer to 2:1 we will will need to use a different floorplan. So instead of using automatic floorplanning, we will use a fixed floorplan which uses a specific width and height.</p> <pre><code>innovus&gt; floorPlan -d 175 175 4.0 4.0 4.0 4.0\n</code></pre> <p>From looking at the <code>.gds</code> file for the SRAM earlier in the tutorial, we know that the SRAM is about 140um wide by 75um tall, so we set the height and width of the floorplan to be 175um.</p> <p></p> <p>The next step is to place the design. We first need to add a \"halo\" around all SRAM macros using the <code>addHaloToBlock</code> command. A halo is a way to tell Cadence Innovus not to place any standard cells too close to the SRAM macros. We specify a halo of 4.8um.</p> <pre><code>innovus&gt; addHaloToBlock 4.8 4.8 4.8 4.8 -allMacro\n</code></pre> <p>Now we need to use extra commands to concurrently place the standard cells and the SRAM macro at the same time. For best results, we would need to create a representative power grid so Cadence Innovus can take into account power distribution when automatically placing SRAM macros, but to simplify our flow we can just specify 20% metal 1 power routing density.</p> <pre><code>innovus&gt; set_macro_place_constraint -pg_resource_model {metal1 0.2}\ninnovus&gt; place_design -concurrent_macros\ninnovus&gt; refine_macro_place\n</code></pre> <p>After these steps the macros will be placed in their final positions, but the standard cells are likely not in legal positions. So we now do the final optimized placement.</p> <pre><code>innovus&gt; place_opt_design\n</code></pre> <p>After placing the design we want to automatically place tie hi/lo cells and the IO pins around the perimeter of the floorplan.</p> <pre><code>innovus&gt; addTieHiLo -cell \"LOGIC1_X1 LOGIC0_X1\"\ninnovus&gt; assignIoPins -pin *\n</code></pre> <p>You should be able to see the SRAM macro placed in the middle of the floorplan with the standard cells implementing the pipeline registers, queue, and control logic positioned above and below the SRAM macro.</p> <p></p> <p>In the following close, up the halo is shown in a salmon color. Some of the standard cells placed above the SRAM macro outside the halo.</p> <p></p> <p>The next step is power routing. We need to connect the power/ground pins of both the standard cells and the SRAM macro to the global power/ground nets. We also need to make sure the tie hi/lo cells are connected to the global power/ground nets.</p> <pre><code>innovus&gt; globalNetConnect VDD -type pgpin -pin VDD -all -verbose\ninnovus&gt; globalNetConnect VSS -type pgpin -pin VSS -all -verbose\ninnovus&gt; globalNetConnect VDD -type pgpin -pin vdd -all -verbose\ninnovus&gt; globalNetConnect VSS -type pgpin -pin gnd -all -verbose\ninnovus&gt; globalNetConnect VDD -type tiehi -pin VDD -all -verbose\ninnovus&gt; globalNetConnect VSS -type tielo -pin VSS -all -verbose\n</code></pre> <p>Just as in the previous tutorials, we then route the M1 power rails for the standard cells, create a power ring, and add horizontal/vertical power stripes to create a power grid.</p> <pre><code>innovus&gt; sroute -nets {VDD VSS}\ninnovus&gt; addRing \\\n           -nets {VDD VSS} -width 0.8 -spacing 0.8 \\\n           -layer [list top 9 bottom 9 left 8 right 8]\ninnovus&gt; addStripe \\\n           -nets {VSS VDD} -layer 9 -direction horizontal \\\n           -width 0.8 -spacing 4.8 \\\n           -set_to_set_distance 11.2 -start_offset 2.4\ninnovus&gt; addStripe \\\n           -nets {VSS VDD} -layer 8 -direction vertical \\\n           -width 0.8 -spacing 4.8 \\\n           -set_to_set_distance 11.2 -start_offset 2.4\n</code></pre> <p></p> <p>In the following close up, we have hidden the halo so we can clearly see how the power routing stops the M1 power rails from going through the SRAM macro. You can also see the horizontal VDD and VSS power stripes have vias that connect to the SRAM macro power/ground pins (i.e., connect to the power ring which is inside the SRAM macro).</p> <p></p> <p>The next step is to route the clock tree and do an initial round of fixing setup-time and hold-time violations.</p> <pre><code>innovus&gt; create_ccopt_clock_tree_spec\ninnovus&gt; set_ccopt_property update_io_latency false\ninnovus&gt; ccopt_design -cts\ninnovus&gt; optDesign -postCTS -setup\ninnovus&gt; optDesign -postCTS -hold\n</code></pre> <p></p> <p>The next step is to route the signals, do a final round of fixing setup-time and hold-time violations, and extract the interconnect RC parasitics.</p> <pre><code>innovus&gt; routeDesign\ninnovus&gt; optDesign -postRoute -setup\ninnovus&gt; optDesign -postRoute -hold\ninnovus&gt; extractRC\n</code></pre> <p>In the following close-up, we can see how Cadence Innovus has routed from the standard-cells to the pins on the SRAM macro, but we can also see how Cadence Innovus has routed some nets over top of the SRAM macro on M5. Cadence Innovus will not route any signals on M1, M2, M3, or M4 over the SRAM macro since the SRAM uses these metal layers for internal routing. Cadence Innovus knows to not use these metal layers by looking at the routing blockages in the SRAM macro's <code>.lef</code> file.</p> <p></p> <p>We can now finish up by adding filler cells and running some physical verification checks.</p> <pre><code>innovus&gt; setFillerMode -core {FILLCELL_X4 FILLCELL_X2 FILLCELL_X1}\ninnovus&gt; addFiller\ninnovus&gt; verifyConnectivity\ninnovus&gt; verify_drc\n</code></pre> <p>As in previous tutorials, we output the design, gate-level netlist, interconnect parasitics, timing delays, and the final layout. Notice how we have to include the <code>.gds</code> file for the SRAM macro so it can be merged into the final <code>.gds</code> file.</p> <pre><code>innovus&gt; saveDesign post-pnr.enc\ninnovus&gt; saveNetlist post-pnr.v\ninnovus&gt; rcOut -rc_corner typical -spef post-pnr.spef\ninnovus&gt; write_sdf post-pnr.sdf\ninnovus&gt; streamOut post-pnr.gds \\\n           -merge \"$env(ECE6745_STDCELLS)/stdcells.gds \\\n                   ../00-openram-memgen/SRAM_32x128_1rw.gds\" \\\n           -mapFile \"$env(ECE6745_STDCELLS)/rtk-stream-out.map\"\n</code></pre> <p>We can generate a timing report for the setup-time constraint.</p> <pre><code>innovus&gt; report_timing -late -path_type full_clock -net\n...\nOther End Arrival Time          0.000\n- External Delay                0.050\n+ Phase Shift                   2.000\n= Required Time                 1.950\n- Arrival Time                  1.582\n= Slack Time                    0.368\n     Clock Fall Edge                      1.000\n     = Beginpoint Arrival Time            1.000\n     +-----------------------------------------------------------------------------------------------------------------------------------+\n     |                        Pin             | Edge |               Net               |        Cell        | Delay | Arrival | Required |\n     |                                        |      |                                 |                    |       |  Time   |   Time   |\n     |----------------------------------------+------+---------------------------------+--------------------+-------+---------+----------|\n     | clk[0]                                 |  v   | clk[0]                          |                    |       |   1.000 |    1.368 |\n     | v/CTS_ccl_a_buf_00002/A                |  v   | clk[0]                          | CLKBUF_X3          | 0.001 |   1.001 |    1.369 |\n     | v/CTS_ccl_a_buf_00002/Z                |  v   | v/CTS_2                         | CLKBUF_X3          | 0.036 |   1.037 |    1.405 |\n     | v/sram/genblk1.sram/clk0               |  v   | v/CTS_2                         | SRAM_32x128_1rw    | 0.001 |   1.038 |    1.406 |\n     | v/sram/genblk1.sram/dout0[29]          |  v   | v/sram_read_data_M1[29]         | SRAM_32x128_1rw    | 0.294 |   1.333 |    1.700 |\n     | v/FE_PDC58_sram_read_data_M1_29/A      |  v   | v/sram_read_data_M1[29]         | BUF_X1             | 0.000 |   1.333 |    1.700 |\n     | v/FE_PDC58_sram_read_data_M1_29/Z      |  v   | v/FE_PDN58_sram_read_data_M1_29 | BUF_X1             | 0.022 |   1.354 |    1.722 |\n     | v/FE_OFC34_sram_read_data_M1_29/A      |  v   | v/FE_PDN58_sram_read_data_M1_29 | CLKBUF_X1          | 0.000 |   1.354 |    1.722 |\n     | v/FE_OFC34_sram_read_data_M1_29/Z      |  v   | v/FE_OFN34_sram_read_data_M1_29 | CLKBUF_X1          | 0.030 |   1.385 |    1.752 |\n     | v/FE_OFC3_sram_read_data_M1_29/A       |  v   | v/FE_OFN34_sram_read_data_M1_29 | CLKBUF_X1          | 0.000 |   1.385 |    1.753 |\n     | v/FE_OFC3_sram_read_data_M1_29/Z       |  v   | v/FE_OFN3_sram_read_data_M1_29  | CLKBUF_X1          | 0.049 |   1.434 |    1.801 |\n     | v/U66/A1                               |  v   | v/FE_OFN3_sram_read_data_M1_29  | AND2_X1            | 0.002 |   1.436 |    1.803 |\n     | v/U66/ZN                               |  v   | v/memresp_msg_M1[data][29]      | AND2_X1            | 0.045 |   1.481 |    1.849 |\n     | v/memresp_queue/dpath/bypass_mux/U30/A |  v   | v/memresp_msg_M1[data][29]      | MUX2_X1            | 0.001 |   1.482 |    1.849 |\n     | v/memresp_queue/dpath/bypass_mux/U30/Z |  v   | v/minion_resp_msg_raw[data][29] | MUX2_X1            | 0.057 |   1.539 |    1.906 |\n     | v/U34/A2                               |  v   | v/minion_resp_msg_raw[data][29] | AND2_X1            | 0.000 |   1.539 |    1.906 |\n     | v/U34/ZN                               |  v   | minion_respstream_msg[29]       | AND2_X1            | 0.043 |   1.582 |    1.950 |\n     | minion_respstream_msg[29]              |  v   | minion_respstream_msg[29]       | SRAMMinion_noparam | 0.000 |   1.582 |    1.950 |\n     +-----------------------------------------------------------------------------------------------------------------------------------+\n</code></pre> <p>Here we can see the SRAM macro is on the critical path. The clock constraint is 2ns. The negative edge of the clock is used to trigger the read data, so the path has an initial 1ns arrival time. This means the clock-to-data path must be less than 1ns. We can see it takes approximately 38ps for the top-level clock pin to reach the clock pin on the SRAM macro and then the actual SRAM read requires 294ps which matches what we saw in the <code>.lib</code> file earlier in the tutorial. It takes 249ps for the data to travel from the SRAM read data ports to the top-level response message pin. The critical path takes 582ps which is less than the required 1ns so we meet the setup time constraint.</p> <p>We can also generate a timing report for the hold-time constraint.</p> <pre><code>innovus&gt; report_timing -early -path_type full_clock -net\n...\nOther End Arrival Time          0.037\n+ Hold                          0.001\n+ Phase Shift                   0.000\n= Required Time                 0.038\n  Arrival Time                  0.048\n  Slack Time                    0.010\n     Clock Rise Edge                      0.000\n     + Input Delay                        0.000\n     = Beginpoint Arrival Time            0.000\n     Timing Path:\n     +---------------------------------------------------------------------------------------------------------------------------+\n     |                Pin                | Edge |               Net               |      Cell       | Delay | Arrival | Required |\n     |                                   |      |                                 |                 |       |  Time   |   Time   |\n     |-----------------------------------+------+---------------------------------+-----------------+-------+---------+----------|\n     | minion_reqstream_msg[3]           |  ^   | minion_reqstream_msg[3]         |                 |       |   0.000 |   -0.010 |\n     | FE_PHC87_minion_reqstream_msg_3/A |  ^   | minion_reqstream_msg[3]         | BUF_X1          | 0.000 |   0.000 |   -0.010 |\n     | FE_PHC87_minion_reqstream_msg_3/Z |  ^   | FE_PHN87_minion_reqstream_msg_3 | BUF_X1          | 0.018 |   0.018 |    0.007 |\n     | FE_PHC50_minion_reqstream_msg_3/A |  ^   | FE_PHN87_minion_reqstream_msg_3 | BUF_X1          | 0.000 |   0.018 |    0.007 |\n     | FE_PHC50_minion_reqstream_msg_3/Z |  ^   | FE_PHN50_minion_reqstream_msg_3 | BUF_X1          | 0.030 |   0.048 |    0.037 |\n     | v/sram/genblk1.sram/din0[3]       |  ^   | FE_PHN50_minion_reqstream_msg_3 | SRAM_32x128_1rw | 0.000 |   0.048 |    0.038 |\n     +---------------------------------------------------------------------------------------------------------------------------+\n     Clock Rise Edge                      0.000\n     = Beginpoint Arrival Time            0.000\n     Other End Path:\n     +------------------------------------------------------------------------------------------+\n     |           Pin            | Edge |   Net   |      Cell       | Delay | Arrival | Required |\n     |                          |      |         |                 |       |  Time   |   Time   |\n     |--------------------------+------+---------+-----------------+-------+---------+----------|\n     | clk[0]                   |  ^   | clk[0]  |                 |       |   0.000 |    0.010 |\n     | v/CTS_ccl_a_buf_00002/A  |  ^   | clk[0]  | CLKBUF_X3       | 0.001 |   0.001 |    0.011 |\n     | v/CTS_ccl_a_buf_00002/Z  |  ^   | v/CTS_2 | CLKBUF_X3       | 0.035 |   0.036 |    0.046 |\n     | v/sram/genblk1.sram/clk0 |  ^   | v/CTS_2 | SRAM_32x128_1rw | 0.001 |   0.037 |    0.047 |\n     +------------------------------------------------------------------------------------------+\n</code></pre> <p>Here we can see that Cadence Innovus has inserted buffers from the top-level input pins to the pipeline register to ensure this path meets the hold-time constraint of 1ps for the SRAM macro. The delay from the top-level clock pin to the clock pin on the pipeline register is 37ps and the delay from the top-level input pin to the data pin of the SRAM macro is 48ps. Since 48ps - 37ps = 11ps this path just meets the hold-time constraint of 1ps with 10ps of slack which was the target.</p> <p>We can report the area as well.</p> <pre><code>innovus&gt; report_area\nHinst Name                            Module Name      Inst Count     Area\n--------------------------------------------------------------------------\nSRAMMinion_noparam                                            539  11675.5\n v                                    tut10_sram_SRAMMinion   424  11584.8\n  v/memresp_queue                     vc_Queue_2_48_2         209    627.2\n   v/memresp_queue/ctrl               vc_QueueCtrl_2_2         22     33.7\n    v/memresp_queue/ctrl/deq_ptr_reg  vc_ResetReg_p_nbits1_1    3      6.3\n    v/memresp_queue/ctrl/enq_ptr_reg  vc_ResetReg_p_nbits1_2    3      5.8\n    v/memresp_queue/ctrl/full_reg     vc_ResetReg_p_nbits1_0    5      7.4\n   v/memresp_queue/dpath              vc_QueueDpath_2_48_2    187    593.4\n    v/memresp_queue/dpath/bypass_mux  vc_Mux2_p_nbits48        45     83.7\n    v/memresp_queue/dpath/qstore      vc_Regfile_1r1w         142    509.6\n  v/sram                              sram_SRAM                38  10740.8\n</code></pre> <p>As expected over 90% of the area is in the SRAM with less than 10% in the pipeline registers, queues, and control logic.</p> <pre><code>innovus&gt; exit\n</code></pre> <p>And now we can use Klayout to look at the final integrated layout.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/04-cadence-innovus-pnr\n% klayout -l $ECE6745_STDCELLS/klayout.lyp post-pnr.gds\n</code></pre> <p></p> <p>In the following close-up we can see the SRAM bitcell array in the upper right-hand corner along with the SRAM address decoder and SRAM column muxing and sense amps. We can see a row of flip-flops which are part of the SRAM macro and at the bottom we can see a few of the standard cells used for the response queue where they connect to the data pins of the SRAM macro.</p> <p></p>"},{"location":"ece6745-tut10-sram/#52-back-annotated-gate-level-simulation-with-sram-macros","title":"5.2. Back-Annotated Gate-Level Simulation with SRAM Macros","text":"<p>Now that we have finished the place-and-route step, we need to use back-annotated gate-level simulation to verify that the final design still passes all of our tests.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram/05-synopsys-vcs-baglsim\n% cd $TOPDIR/asic/build-tut10-sram/05-synopsys-vcs-baglsim\n% vcs -sverilog -xprop=tmerge -override_timescale=1ns/1ps -top Top \\\n    +neg_tchk +sdfverbose \\\n    -sdf max:Top.DUT:../04-cadence-innovus-pnr/post-pnr.sdf \\\n    +define+CYCLE_TIME=2.000 \\\n    +define+VTB_INPUT_DELAY=0.025 \\\n    +define+VTB_OUTPUT_DELAY=0.025 \\\n    +define+VTB_DUMP_SAIF=waves.saif \\\n    +vcs+dumpvars+waves.vcd \\\n    +incdir+${TOPDIR}/sim/build \\\n    ${ECE6745_STDCELLS}/stdcells.v \\\n    ../00-openram-memgen/SRAM_32x128_1rw.v \\\n    ../04-cadence-innovus-pnr/post-pnr.v \\\n    ${TOPDIR}/sim/build/SRAMMinion_noparam_sram-rtl-random_tb.v\n% ./simv\n</code></pre> <p>Let's open-up the waveforms using Surfer and verify that the clock-to-data delay for the SRAM is about 300ps.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram/05-synopsys-vcs-baglsim\n% code waves.vcd\n</code></pre> <p>The following close-up shows the clock-to-data delay is indeed about 300ps.</p> <p></p>"},{"location":"ece6745-tut10-sram/#53-power-analysis-with-sram-macros","title":"5.3. Power Analysis with SRAM Macros","text":"<p>Now we can use Synopsys PrimeTime (PT) for power analysis.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram/06-synopsys-pt-pwr\n% cd $TOPDIR/asic/build-tut10-sram/06-synopsys-pt-pwr\n% pt_shell\n</code></pre> <p>The initial setup similar to the previous tutorials, except we need to provide Synopsys PT the <code>.db</code> files for the SRAM macro.</p> <pre><code>pt_shell&gt; set_app_var target_library \"$env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\npt_shell&gt; set_app_var link_library   \"* $env(ECE6745_STDCELLS)/stdcells.db ../00-openram-memgen/SRAM_32x128_1rw.db\"\npt_shell&gt; set_app_var power_enable_analysis true\n</code></pre> <p>We then read in the post-pnr gate-level netlist, the <code>.saif</code> file with the activity factors from back-annotated gate-level simulation, and the <code>.spef</code> file with the interconnect parasitics.</p> <pre><code>pt_shell&gt; read_verilog ../04-cadence-innovus-pnr/post-pnr.v\npt_shell&gt; current_design SRAMMinion_noparam\npt_shell&gt; link_design\npt_shell&gt; read_saif ../05-synopsys-vcs-baglsim/waves.saif -strip_path Top/DUT\npt_shell&gt; read_parasitics -format spef ../04-cadence-innovus-pnr/post-pnr.spef\n</code></pre> <p>Finally, we create the clock and perform the power analysis.</p> <pre><code>pt_shell&gt; create_clock clk -name ideal_clock1 -period 2.000\npt_shell&gt; update_power\npt_shell&gt; report_power\npt_shell&gt; report_power -hierarchy\n</code></pre>"},{"location":"ece6745-tut10-sram/#6-asic-automated-flow-with-sram-macros","title":"6. ASIC Automated Flow with SRAM Macros","text":"<p>Manually entering commands is a great way to understand how the tools work but is also tedious and error prone. The ASIC automated flow includes support for using OpenRAM to generate SRAMs. We just need to specify a list of SRAM macros we want to use in the YAML design file. Take a look at the following YAML design file:</p> <pre><code>% cd $TOPDIR/asic/designs\n% code tut10-sram.yml\n</code></pre> <p>The key to using SRAM macros is (1) adding <code>00-openram-memgen</code> as the first step and (2) adding the the <code>sram_dir</code> and <code>srams</code> variables as shown below.</p> <pre><code>steps:\n - 00-openram-memgen\n - 01-synopsys-vcs-rtlsim\n - 02-synopsys-dc-synth\n - 03-synopsys-vcs-ffglsim\n - 04-cadence-innovus-pnr\n - 05-synopsys-vcs-baglsim\n - 06-synopsys-pt-pwr\n - 07-summarize-results\n\n...\n\nsram_dir : ../../../sim/sram\nsrams:\n - SRAM_32x128_1rw\n</code></pre> <p>The ASIC automated flow includes a new step template for using OpenRAM to generate SRAMs. Take a look at the corresponding run script</p> <pre><code>% cd $TOPDIR/asic/steps/00-openram-memgen\n% code run\n</code></pre> <p>The template at the bottom runs the <code>memgen</code> bash function for each SRAM macro.</p> <pre><code>{% for sram in srams | default([]) -%}\nmemgen {{sram}}\n{% endfor %}\n</code></pre> <p>You should recognize the steps in the <code>memgen</code> bash function which include running OpenRAM, copying the <code>.lib</code>, <code>.lef</code>, <code>.gds</code>, and <code>.v</code> files, and running library compiler to generate the <code>.db</code> file.</p> <p>Let's see some examples of how the remaining step templates include support for using SRAM macros. First, let's look at the run scripts for synthesis.</p> <pre><code>% cd $TOPDIR/asic/steps/02-synopsys-dc-synth\n% code run.tcl\n</code></pre> <p>The key difference for synthesis is we need to include the <code>.db</code> file for each SRAM macro.</p> <pre><code>set_app_var target_library [list \\\n  \"$env(ECE6745_STDCELLS)/stdcells.db\" \\\n  {% for sram in srams | default([]) -%}\n  \"../00-openram-memgen/{{sram}}.db\" \\\n  {% endfor %}\n]\n</code></pre> <p>For gate-level simulation we need to include the Verilog behavioral models. Let's look at the run scripts for place-and-route.</p> <pre><code>% cd $TOPDIR/asic/steps/04-cadence-innovus-pnr\n% code run.tcl\n</code></pre> <p>The key difference is we need to include the <code>.lef</code> and <code>.gds</code> files for each SRAM macro.</p> <pre><code>set lef_files [list \\\n  \"$env(ECE6745_STDCELLS)/rtk-tech.lef\" \\\n  \"$env(ECE6745_STDCELLS)/stdcells.lef\" \\\n  {% for sram in srams | default([]) -%}\n  \"../00-openram-memgen/{{sram}}.lef\" \\\n  {% endfor %}\n]\n\n...\n\nset gds_files [list \\\n  \"$env(ECE6745_STDCELLS)/stdcells.gds\" \\\n  {% for sram in srams | default([]) -%}\n  \"../00-openram-memgen/{{sram}}.gds\" \\\n  {% endfor %}\n]\n</code></pre> <p>We also need to make sure to include the <code>.lib</code> files in the <code>setup-timing.tcl</code> script.</p> <p>Now that we know understand how the step templates include support for using SRAM macros, let's go ahead and push the SRAM val/rdy wrapper through the ASIC automated flow. First let's delete the build directory we have been using so far so we can start over.</p> <pre><code>% cd $TOPDIR/asic\n% trash build-tut10-sram\n</code></pre> <p>Now let's use pyhflow to generate the run scripts and go through each step one at a time.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram\n% cd $TOPDIR/asic/build-tut10-sram\n% pyhflow ../designs/tut10-sram.yml\n% ./00-openram-memgen/run\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>The summary results should be similar to as shown below.</p> <pre><code> timestamp           = 2025-04-06 13:32:59\n design_name         = SRAMMinion_noparam\n clock_period        = 2.0\n rtlsim              = 7/7 passed\n synth_setup_slack   = 0.4255 ns\n synth_num_stdcells  = 354\n synth_area          = 11508.482 um^2\n ffglsim             = 7/7 passed\n pnr_setup_slack     = 0.3165 ns\n pnr_hold_slack      = 0.0102 ns\n pnr_clk_ins_src_lat = 0 ns\n pnr_num_stdcells    = 545\n pnr_area            = 11680.318 um^2\n baglsim             = 7/7 passed\n\n SRAMMinion_noparam_sram-rtl-random\n  - exec_time = 263 cycles\n  - exec_time = 526.0000 ns\n  - power     = 0.3296 mW\n  - energy    = 0.1734 nJ\n</code></pre>"},{"location":"ece6745-tut10-sram/#7-to-do-on-your-own","title":"7. To-Do On Your Own","text":"<p>Now that you understand how to use SRAM macros, try a simple experiment to see the difference in energy when we only read/write zeros to the SRAM macro. Our interactive simulator provides such a dataset.</p> <pre><code>% cd $TOPDIR/sim/build\n% ../tut10_sram/sram-sim --impl rtl --input allzero --translate --dump-vtb\n</code></pre> <p>Now modify the YAML design file to add this new evaluation.</p> <pre><code>evals:\n - SRAMMinion_noparam_sram-rtl-random\n - SRAMMinion_noparam_sram-rtl-allzero\n</code></pre> <p>Then you can regenerate the flow using pyhflow. There is no need to regenerate the SRAM macros, rerun synthesis, or rerun place-and-route. We can just just rerun four-state RTL, fast-functional gate-level, back-annotated gate-level simulation, power analysis, and the final summary.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram\n% pyhflow ../designs/tut10-sram.yml\n% ./01-synopsys-vcs-rtlsim/run\n% ./03-synopsys-vcs-ffglsim/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>Compare the energy of the experiments with random data vs all zeros. Look at the detailed energy reports.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram\n% code 06-synopsys-pt-pwr/SRAMMinion_noparam_sram-rtl-random-detailed.rpt\n% code 06-synopsys-pt-pwr/SRAMMinion_noparam_sram-rtl-allzero-detailed.rpt\n</code></pre> <p>The energy is not zero since even for the all zeros dataset the addresses are random and choosing between read/writes is also random.</p> <p>Now let's try another experiment to see the impact of column muxing. Change the column muxing for the 32x128 SRAM macro from 4 to 2 by updating the <code>words_per_row</code> variable in the <code>SRAM_32x128_1rw_cfg.py</code> configuration file. Then delete the build directory we have been using so far so we can start over.</p> <pre><code>% cd $TOPDIR/asic\n% trash build-tut10-sram\n</code></pre> <p>Use OpenRAM to regenerate the SRAM macros.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut10-sram\n% cd $TOPDIR/asic/build-tut10-sram\n% pyhflow ../designs/tut10-sram.yml\n% ./00-openram-memgen/run\n</code></pre> <p>Take a look at the resulting layout using Klayout. Notice how the SRAM array is much taller now, but also how the output flip-flops result in quite a bit of white space. Go ahead and run the rest of the ASIC automated flow.</p> <pre><code>% cd $TOPDIR/asic/build-tut10-sram\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre>"},{"location":"ece6745-tut12-spice-sim/","title":"ECE 6745 Tutorial 9: SPICE Simulation","text":"<p>ngspice is an open-source SPICE simulator for electrical circuits. We can use it to try out some circuit simulations as we go through the semester. In this tutorial, we will start by exploring two simple circuits: an NMOS transistor discharging a load capacitance and an NMOS transistor charging a load capacitance. We can use ngspice to simulate these two scenarios and plot the voltages on various nets. We will then simulate simple logic gates constructed explicitly using transistors, before simulating a few gates from a standard cell library.</p> <p>ngspice takes as input a SPICE deck. This is a text file which describes the circuit you want to simulate along with what kind of analysis you would like to perform on your circuit. You can learn more about SPICE decks in Chapter 8 of Weste &amp; Harris. You can also look at the ngspice documentation:</p> <ul> <li>http://ngspice.sourceforge.net/docs/ngspice-34-manual.pdf</li> </ul> <p>The first step is to source the setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% mkdir $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut12-spice tut12\n% cd tut12\n% TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut12-spice-sim/#1-simulating-an-nmos-discharging-a-load-capacitance","title":"1. Simulating an NMOS Discharging a Load Capacitance","text":"<p>Here is a simple SPICE deck for the first scenario where we have an NMOS transistor discharging a load capacitance.</p> <pre><code>* MMOS Discharging Capacitor\n* ========================================================================\n\n* Parameters and Models\n* ------------------------------------------------------------------------\n\n.param VDD='1.1V'\n.temp  25\n.inc   \"/classes/ece6745/install/adk-pkgs/freepdk-45nm/stdview/pdk-models.sp\"\n\n* Supply Voltage Source\n* ------------------------------------------------------------------------\n\nVdd vdd gnd VDD\n\n* Transistors\n* ------------------------------------------------------------------------\n\n*  src  gate drain body type\nM1 gnd  in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n\n* Output Load\n* ------------------------------------------------------------------------\n\nCload out gnd 7fF\n\n* Input Signals\n* ------------------------------------------------------------------------\n\nVin in gnd pwl( 0ns 0V 0.5ns 0V 0.7ns VDD )\n\n* Analysis\n* ------------------------------------------------------------------------\n\n.ic   V(out)=VDD\n.tran 0.01ns 2.5ns\n\n.control\nrun\nset color0=white\nset color1=black\nset xbrushwidth=2\nplot V(in) V(out)\n.endc\n\n.end\n</code></pre> <p>The first line in the SPICE deck must be a comment. Comments start with an asterisk. Let's discuss each part. The first part sets up parameters and models:</p> <pre><code>.param VDD='1.1V'\n.temp  25\n.inc   \"/classes/ece6745/install/adk-pkgs/freepdk-45nm/stdview/pdk-models.sp\"\n</code></pre> <p>We create a constant named VDD which is the supply voltage we want to use in our circuit. Note that VDD is -not- a voltage source or a node in our circuit. It is just a constant. We set the temperature we want to use for the simulation. Finally, we include the model files associated with the technology we want to use. We will be using the FreePDK 45nm technology in the labs/projects, so here we are including the transistor models from that technology.</p> <p>The next part instantiates a supply voltage source:</p> <pre><code>Vdd vdd gnd VDD\n</code></pre> <p>SPICE decks have this weird thing where the very first character of a line indicates the type of circuit element you want to instantiate. The book gives many more examples. If the first character is a <code>V</code> then it is a voltage source. So here we are creating a voltage source between two nodes named <code>vdd</code> and <code>gnd</code>. Other examples include <code>R</code> for resistor, <code>C</code> for capacitor, <code>M</code> for MOSFET transistor, <code>A</code> for models with special code, and <code>X</code> for subcircuits. Note that SPICE decks are case sensitive. The voltage source is a constant 1.1V. We just use the constant <code>VDD</code> so we can set the supply voltage in one place at the top of the deck.</p> <p>The next part instantiates a transistor:</p> <pre><code>*  src   gate drain body type\nM1 gnd   in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n</code></pre> <p>The first letter is an <code>M</code> which means MOSFET. We specify nodes for the source, gate, drain, and body. We also indicate whether this is an NMOS or PMOS and the width and length in micron. This is a 45nm technology, so we use the minimum transistor length of 45nm (0.045um). If we look at our Nangate standard cell library for a INV_X1 we can see that the NMOS has a width of about 10x the length, so for we make the NMOS width to be 0.450um. So the above example creates a \"minimum\" sized NMOS transistor, where \"minimum\" means the NMOS we will be using in a minimum sized inverter.</p> <p>The next part instantiates an output load:</p> <pre><code>Cload out gnd 7fF\n</code></pre> <p>The first letter is a <code>C</code> which means capacitor. We specify the positive and negative terminals and the capacitance. An INV_X4 inverter has an input cap of 6.25fF so we round up to 7fF as a reasonable output load.</p> <p>The next part instantiates another voltage source, but this source will be used for the input signal:</p> <pre><code>Vin in gnd pwl( 0ns 0V 0.5ns 0V 0.7ns 1.1V )\n</code></pre> <p>Here we can use <code>pwl</code> to create a piece-wise-linear voltage signal.</p> <p>The final part specifies what analysis we want to do:</p> <pre><code>.ic   V(out)=VDD\n.tran 0.01ns 2.5ns\n\n.control\nrun\nset color0=white\nset color1=black\nset xbrushwidth=2\nplot V(in) V(out)\n.endc\n</code></pre> <p>So the <code>.ic</code> line sets an initial condition. Here we want to make sure the output node is initially charged up. The <code>.tran</code> line specifies that we want to do transient analysis for 2.5ns in 0.01ns timesteps. The <code>.control</code>/<code>.endc</code> block is a set of interactive commands which run the simulation and then plot the results.</p> <p>Now let's run the simulation using ngspice:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice nmos-discharge-cap-sim.sp\n</code></pre> <p>Note that if we use ngspice to display plots, then it is a Linux GUI application so you will need to use Microsoft Remote Desktop. A little plot should pop up that looks like the following. This plot clearly shows Vin going from 0V to 1.1V and Vout going from 1.1V to 0V. Everything is \"full rail\".</p> <p></p> <p>To Do On Your Own: Increase the load capacitance by 10x and then 100x and observe the impact on the time to discharge the capacitor.</p>"},{"location":"ece6745-tut12-spice-sim/#2-simulating-an-nmos-charging-a-load-capacitance","title":"2. Simulating an NMOS Charging a Load Capacitance","text":"<p>Now let's try a similar experiment except this time we are going to use the NMOS transistor to charge up an output load. Here is the corresponding spice deck:</p> <pre><code>* MMOS Charging Capacitor\n* ========================================================================\n\n* Parameters and Models\n* ------------------------------------------------------------------------\n\n.param VDD='1.1V'\n.temp  25\n.inc   \"/classes/ece6745/install/adk-pkgs/freepdk-45nm/stdview/pdk-models.sp\"\n\n* Supply Voltage Source\n* ------------------------------------------------------------------------\n\nVdd vdd gnd VDD\n\n* Transistors\n* ------------------------------------------------------------------------\n\n*  src  gate drain body type\nM1 vdd  in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n\n* Output Load\n* ------------------------------------------------------------------------\n\nCLoad out gnd 7fF\n\n* Input Signals\n* ------------------------------------------------------------------------\n\nVin in gnd pwl( 0ns 0V 0.5ns 0V 0.7ns VDD )\n\n* Analysis\n* ------------------------------------------------------------------------\n\n.ic   V(out)=0V\n.tran 0.01ns 2.5ns\n\n.control\nrun\nset color0=white\nset color1=black\nset xbrushwidth=2\nplot V(in) V(out) V(in)-V(out) V(vdd)-V(out)\n.endc\n\n.end\n</code></pre> <p>This is similar to what we had above except now the source of the NMOS transistor is connected to vdd, and we set the initial condition such that the output load is initially discharged. Now let's run the simulation using ngspice:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice nmos-charge-cap-sim.sp\n</code></pre> <p>A little plot should pop up that looks like the following. This plot shows things are not working as well! Vin obviously goes from 0V to 1.1V, but Vout goes from 0V and then starts to level off around 0.8V. It never reaches 1.1V. Why? Well, we are also plotting Vgs (this is the organize line, it is V(in)-V(out)). You can see that Vgs goes up but then starts to go down because Vout is increasing! The transistor starts to turn off an this prevents us from fully charging up Vout. Notice that Vout is still slowly increasing ... this is probably due to some second order effect like leakage or more likely that the NMOS is not 100% off since Vgs is right around the threshold voltage.</p> <p></p> <p>To Do On Your Own: Increase the load capacitance by 10x and then 100x and observe the impact on the time to discharge the capacitor.</p>"},{"location":"ece6745-tut12-spice-sim/#3-simulating-simple-logic-gates","title":"3. Simulating Simple Logic Gates","text":"<p>Let's experiment with some simple logic gates. Take a look at the SPICE deck in <code>inv-sim.sp</code> which contains the canonical minimum sized inverter:</p> <pre><code>*  src  gate drain body type\nM1 vdd  in   out   vdd  PMOS_VTL W=0.900um L=0.045um\nM2 gnd  in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n</code></pre> <p>Notice how the PMOS transistor is sized to be twice the size of the minimum-sized NMOS transistor. We can use a more complicated piece-wise linear voltage source to toggle the input to the inverter:</p> <pre><code>Vin in gnd pwl\n+ (\n+   0.0ns  0V\n+   0.4ns  0V\n+   0.6ns VDD\n+   0.9ns VDD\n+   1.1ns VDD\n+   1.4ns VDD\n+   1.6ns  0V\n+   1.9ns  0V\n+ )\n</code></pre> <p>We can use <code>+</code> to continue a long line SPICE command across multiple lines in the SPICE deck. Here we have formatted the piece-wise linear voltage source to look a little like a table. The input is low for 0.5ns, then goes high for 1ns, and then goes low again for 0.5ns. Our SPICE deck also includes some measurement commands:</p> <pre><code>.measure tran tpdr trig v(in) val='VDD/2' fall=1 targ v(out) val='VDD/2' rise=1\n.measure tran tpdf trig v(in) val='VDD/2' rise=1 targ v(out) val='VDD/2' fall=1\n.measure tran tpd param='(tpdr+tpdf)/2'\n</code></pre> <p>The ngspice manual explains measurement commands in more detail. Briefly, the first command measures the propagation delay for a low-to-high output transition, and the second command measures the propagation delay for a high-to-low output transition. These delays are measured from when the input is VDD/2 to when the output is VDD/2. The third measurement command uses the average of these two propagation delays to estimate the overall propagation delay of the inverter. Chapter 8 of Weste &amp; Harris discusses in more detail how to effectively characterize various CMOS circuits. Now let's run the simulation using ngspice:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice inv-sim.sp\n...\ntpdr = 1.037703e-11 targ = 1.510377e-09 trig = 1.500000e-09\ntpdf = 2.409571e-11 targ = 5.240957e-10 trig = 5.000000e-10\ntpd  = 1.72364e-11\n</code></pre> <p>A little plot should pop up that shows the input and output voltages, and the measurement results will be displayed in the terminal. The propagation delay is approximately 17.2ps.</p> <p>To Do On Your Own: Increase the load capacitance by 10x and then 100x and observe the impact on the propagation delay. Make sure you look at the actual waveforms to see if the output has time to go full rail. If not, you need to increase the time between input transitions to make an accurate estimate of the propagation delay.</p> <p>Let's dig a little deeper. Notice that the rise time is not equal to the fall time for our inverter. The rise time is 10.4ps but the fall time is 24.1ps. We have made the PMOS twice the width of the NMOS (i.e., the PMOS is 900nm wide while the NMOS is 450nm wide), so why aren't the rise and fall times equal? Part of the reason is the PMOS mobility is not exactly half the NMOS mobility in this technology as well as many other second order effects. Change the size of PMOS so it is only 1.5x as large as the NMOS like this:</p> <pre><code>*  src  gate drain body type\nM1 vdd  in   out   vdd  PMOS_VTL W=0.675um L=0.045um\nM2 gnd  in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n</code></pre> <p>Rerun the simulation:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice inv-sim.sp\n...\ntpdr = 1.940778e-11 targ = 2.019408e-09 trig = 2.000000e-09\ntpdf = 1.812324e-11 targ = 1.018123e-09 trig = 1.000000e-09\ntpd  = 1.87655e-11\n</code></pre> <p>You can now see the rise and fall times are much closer to being equal. Of course this begs the question, \"Why is it important to have equal rise and fall times?\". To some degree this is a design decision. It is certainly possible to have unequal rise and fall times, and indeed this can also often lead to better area/power or enabling making a critical transition faster (at the expense of the other transition). However, the largest motivation for equal rise and fall times is that it maximizes the noise margins. To understand this, let's use ngspice to analyze the DC transfer curve of an inverter. Take a look at the SPICE deck in <code>inv-sim-xfer.sp</code> which contains the same canonical minimum sized inverter but with DC instead of transient analysis:</p> <pre><code>.dc Vin 0 'VDD' 0.01\n</code></pre> <p>Here is the resulting DC transfer curve showing Vin vs Vout (after I manually annotated the noise margins):</p> <p></p> <p>Recall that the noise margins are with respect to where the slope of the transfer curve is -1 (i.e., maximum gain). V_IL is the maximum low input voltage and V_IH is the minimum high input voltage. V_OL is the maximum low output voltage and V_OH is the minimum high output voltage. The noise margins are NM_H = V_OH - V_IH and NM_L = V_IL - V_OL and we want these noise margins to be as large as possible. With large noise margins we can tolerate noise on the input without it propagating through the inverter and causing it to switch the output. For this example the noise margins are roughly equal at 0.3V:</p> <pre><code>V_IL = 0.45V\nV_IH = 0.65V\nV_OL = 0.15V\nV_OH = 0.95V\nNM_H = V_OH - V_IH = 0.95V - 0.65V = 0.31V\nNM_L = V_IL - V_OL = 0.45V - 0.15V = 0.30V\n</code></pre> <p>Now the problem with unequal rise and fall times is it means we essentially skew the noise margins. We make one noise larger but the other noise margin smaller. Try rerunning the simulation, but this time make the PMOS the same size as the NMOS like this:</p> <pre><code>*  src  gate drain body type\nM1 vdd  in   out   vdd  PMOS_VTL W=0.450um L=0.045um\nM2 gnd  in   out   gnd  NMOS_VTL W=0.450um L=0.045um\n</code></pre> <p>Rerun the simulation and you should see something like the following (after I manually annotated the noise margins):</p> <p></p> <p>And here are roughly the corresponding noise margins:</p> <pre><code>V_IL = 0.35V\nV_IH = 0.48V\nV_OL = 0.15V\nV_OH = 0.98V\nNM_H = V_OH - V_IH = 0.98V - 0.48V = 0.5V\nNM_L = V_IL - V_OL = 0.35V - 0.15V = 0.2V\n</code></pre> <p>Notice how the low noise margin has gone from 0.3V to 0.2V. This means the gate is now much more sensitive to noise. So in general we perfer equal rise and fall times becuase it improves our noise margins (and also simplifies our analysis).</p> <p>To Do On Your Own: Make the NMOS twice as big as the PMOS and observe how this impacts the noise margins.</p> <p>Creating voltage sources to change the inputs can be very tedious, especially when we want to drive multiple inputs. We can take advantage of ngspice's support for mixed-signal analog/digital simulation to simplify the task of creating many digital input values. Take a look at the SPICE deck in <code>inv-dsource-sim.sp</code> to see a different way of generating input sources:</p> <pre><code>A1 [in_] inv_source\n.model inv_source d_source (input_file=\"inv-source.txt\")\n</code></pre> <p>Here we are instantiating a <code>d_source</code> and giving this new component the name <code>a1</code>. The <code>d_source</code> reads an input text file to see the values of the given input nodes (i.e., <code>in_</code>). The <code>inv-source.txt</code> file looks like this:</p> <pre><code>* inv-source.txt\n* ====================================================================\n\n* time in\n0.0ns  0s\n1.0ns  1s\n2.0ns  0s\n</code></pre> <p>Lines that start with <code>*</code> are comments. The first column corresponds to time and each remaining column corresponds to an input node. The input node can be either <code>0s</code> (for a strong logic zero) or <code>1s</code> (for a strong logic one). So the above example toggles the input node just as with the previous piece-wise linear voltage source. Note that there is a positional mapping from the columns in the text file to the nodes in the SPICE deck when instantiating the <code>d_source</code>. So the second column maps to the <code>in_</code> input node.</p> <p>We also need to instantiate a digital-to-analog converter (DAC) to translate the digital values into analog values suitable for driving a CMOS circuit:</p> <pre><code>Ain [in_] [in] dac_in\n.model dac_in dac_bridge (out_low=0V out_high='VDD' t_rise=0.2ns t_fall=0.2ns)\n</code></pre> <p>The <code>dac_bridge</code> component takes parameters specifying the logic low and logic high voltage levels and the rise/fall times. We also need to specify the mapping from digital input nodes (<code>in_</code>) to analog input nodes (<code>in</code>). Now let's run the simulation using ngspice and confirm that the result is the same as when using piece-wise linear voltage sources:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice inv-dsource-sim.sp\n</code></pre> <p>Now let's experiment with a NAND2 gate. Take a look at the SPICE deck in <code>nand2-sim.sp</code> which contains the canonical NAND2 gate:</p> <pre><code>*  src  gate drain body type\nM1 vdd  a    y     vdd  PMOS_VTL W=0.900um L=0.045um\nM2 vdd  b    y     vdd  PMOS_VTL W=0.900um L=0.045um\nM3 n0   a    y     gnd  NMOS_VTL W=0.900um L=0.045um\nM4 gnd  b    n0    gnd  NMOS_VTL W=0.900um L=0.045um\n</code></pre> <p>Notice how we have sized this NAND2 gate to have equal worst-case rise and fall times assuming a PMOS/NMOS mobility ratio of two, and we have also sized this NAND2 gate to have similar effective resistance as the canonical minimum-sized inverter</p> <p>To Do On Your Own: Copy the <code>nand2-sim.sp</code> SPICE deck to create a new file named <code>nor2-sim.sp</code> and copy the <code>nand2-source.txt</code> input file to create a new file named <code>nor2-source.txt</code>. Replace the NAND2 gate with an explicit transistor implementation of a NOR2 gate. Size the NOR2 gate to have equal worst-case rise and fall times assuming a PMOS/NMOS mobility ratio of two and similar effective resistance as the canonical minimum-sized inverter. Run the simulation and verify the functionality using the waveforms.</p>"},{"location":"ece6745-tut12-spice-sim/#4-simulating-standard-cells","title":"4. Simulating Standard Cells","text":"<p>A standard cell library will include many views including SPICE decks for each standard cell. Actually, the standard cell library will usually include two kinds of SPICE decks. The schematic SPICE deck includes just the transistors, while the extracted SPICE deck will include all of the extracted parasitic resistances and capacitances. Take a look at the schematic SPICE deck for a minimum sized inverter (INV_X1):</p> <pre><code>% less -p INV_X1 ${ECE6745_STDCELLS}/stdcells.spi\n.SUBCKT INV_X1 A ZN VDD VSS\n*.PININFO A:I ZN:O VDD:P VSS:G\n*.EQN ZN=!A\nM_i_0 ZN A VSS VSS NMOS_VTL W=0.415000U L=0.050000U\nM_i_1 ZN A VDD VDD PMOS_VTL W=0.630000U L=0.050000U\n.ENDS\n</code></pre> <p>The SPICE deck for an inverter is encapsulated in a SPICE subcircuit (<code>SUBCKT</code>). A subcircuit is like a PyMTL3 or Verilog module with an interface (i.e., list of ports) and an implementation (i.e., instantiating transistors or other subcircuits). In this case, the INV_X1 gate includes four ports: the input (<code>A</code>), the output (<code>ZN</code>), the power supply (<code>VDD</code>) and ground (<code>VSS</code>). As expected, the implementation includes a PMOS and NMOS transistor. Notice that even though the minimum length transistor in this technology is 0.045um, both transistors are 0.050um. This is actually quite common. Standard cells often use slightly longer transistors to offer a better performance vs. power trade-off (i.e., lower leakage). Some standard cell libraries will actually include different implementations of every gate each with a different channel length. Also notice how the PMOS is only 1.5x larger than the NMOS. Again, this is actually quite common. A PMOS/NMOS mobility ratio of two is just an assumption; a specific technology will likely have a different mobility ratio which is often less than two. Standard cells will also often have slightly skewed rise/fall times to offer a better area vs. noise margin trade-off.</p> <p>While we could certainly simulate the schematic SPICE deck, it is more useful to simulate the extracted SPICE deck since this will provide accurate performance analysis. Take a loo at the extracted SPICE deck for a minimum sized inverter (INV_X1):</p> <pre><code>% less -p INV_X1 $ECE6745_STDCELLS/stdcells-lpe.spi\n.SUBCKT INV_X1 VDD VSS A ZN\n*.PININFO VDD:P VSS:G A:I ZN:O\n*.EQN ZN=!A\nM_M1 N_ZN_M0_d N_A_M0_g N_VDD_M0_s VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M0 N_ZN_M1_d N_A_M1_g N_VSS_M1_s VSS NMOS_VTL W=0.415000U L=0.050000U\nC_x_PM_INV_X1%VDD_c0 x_PM_INV_X1%VDD_31 VSS 4.13109e-17\nC_x_PM_INV_X1%VDD_c1 x_PM_INV_X1%VDD_19 VSS 2.61599e-16\nC_x_PM_INV_X1%VDD_c2 x_PM_INV_X1%VDD_18 VSS 1.89932e-17\nC_x_PM_INV_X1%VDD_c3 N_VDD_M0_s VSS 3.88255e-17\nC_x_PM_INV_X1%VDD_c4 x_PM_INV_X1%VDD_12 VSS 1.92462e-17\nC_x_PM_INV_X1%VDD_c5 x_PM_INV_X1%VDD_11 VSS 2.334e-16\nC_x_PM_INV_X1%VDD_c6 x_PM_INV_X1%VDD_8 VSS 5.52247e-16\nR_x_PM_INV_X1%VDD_r7 VDD x_PM_INV_X1%VDD_31 0.13879\nR_x_PM_INV_X1%VDD_r8 VDD x_PM_INV_X1%VDD_28 0.392137\n...\n.ENDS\n</code></pre> <p>The INV_X1 gate still includes four ports (although they are in a different order which is annoying), but notice that the implementation is radically different. There are ~50 parasitic resistances and capacitances extracted from the actual layout for this standard cell. These parasitics are what enable more accurate performance analysis.</p> <p>Take a look at the SPICE deck in <code>inv-stdcell-sim.sp</code> which is meant for simulating the INV_X1 standard cell. First, notice that we need to include the standard cell SPICE deck:</p> <pre><code>.param VDD='1.1V'\n.temp  25\n.inc   \"/classes/ece6745/install/adk-pkgs/freepdk-45nm/stdview/pdk-models.sp\"\n.inc   \"/classes/ece6745/install/adk-pkgs/freepdk-45nm/stdview/stdcells-lpe.spi\"\n</code></pre> <p>Instead of directly instantiating transistors, we simply instantiate the <code>INV_X1</code> subcircuit:</p> <pre><code>X1 vdd gnd in out INV_X1\n</code></pre> <p>The instance name of subcircuits (<code>X1</code>) must start with <code>X</code>. The instance name is followed by the list of nodes that should be connected to the ports of the subcircuit. The nodes are connected by position. So since the port list in the subcircuit definition is <code>VDD VSS A ZN</code>, we must list the nodes in the subcircuit instance in the exact same order. The subcircuit instance ends with the type of subcircuit we wish to instantiate. The rest of the SPICE deck is the same as earlier in the tutorial. Let's run the simulation using ngspice:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice inv-stdcell-sim.sp\n...\ntpdr = 2.577757e-11 targ = 2.125778e-09 trig = 2.100000e-09\ntpdf = 2.275623e-11 targ = 1.122756e-09 trig = 1.100000e-09\ntpd  = 2.42669e-11\n</code></pre> <p>Recall that the propagation delay when we instantiated transistors directly was 17.2ps while now it is 24.3ps. The extracted SPICE decks are almost always slower than schematic SPICE decks, since we are actually modeling the parasitic resistances and capacitances.</p> <p>To Do On Your Own: Increase the load capacitance by 10x and then 100x and observe the impact on the propagation delay. Make sure you look at the actual waveforms to see if the output has time to go full rail. If not, you need to increase the time between input transitions to make an accurate estimate of the propagation delay.</p> <p>Now let's experiment with the NAND2_X1 gate from the standard cell library. Take a look at the SPICE deck in <code>nand2-stdcell-sim.sp</code> which instantiates the appropriate subcircuit, then run the simulation using ngspice:</p> <pre><code>% cd $TOPDIR/sim\n% ngspice nand2-stdcell-sim.sp\n</code></pre> <p>To Do On Your Own: Copy the <code>nand2-stdcell-sim.sp</code> SPICE deck to create a new file named <code>nor2-stdcell-sim.sp</code> and copy the <code>nand2-source.txt</code> input file to create a new file named <code>nor2-source.txt</code>. Replace the NAND2_X1 subcircuit instance with an instance of the NOR2_X1 gate from the standard cell library. Run the simulation and verify the functionality using the waveforms.</p>"},{"location":"ece6745-tut12-spice-sim/#5-to-do-on-your-own","title":"5. To Do On Your Own","text":"<p>The Nangate standard cell library includes a full-adder gate:</p> <pre><code>% less -p FA_X1 ${ECE6745_STDCELLS}/stdcells-lpe.spi\n.SUBCKT FA_X1 VDD VSS CO CI A B S\n*.PININFO VDD:P VSS:G CO:O CI:I A:I B:I S:O\n*.EQN CO=((A * B) + (CI * (A + B)));S=(CI ^ (A ^ B))\nM_M14 N_VDD_M0_d N_4_M0_g N_CO_M0_s VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M15 net_007 N_B_M1_g N_VDD_M0_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M16 N_4_M2_d N_A_M2_g net_007 VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M17 N_6_M3_d N_CI_M3_g N_4_M2_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M18 N_VDD_M4_d N_A_M4_g N_6_M3_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M19 N_6_M5_d N_B_M5_g N_VDD_M4_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M20 N_11_M6_d N_B_M6_g N_VDD_M6_s VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M21 N_VDD_M7_d N_CI_M7_g N_11_M6_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M22 N_11_M8_d N_A_M8_g N_VDD_M7_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M23 N_12_M9_d N_4_M9_g N_11_M8_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M24 net_010 N_CI_M10_g N_12_M9_d VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M25 net_009 N_B_M11_g net_010 VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M26 N_VDD_M12_d N_A_M12_g net_009 VDD PMOS_VTL W=0.315000U L=0.050000U\nM_M27 N_S_M13_d N_12_M13_g N_VDD_M12_d VDD PMOS_VTL W=0.630000U L=0.050000U\nM_M0 N_VSS_M14_d N_4_M14_g N_CO_M14_s VSS NMOS_VTL W=0.415000U L=0.050000U\nM_M1 net_000 N_B_M15_g N_VSS_M14_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M2 N_4_M16_d N_A_M16_g net_000 VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M3 N_7_M17_d N_CI_M17_g N_4_M16_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M4 N_VSS_M18_d N_A_M18_g N_7_M17_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M5 net_002 N_B_M19_g N_VSS_M18_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M6 net_006 N_B_M20_g N_VSS_M20_s VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M7 N_VSS_M21_d N_CI_M21_g net_006 VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M8 N_10_M22_d N_A_M22_g N_VSS_M21_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M9 N_12_M23_d N_4_M23_g N_10_M22_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M10 net_004 N_CI_M24_g N_12_M23_d VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M11 net_003 N_B_M25_g net_004 VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M12 N_VSS_M26_d N_A_M26_g net_003 VSS NMOS_VTL W=0.210000U L=0.050000U\nM_M13 N_S_M27_d N_12_M27_g N_VSS_M26_d VSS NMOS_VTL W=0.415000U L=0.050000U\n...\n.ENDS\n</code></pre> <p>Try instantiating and chaining four of these gates together to create a four-bit ripple-carry adder. Create an appropriate SPICE deck to drive the simulation including a <code>d_source</code> that reads in a text file with the two four-bit input values. Here is what the results look like if you start with adding 0b1111 to 0b0000 and then change the b input to 0b0001 at 200ps. Notice the sum outputs transitioning from 0 to 1 as the carry is propagated through the full-adder gates. As discussed in Chapter 8 of Weste &amp; Harris, for more accurate performance analysis you would need to add inverters to the inputs for realistic waveform shaping and to the outputs for realistic load capacitance.</p> <p></p>"},{"location":"ece6745-tut13-dw/","title":"6745 Tutorial 13: DesignWare and Retiming","text":"<p>Synopsys Design Compiler (DC) includes the DesignWare (DW) library which is a collection of hardware components implementing arbiters, integer arithmetic units, floating-point arithmetic units, and memories. The Synopsys DW components also have optimized gate-level implementations that Synopsys DC can use when synthesizing your design. This tutorial will describe how these components can be used either through automatic inference or explicit instantiation. You can see a list of all of the available Synopsys DW components in the user guide here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_userguide.pdf</li> </ul> <p>The user guide shows which units can be automatically inferred from an operator or function and which can only be used through explicit instantiation. Since most of the arithmetic units are combinational, the tutorial will also discuss how you can use register retiming to automatically pipeline these units so they can operate at higher clock frequencies. This tutorial assumes you have already completed the tutorials on Linux, Git, PyMTL, Verilog, ASIC front-end flow, ASIC back-end flow, and ASIC automated ASIC flow.</p> <p>The first step is to access <code>ecelinux</code>. Use VS Code to log into a specific <code>ecelinux</code> server. Once you are at the <code>ecelinux</code> prompt, source the setup script, clone this repository from GitHub, and define an environment variable to keep track of the top directory for the project.</p> <pre><code>% source setup-ece6745.sh\n% mkdir -p $HOME/ece6745\n% cd $HOME/ece6745\n% git clone git@github.com:cornell-ece6745/ece6745-tut13-dw tut13\n% cd tut13\n% export TOPDIR=$PWD\n</code></pre>"},{"location":"ece6745-tut13-dw/#1-synopsys-designware-automatic-inference","title":"1. Synopsys DesignWare Automatic Inference","text":"<p>Let's start by exploring how Synopsys DC can automatically infer the use of Synopsys DW components by reviewing the sort unit from earlier tutorials. Recall the sort unit is implemented using a three-stage pipelined, bitonic sorting network and the datapath is shown below.</p> <p></p> <p>Let's look at the min/max unit:</p> <pre><code>module tut3_verilog_sort_MinMaxUnit\n#(\n  parameter p_nbits = 1\n)(\n  input  logic [p_nbits-1:0] in0,\n  input  logic [p_nbits-1:0] in1,\n  output logic [p_nbits-1:0] out_min,\n  output logic [p_nbits-1:0] out_max\n);\n\n  always_comb begin\n\n    // Find min/max\n\n    if ( in0 &gt;= in1 ) begin\n      out_max = in0;\n      out_min = in1;\n    end\n    else if ( in0 &lt; in1 ) begin\n      out_max = in1;\n      out_min = in0;\n    end\n\n    // Handle case where there is an X in the input\n\n    else begin\n      out_min = 'x;\n      out_max = 'x;\n    end\n\n  end\n\nendmodule\n</code></pre> <p>Notice how this unit uses two comparison operators, one for greater-than-equal and one for less than. We will see how Synopsys DC is able to automatically infer the use of two Synopsys DW components for these operators.</p> <p>First, we need to run the tests and interactive simulator to create the Verilog test benches which we can use for four-state RTL, fast-functional gate-level, and back-annotated gate-level simulation.</p> <pre><code>% mkdir -p $TOPDIR/sim/build\n% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort/test --test-verilog --dump-vtb\n% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input random --stats --translate --dump-vtb\n% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input zeros  --stats --translate --dump-vtb\n</code></pre> <p>Now let's use the ASIC automated flow to push the sort unit through synthesis and place-and-route.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut08-sort\n% cd $TOPDIR/asic/build-tut08-sort\n% pyhflow ../designs/tut08-sort.yml\n% ./run-flow\n</code></pre> <p>Then you can look at the resources report generated by Synopsys DC to see what Synopsys DW components were inferred.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% cat 02-synopsys-dc-synth/resources.rpt\n</code></pre> <p>You should see something like this.</p> <pre><code>================================================================\n| Cell     | Module  | Parameters | Contained Operations       |\n================================================================\n| gte_x_1  | DW_cmp  | width=8    | gte_30 (MinMaxUnit.v:30)   |\n| lt_x_2   | DW_cmp  | width=8    | lt_34 (MinMaxUnit.v:34)    |\n================================================================\n\nImplementation Report\n========================================\n|          |         | Current         |\n| Cell     | Module  | Implementation  |\n========================================\n| gte_x_1  | DW_cmp  | apparch (area)  |\n| lt_x_2   | DW_cmp  | apparch (area)  |\n========================================\n</code></pre> <p>The report shows how Synopsys DC was able to infer the use of a Synopsys DW comparator (<code>DW_cmp</code>). You can learn more about this component from its datasheet here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_datasheets/DW01_cmp2.pdf</li> </ul> <p>You will see that the component includes three different microarchitectures:</p> <ul> <li><code>rpl</code>: Ripple carry</li> <li><code>pparch</code>: Delay-optimized flexible parallel-prefix</li> <li><code>apparch</code>: Area-optimized flexible architecture</li> </ul> <p>Since the clock constraint is relatively generous (140ps of positive slack), Synopsys DC has decided to use a more area-optimized implementation.</p>"},{"location":"ece6745-tut13-dw/#2-synopsys-designware-explicit-instantiation","title":"2. Synopsys DesignWare Explicit Instantiation","text":"<p>Synopsys DC will to its best to infer Synopsys DW components whenever possible, but many components can only be used by explicitly instantiating the component in your Verilog. In this section, we will look at two examples: (1) instantiating a six-function comparator in the sort unit; and (2) instantiating a floating-point adder.</p>"},{"location":"ece6745-tut13-dw/#21-explicitly-instantiating-six-function-comparator","title":"2.1. Explicitly Instantiating Six-Function Comparator","text":"<p>To illustrate how explicit instantiation works, let's use a six-function comparator to implement the min/max unit. Review the corresponding data-sheet here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_datasheets/DW01_cmp6.pdf</li> </ul> <p>Now go ahead and modify the min/max unit to explicitly instantiate and use this six-function comparator as shown below.</p> <pre><code>module tut3_verilog_sort_MinMaxUnit\n#(\n  parameter p_nbits = 1\n)(\n  input  logic [p_nbits-1:0] in0,\n  input  logic [p_nbits-1:0] in1,\n  output logic [p_nbits-1:0] out_min,\n  output logic [p_nbits-1:0] out_max\n);\n\n  logic lt;\n  logic gt;\n  logic eq;\n  logic le;\n  logic ge;\n  logic ne;\n\n  DW01_cmp6#(p_nbits) cmp_gt\n  (\n    .A  (in0),\n    .B  (in1),\n    .TC (1'b0),\n    .LT (lt),\n    .GT (gt),\n    .EQ (eq),\n    .LE (le),\n    .GE (ge),\n    .NE (ne)\n  );\n\n  assign out_max = gt ? in0 : in1;\n  assign out_min = lt ? in0 : in1;\n\nendmodule\n</code></pre> <p>Now try to rerun the tests.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort/test -x --tb=long\n</code></pre> <p>The tests will fail because Verilator cannot find the implementation of the Synopsys DW component. Add the following include directive at the top of the implementation of the min/max unit:</p> <pre><code>`include \"/opt/synopsys/syn/V-2023.12-SP5/dw/sim_ver/DW01_cmp6.v\"\n</code></pre> <p>Now Verilator will be able to find the implementation of the Synopsys DW component, but it produces a warning about an implicit static function. We will need to disable this warning when processing the Synopsys DW component using Verilator's special linting comments.</p> <pre><code>/* verilator lint_off IMPLICITSTATIC */\n`include \"/opt/synopsys/syn/V-2023.12-SP5/dw/sim_ver/DW01_cmp6.v\"\n/* verilator lint_on IMPLICITSTATIC */\n</code></pre> <p>Now the tests should all pass so we can now regenerate the Verilog test benches for four-state RTL, fast-functional gate-level, and back-annotated gate-level simulation.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut3_verilog/sort/test --test-verilog --dump-vtb\n% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input random --stats --translate --dump-vtb\n% ../tut3_verilog/sort/sort-sim --impl rtl-struct --input zeros  --stats --translate --dump-vtb\n</code></pre> <p>Now let's push the sort unit through the ASIC automated flow again. We will start by just running the first two steps and looking at the resources report.</p> <pre><code>% cd ${TOPDIR}/asic/build-tut08-sort\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% cat 02-synopsys-dc-synth/resources.rpt\n</code></pre> <p>You should see something like this:</p> <pre><code>==================================================================\n| Cell     | Module    | Parameters | Contained Operations       |\n==================================================================\n| cmp_gt   | DW01_cmp6 | width=8    | cmp_gt (MinMaxUnit.v:38)   |\n==================================================================\n\nImplementation Report\n==========================================\n|          |           | Current         |\n| Cell     | Module    | Implementation  |\n==========================================\n| cmp_gt   | DW01_cmp6 | apparch (area)  |\n==========================================\n</code></pre> <p>This clearly indicates that Synopsys DC is now using the explicitly instantiated six-function comparator instead of automatically inferring a two-function comparator.</p> <p>Let's go ahead and push the sort unit through the reset of the ASIC automated flow.</p> <pre><code>% cd $TOPDIR/asic/build-tut08-sort\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>Since the implementation now depends on Verilog code outside the source tree, your tests will no longer work on GitHub Actions. You can solve this by copying the Verilog corresponding to the explicitly instantiated components into your source tree. For example, we can copy the Verilog for the six-function comparator into a <code>dw</code> subdirectory.</p> <pre><code>% mkdir -p $TOPDIR/sim/dw\n% cd $TOPDIR/sim/dw\n% cp /opt/synopsys/syn/V-2023.12-SP5/dw/sim_ver/DW01_cmp6.v .\n</code></pre> <p>Then modify the include directive at the top of the implementation of the min/max unit appropriately.</p> <pre><code>`include \"dw/DW01_cmp6.v\"\n</code></pre> <p>Note that since the verilog provided by Synopsys DW is copyrighted you should not make it public.</p>"},{"location":"ece6745-tut13-dw/#22-explicitly-instantiating-floating-point-adder","title":"2.2. Explicitly Instantiating Floating-Point Adder","text":"<p>This section will further illustrate how to use Synopsys DW components by explicitly instantiating a floating-point adder. You can learn more about the Synopsys DW component for a floating-point adder from its datasheet here:</p> <ul> <li>https://web.csl.cornell.edu/courses/ece6745/asicdocs/dwbb_datasheets/dw_fp_add.pdf</li> </ul> <p>We have already shown how to explicitly instantiate this Synopsys DW component along with input registers to create a single-stage floating-point adder. Look at the implementation provided in <code>FPAdd1stage.v</code>.</p> <pre><code>% cd $TOPDIR/sim/tut13_dw\n% code FPAdd1stage.v\n</code></pre> <p>The implementation is shown below.</p> <pre><code>module tut13_dw_FPAdd1stage\n(\n  input  logic        clk,\n  input  logic        reset,\n\n  input  logic        in_val,\n  input  logic [31:0] in0,\n  input  logic [31:0] in1,\n\n  output logic        out_val,\n  output logic [31:0] out\n);\n\n  // pipeline registers\n\n  logic        val_X0;\n  logic [31:0] in0_X0;\n  logic [31:0] in1_X0;\n\n  always_ff @(posedge clk) begin\n    if ( reset )\n      val_X0 &lt;= 1'b0;\n    else\n      val_X0 &lt;= in_val;\n\n    in0_X0 &lt;= in0;\n    in1_X0 &lt;= in1;\n  end\n\n  // floating-point adder\n\n  logic [7:0]  status_X0;\n  logic [31:0] out_X0;\n\n  DW_fp_add\n  #(\n    .sig_width       (23),\n    .exp_width       (8),\n    .ieee_compliance (1)\n  )\n  fp_add\n  (\n    .a      (in0_X0),\n    .b      (in1_X0),\n    .rnd    (3'b000),\n    .z      (out_X0),\n    .status (status_X0)\n  );\n\n  // output logic\n\n  assign out_val = val_X0;\n  assign out = out_X0 &amp; {32{val_X0}};\n\nendmodule\n</code></pre> <p>We configure the floating-point adder to support 32-bit floating point in standard single-precision IEEE format. The Synopsys DW component supports disabling IEEE compliance, different rounding modes, and status flags. We need to also explicitly include the Synopsys DW behavioral Verilog files. Let's go ahead and copy them into a <code>dw</code> directory in the source tree.</p> <pre><code>% mkdir -p $TOPDIR/sim/dw\n% cd $TOPDIR/sim/dw\n% cp /opt/synopsys/syn/V-2023.12-SP5/dw/sim_ver/DW_fp_addsub.v .\n% cp /opt/synopsys/syn/V-2023.12-SP5/dw/sim_ver/DW_fp_add.v .\n</code></pre> <p>Notice how we have to copy two files since <code>DW_fp_add.v</code> uses the module defined in <code>DW_fp_addsub.v</code>. You may need to experiment to ensure you have copied all of the files required for the desired Synopsys DW component.</p> <p>Now add the following include directives at the top of the <code>FPAdd1stage.v</code> file.</p> <pre><code>/* verilator lint_off LATCH */\n`include \"dw/DW_fp_addsub.v\"\n`include \"dw/DW_fp_add.v\"\n/* verilator lint_on LATCH */\n</code></pre> <p>Here we are using Verilator's special linting comments to turn off linting checks for inferred latches. You may need to experiment to ensure you have turned off the right linting checks so that Verilator can use the Synopsys DW behavioral Verilog component.</p> <p>Examine the simple basic test we have provided for the floating-point adder.</p> <pre><code>% cd $TOPDIR/sim/tut13_dw/test\n% code FPAdd1stage_test.py\n</code></pre> <p>The basic test case along with some helper functions is shown below.</p> <pre><code>def fp2bits( fp ):\n  if fp == '?':\n    return '?'\n  else:\n    return Bits32(int.from_bytes( pack( '&gt;f', fp ), byteorder='big' ))\n\ndef row( in_val, in0, in1, out_val, out ):\n  return [ in_val, fp2bits(in0), fp2bits(in1), out_val, fp2bits(out) ]\n\ndef test_basic( cmdline_opts ):\n  run_test_vector_sim( FPAdd1stage(), [\n       ( 'in_val in0   in1   out_val* out*'   ),\n    row( 0,      0.00, 0.00, 0,       '?'     ),\n    row( 1,      1.00, 1.00, 0,       '?'     ),\n    row( 1,      1.50, 1.50, 1,       2.00    ),\n    row( 1,      1.25, 2.50, 1,       3.00    ),\n    row( 0,      0.00, 0.00, 1,       3.75    ),\n    row( 0,      0.00, 0.00, 0,       '?'     ),\n  ], cmdline_opts )\n</code></pre> <p>We can use the Python <code>struct</code> package to convert a Python floating-point variable into 32-bit IEEE single-precision format. Here is an example:</p> <pre><code>% python\n&gt;&gt;&gt; from struct import pack\n&gt;&gt;&gt; pack( '&gt;f', 1.5 ).hex()\n'3fc00000'\n</code></pre> <p>The encoding of 0x3fc00000 matches what we expect when using an IEEE-754 floating-point converter such as this:</p> <ul> <li>https://www.h-schmidt.net/FloatConverter/IEEE754.html</li> </ul> <p>We need to use <code>int.from_bytes</code> to convert a byte array into an integer which is required when creating a <code>Bits32</code> object.</p> <p>Let's go ahead and run this basic test.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut13_dw/test/FPAdd1stage_test.py -sv\n</code></pre> <p>Now we are ready to generate a Verilog test bench which we can use for four-state RTL, fast-functional gate-level, and back-annotated gate-level simulation.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut13_dw/test/FPAdd1stage_test.py --test-verilog --dump-vtb\n</code></pre> <p>Now let's push the 1-stage floating-point adder through the ASIC automated flow again. We will start by just running the first two steps and looking at the synthesis reports.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut13-fpadd-1stage\n% cd $TOPDIR/asic/build-tut13-fpadd-1stage\n% pyhflow ../designs/tut13-fpadd-1stage.yml\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n</code></pre> <p>Let's first check the resources report to confirm that Synopsys DC is indeed using the Synopsys DW component for the floating-point adder as expected.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-1stage\n% cat 02-synopsys-dc-synth/resources.rpt\n</code></pre> <p>The resources report shows how Synopsys DC ultimately ended using not just one Synopsys DW component, but many components which together implement the floating-point addition. For example, consider this part of the resources report.</p> <pre><code>===============================================================================\n| Cell      | Module     | Parameters            | Contained Operations       |\n===============================================================================\n| lt_x_1    | DW_cmp     | width=31              | lt_189                     |\n| sub_x_6   | DW01_sub   | width=8               | sub_230                    |\n| ashr_7    | DW_rightsh | A_width=26,SH_width=8 | srl_235_lsb_trim           |\n| ash_8     | DW_leftsh  | A_width=26,SH_width=8 | sll_237                    |\n| gt_x_10   | DW_cmp     | width=8               | gt_253                     |\n| ash_12    | DW_leftsh  | A_width=27,SH_width=5 | sll_264                    |\n| add_x_16  | DW01_inc   | width=23              | add_301                    |\n| U1        | DW_lzd     | a_width=27            | U1                         |\n| DP_OP_54J1| DP_OP_54J1 |                       |                            |\n| DP_OP_55J1| DP_OP_55J1 |                       |                            |\n===============================================================================\n</code></pre> <p>Here we can see that Synopsys DC is using Synopsys DW components for comparators, subtractors, shifters, incrementers, and zero detectors. The bottom two rows tell us that Synospys DC has also created some custom components by unmerging and merging Synopsys DW components. You can learn more about these custom operators later in the report.</p> <pre><code>Datapath Report for DP_OP_54J1_124_7007\n==============================================================================\n| Cell                 | Contained Operations                                |\n==============================================================================\n| DP_OP_54J1_124_7007  | add_247 add_247_2                                   |\n==============================================================================\n\n==============================================================================\n|       |      | Data     |       |                                          |\n| Var   | Type | Class    | Width | Expression                               |\n==============================================================================\n| I1    | PI   | Unsigned | 27    |                                          |\n| I2    | PI   | Unsigned | 28    |                                          |\n| I3    | PI   | Unsigned | 1     |                                          |\n| O1    | PO   | Unsigned | 28    | I1 + I2 + I3                             |\n==============================================================================\n\nDatapath Report for DP_OP_55J1_125_9206\n==============================================================================\n| Cell                 | Contained Operations                                |\n==============================================================================\n| DP_OP_55J1_125_9206  | add_304 sub_305                                     |\n==============================================================================\n\n==============================================================================\n|       |      | Data     |       |                                          |\n| Var   | Type | Class    | Width | Expression                               |\n==============================================================================\n| I1    | PI   | Unsigned | 8     |                                          |\n| I2    | PI   | Unsigned | 5     |                                          |\n| O1    | PO   | Unsigned | 9     | I1 + $unsigned(1'b1)                     |\n| O2    | PO   | Signed   | 10    | O1 - I2                                  |\n==============================================================================\n</code></pre> <p>The <code>DP_OP_54J1</code> custom component implements a three input adder which adds a 27-bit, 28-bit, and 1-bit input to produce a 28-bit output. The <code>DP_OP_55J1</code> custom component implements a kind of addition/subtraction operation.</p> <p>Now let's check the timing report.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-1stage\n% cat 02-synopsys-dc-synth/timing.rpt\n</code></pre> <p>The timing report should look similar to what is shown below.</p> <pre><code>  Startpoint: v/in1_reg_reg[7]\n              (rising edge-triggered flip-flop clocked by ideal_clock1)\n  Endpoint: out[20] (output port clocked by ideal_clock1)\n  Path Group: ideal_clock1\n  Path Type: max\n\n  Des/Clust/Port     Wire Load Model       Library\n  ------------------------------------------------\n  FPAdd1stage_noparam\n                     5K_hvratio_1_1        NangateOpenCellLibrary\n\n  Point                        Fanout      Incr       Path\n  -----------------------------------------------------------\n  clock ideal_clock1 (rise edge)         0.0000     0.0000\n  clock network delay (ideal)            0.0000     0.0000\n  v/in1_X0_reg[7]/CK (DFF_X1)            0.0000     0.0000 r\n  v/in1_X0_reg[7]/Q (DFF_X1)             0.0790     0.0790 f\n  v/in1_reg[7] (net)             1       0.0000     0.0790 f\n  v/U44/ZN (OR2_X2)                      0.0525     0.1315 f\n  v/n246 (net)                   2       0.0000     0.1315 f\n  v/U493/ZN (OAI211_X1)                  0.0368     0.1683 r\n  ...\n  v/U442/ZN (XNOR2_X1)                   0.0528     2.8226 f\n  v/n213 (net)                   1       0.0000     2.8226 f\n  v/U474/ZN (NOR2_X1)                    0.0359     2.8584 r\n  v/n1483 (net)                  1       0.0000     2.8584 r\n  v/U39/ZN (OR2_X2)                      0.0452     2.9036 r\n  v/out[20] (net)                1       0.0000     2.9036 r\n  v/out[20] (tut13_dw_FPAdd1stage)       0.0000     2.9036 r\n  out[20] (net)                          0.0000     2.9036 r\n  out[20] (out)                          0.0456     2.9492 r\n  data arrival time                                 2.9492\n\n  clock ideal_clock1 (rise edge)         3.0000     3.0000\n  clock network delay (ideal)            0.0000     3.0000\n  output external delay                 -0.0500     2.9500\n  data required time                                2.9500\n  -----------------------------------------------------------\n  data required time                                2.9500\n  data arrival time                                -2.9492\n  -----------------------------------------------------------\n  slack (MET)                                       0.0008\n</code></pre> <p>The clock period constraint was set to be 3ns. The design is able to meet this constraint with a critical path that through almost 60 logic gates.</p> <p>Let's go ahead and push the 1-stage floating-point adder through the reset of the ASIC automated flow.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-1stage\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>The final summary is shown below.</p> <pre><code> timestamp           = 2025-04-06 11:17:28\n design_name         = FPAdd1stage_noparam\n clock_period        = 3.0\n rtlsim              = 1/1 passed\n synth_setup_slack   = 0.0008 ns\n synth_num_stdcells  = 1713\n synth_area          = 1985.956 um^2\n ffglsim             = 1/1 passed\n pnr_setup_slack     = 0.2676 ns\n pnr_hold_slack      = 0.0100 ns\n pnr_clk_ins_src_lat = 0 ns\n pnr_num_stdcells    = 1760\n pnr_area            = 2005.108 um^2\n baglsim             = 1/1 passed\n</code></pre>"},{"location":"ece6745-tut13-dw/#3-synopsys-design-compiler-for-register-retiming","title":"3. Synopsys Design Compiler for Register Retiming","text":"<p>While it can be very useful to leverage Synopsys DW components, what do we do if the provided component does not meet timing? In the previous section, our floating-point adder met the 3ns clock period constraint, but what if our target constraint is 1.5ns? Normally, we would consider pipelining the floating-point adder but this is not possible since we did not implement the floating-point adder ourselves. Even if we did implement the floating-point adder pipelining complex arithmetic units can be quite tedious. To address this issue, we can use a powerful technique called register retiming where the synthesis tool will automatically move pipeline registers to try and balance the pipeline stages. If we add an extra stage of pipeline registers at the end of the floating-point adder, then the synthesis tool can push these registers into the combinational logic to reduce the critical path.</p> <p>To illustrate register retiming, we have provided a 2-stage floating-point adder in <code>FPAdd2stage.v</code>.</p> <pre><code>% cd $TOPDIR/sim/tut13_dw\n% code FPAdd2stage.v\n</code></pre> <p>This implementation is similar to the 1-stage floating-point adder except for the extra set of retiming registers shown below.</p> <pre><code>  // retiming registers\n\n  logic        val_X1;\n  logic [31:0] out_X1;\n\n  always_ff @(posedge clk) begin\n    if ( reset )\n      val_X1 &lt;= 1'b0;\n    else\n      val_X1 &lt;= val_X0;\n\n    out_X1 &lt;= out_X0;\n  end\n\n  // output logic\n\n  assign out_val = val_X1;\n  assign out = out_X1 &amp; {32{val_X1}};\n</code></pre> <p>This looks strange since we are adding a set of pipeline registers after the floating-point adder. Without register retiming this would make no sense since these extra retiming registers will not actually reduce the critical path. The key idea though, is that register retiming will enable the synthesis tool to move these retiming registers into the middle of the combinational logic for the floating-point adder.</p> <p>Let's run the tests for our 2-stage floating point adder.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut13_dw/test/FPAdd2stage_test.py -sv\n</code></pre> <p>The trace output is shown in part below.</p> <pre><code>../tut13_dw/test/FPAdd1stage_test.py::test_basic\n  1r in_val=0, in0=00000000, in1=00000000, out=00000000, out_val=0\n  2r in_val=0, in0=00000000, in1=00000000, out=00000000, out_val=0\n  3: in_val=0, in0=00000000, in1=00000000, out=00000000, out_val=0\n  4: in_val=1, in0=3f800000, in1=3f800000, out=00000000, out_val=0\n  5: in_val=1, in0=3fc00000, in1=3fc00000, out=00000000, out_val=0\n  6: in_val=1, in0=3fa00000, in1=40200000, out=40000000, out_val=1\n  7: in_val=0, in0=00000000, in1=00000000, out=40400000, out_val=1\n  8: in_val=0, in0=00000000, in1=00000000, out=40700000, out_val=1\n</code></pre> <p>We can now see that a transaction takes two instead of one cycle. The first transaction goes into the floating-point adder on cycle 4 and the result is valid on cycle 6. Let's run the tests to create the Verilog test benches which we can use for four-state RTL, fast-functional gate-level, and back-annotated gate-level simulation.</p> <pre><code>% cd $TOPDIR/sim/build\n% pytest ../tut13_dw/test/FPAdd2stage_test.py --test-verilog --dump-vtb\n</code></pre> <p>Now let's push the 2-stage floating-point adder through the first two steps of the ASIC automated flow and look at the synthesis timing reports.</p> <pre><code>% mkdir -p $TOPDIR/asic/build-tut13-fpadd-2stage\n% cd $TOPDIR/asic/build-tut13-fpadd-2stage\n% pyhflow ../designs/tut13-fpadd-2stage.yml\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% cat ./02-synopsys-dc-synth/timing.rpt\n</code></pre> <p>The timing report should look similar to what is shown below.</p> <pre><code>  Startpoint: v/in1_X0_reg[0]\n              (rising edge-triggered flip-flop clocked by ideal_clock1)\n  Endpoint: v/out_X1_reg[22]\n            (rising edge-triggered flip-flop clocked by ideal_clock1)\n  Path Group: ideal_clock1\n  Path Type: max\n\n  Des/Clust/Port     Wire Load Model       Library\n  ------------------------------------------------\n  FPAdd2stage_noparam\n                     5K_hvratio_1_1        NangateOpenCellLibrary\n\n  Point                                       Fanout      Incr       Path\n  --------------------------------------------------------------------------\n  clock ideal_clock1 (rise edge)                        0.0000     0.0000\n  clock network delay (ideal)                           0.0000     0.0000\n  v/in1_X0_reg[0]/CK (DFF_X1)                           0.0000     0.0000 r\n  v/in1_X0_reg[0]/Q (DFF_X1)                            0.0929     0.0929 r\n  v/in1_X0[0] (net)                             4       0.0000     0.0929 r\n  v/U318/ZN (AND2_X1)                                   0.0445     0.1373 r\n  v/n217 (net)                                  1       0.0000     0.1373 r\n  v/U580/ZN (NAND2_X1)                                  0.0246     0.1619 f\n  ...\n  v/U368/ZN (AND3_X2)                                   0.0677     2.3291 f\n  v/n2090 (net)                                11       0.0000     2.3291 f\n  v/U2004/ZN (NAND2_X1)                                 0.0377     2.3667 r\n  v/n1854 (net)                                 1       0.0000     2.3667 r\n  v/U2005/ZN (NAND2_X1)                                 0.0254     2.3922 f\n  v/n2221 (net)                                 1       0.0000     2.3922 f\n  v/out_X1_reg[22]/D (DFF_X1)                           0.0086     2.4007 f\n  data arrival time                                                2.4007\n\n  clock ideal_clock1 (rise edge)                        1.5000     1.5000\n  clock network delay (ideal)                           0.0000     1.5000\n  v/out_X1_reg[22]/CK (DFF_X1)                          0.0000     1.5000 r\n  library setup time                                   -0.0395     1.4605\n  data required time                                               1.4605\n  --------------------------------------------------------------------------\n  data required time                                               1.4605\n  data arrival time                                               -2.4007\n  --------------------------------------------------------------------------\n  slack (VIOLATED)                                                -0.9402\n</code></pre> <p>Since we are using a 2-stage floating-point adder we reduced the clock period constraint to 1.5ns but we are not able to meet timing. This is because even though we added a set of retiming registers, we have not actually enabled retiming so the critical path will still be through the entire floating-point adder. The tools try hard but missing timing with a negative slack of 940ps.</p> <p>We need to use the <code>set_optimize_registers</code> command in the TCL script for Synospys DC to enable register retiming for specific modules in our design. The command would look like this:</p> <pre><code>set_optimize_registers true \\\n  -check_design -verbose -print_critical_loop \\\n  -design FPAdd2stage_noparam \\\n  -clock ideal_clock1 \\\n  -delay_threshold 1.5\n</code></pre> <p>We have support for register retiming in the ASIC automated flow. You can see it in the synthesis step template.</p> <pre><code>% cd $TOPDIR/asic/steps/02-synopsys-dc-synth\n% code run.tcl\n</code></pre> <p>Search through the TCL file to find the part related to register retiming which should be similar to what is shown below.</p> <pre><code>{% for module in retiming | default([]) -%}\nset_optimize_registers true \\\n  -design {{module}}  \\\n  -check_design -verbose -print_critical_loop \\\n  -clock ideal_clock1 -delay_threshold {{clock_period}}\n{% endfor %}\n</code></pre> <p>The <code>retime</code> variable in the YAML design file is used to specify a list of module names that should be retimed. Modify the <code>tut13-fpadd-2stage.yml</code> using VS Code.</p> <pre><code>% cd $TOPDIR/asic/designs/tut13-fpadd-2stage.yml\n% code run.tcl\n</code></pre> <p>Add the following to indicate that the <code>FPAdd2stage_noparam</code> module should be retimed.</p> <pre><code>retiming:\n  - FPAdd2stage_noparam\n</code></pre> <p>Now rerun pyhflow and verify the run scripts for synthesis now include the <code>set_optimize_registers</code> command.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-2stage\n% pyhflow ../designs/tut13-fpadd-2stage.yml\n% less ./02-synopsys-dc-synth/run.tcl\n</code></pre> <p>Assuming everything looks good, let's rerun synthesis and look at the timing report again.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-2stage\n% ./01-synopsys-vcs-rtlsim/run\n% ./02-synopsys-dc-synth/run\n% cat ./02-synopsys-dc-synth/timing.rpt\n</code></pre> <p>The timing report should look similar to what is shown below.</p> <pre><code>  Startpoint: v/ideal_clock1_r_REG58_S1\n              (rising edge-triggered flip-flop clocked by ideal_clock1)\n  Endpoint: v/ideal_clock1_r_REG13_S2\n            (rising edge-triggered flip-flop clocked by ideal_clock1)\n  Path Group: ideal_clock1\n  Path Type: max\n\n  Des/Clust/Port     Wire Load Model       Library\n  ------------------------------------------------\n  FPAdd2stage_noparam\n                     5K_hvratio_1_1        NangateOpenCellLibrary\n\n  Point                                       Fanout      Incr       Path\n  --------------------------------------------------------------------------\n  clock ideal_clock1 (rise edge)                        0.0000     0.0000\n  clock network delay (ideal)                           0.0000     0.0000\n  v/ideal_clock1_r_REG58_S1/CK (DFF_X1)                 0.0000     0.0000 r\n  v/ideal_clock1_r_REG58_S1/Q (DFF_X1)                  0.0803     0.0803 f\n  v/n1594 (net)                                 2       0.0000     0.0803 f\n  v/U14/ZN (OR2_X1)                                     0.0691     0.1494 f\n  v/n34 (net)                                   4       0.0000     0.1494 f\n  v/U57/ZN (NOR2_X1)                                    0.0900     0.2395 r\n  ...\n  v/U943/ZN (AND3_X1)                                   0.0366     1.3132 f\n  v/n774 (net)                                  1       0.0000     1.3132 f\n  v/U944/ZN (AND2_X1)                                   0.0373     1.3505 f\n  v/n776 (net)                                  1       0.0000     1.3505 f\n  v/U945/ZN (NOR4_X1)                                   0.0863     1.4368 r\n  v/n1692 (net)                                 1       0.0000     1.4368 r\n  v/ideal_clock1_r_REG13_S2/D (DFF_X1)                  0.0090     1.4458 r\n  data arrival time                                                1.4458\n\n  clock ideal_clock1 (rise edge)                        1.5000     1.5000\n  clock network delay (ideal)                           0.0000     1.5000\n  v/ideal_clock1_r_REG13_S2/CK (DFF_X1)                 0.0000     1.5000 r\n  library setup time                                   -0.0400     1.4600\n  data required time                                               1.4600\n  --------------------------------------------------------------------------\n  data required time                                               1.4600\n  data arrival time                                               -1.4458\n  --------------------------------------------------------------------------\n  slack (MET)                                                      0.0142\n</code></pre> <p>We are now able to meet timing. The synthesis tool has retimed both the input and output registers which is why the critical path starts and ends at registers with new names.</p> <p>Let's go ahead and push the 2-stage floating-point adder through the reset of the ASIC automated flow.</p> <pre><code>% cd $TOPDIR/asic/build-tut13-fpadd-2stage\n% ./03-synopsys-vcs-ffglsim/run\n% ./04-cadence-innovus-pnr/run\n% ./05-synopsys-vcs-baglsim/run\n% ./06-synopsys-pt-pwr/run\n% ./07-summarize-results/run\n</code></pre> <p>The final summary is shown below.</p> <pre><code> timestamp           = 2025-04-06 11:57:03\n design_name         = FPAdd2stage_noparam\n clock_period        = 1.5\n rtlsim              = 1/1 passed\n synth_setup_slack   = 0.0142 ns\n synth_num_stdcells  = 1759\n synth_area          = 2272.970 um^2\n ffglsim             = 1/1 passed\n pnr_setup_slack     = 0.2948 ns\n pnr_hold_slack      = 0.0108 ns\n pnr_clk_ins_src_lat = 0 ns\n pnr_num_stdcells    = 1851\n pnr_area            = 2372.454 um^2\n baglsim             = 1/1 passed\n</code></pre> <p>Compare these results to the results for the 1-stage floating-point adder. The 1-stage design met timing at 3ns, while the 2-stage design is able to meet timing at 1.5ns. The trade-off is area. The 2-stage design requires 2372um^2 while the 1-stage design only required 2005um^2 (18% increase). The energy for the 2-stage design would also likely be higher.</p>"}]}